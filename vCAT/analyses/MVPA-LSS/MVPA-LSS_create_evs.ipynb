{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vCAT MVPA - LSS Task \n",
    "## Create condition-specific EV files\n",
    "### Task structure: 2 sets/2 runs per set\n",
    "#### 180 trials/run: *30 BL, *50 cond, *100 fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sub-005\n",
      "\n",
      "sub-006\n",
      "\n",
      "sub-007\n",
      "\n",
      "sub-008\n",
      "\n",
      "sub-010\n",
      "\n",
      "sub-012\n",
      "\n",
      "sub-013\n",
      "\n",
      "sub-014\n",
      "\n",
      "sub-015\n",
      "\n",
      "sub-016\n",
      "\n",
      "sub-018\n",
      "\n",
      "sub-019\n",
      "\n",
      "sub-020\n",
      "\n",
      "sub-021\n",
      "\n",
      "sub-022\n",
      "\n",
      "sub-023\n",
      "\n",
      "sub-024\n",
      "\n",
      "sub-025\n",
      "\n",
      "sub-026\n",
      "\n",
      "sub-027\n",
      "\n",
      "sub-028\n",
      "\n",
      "sub-029\n",
      "\n",
      "sub-030\n",
      "\n",
      "sub-031\n",
      "\n",
      "sub-032\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "subs = ['sub-005', 'sub-006', 'sub-007', 'sub-008', 'sub-010', \n",
    "        'sub-012', 'sub-013', 'sub-014', 'sub-015', 'sub-016', \n",
    "        'sub-018', 'sub-019', 'sub-020', 'sub-021', 'sub-022', \n",
    "        'sub-023', 'sub-024', 'sub-025', 'sub-026', 'sub-027', \n",
    "        'sub-028', 'sub-029', 'sub-030', 'sub-031', 'sub-032']\n",
    "subs1 = ['sub-005']\n",
    "stim_sets = ['set1', 'set2']\n",
    "\n",
    "for sub in subs:\n",
    "    sub_dir = '/home/data/madlab/Mattfeld_vCAT/behav/{0}/'.format(sub)\n",
    "    dir_files = sorted(glob(join(sub_dir, '{0}_simp_task*.csv'.format(sub)))) \n",
    "    for i, curr_set in enumerate(stim_sets):\n",
    "        for curr_run in ['1', '2']:\n",
    "            if curr_run == '1':\n",
    "                run = pd.read_csv(dir_files[i*2]) #create dataframe for text files to extract EVs\n",
    "            else:\n",
    "                run = pd.read_csv(dir_files[i*2+1])              \n",
    "\n",
    "            trialtype = run['trialtype'].values #convert dataframes into numpy arrays\n",
    "            acc = run['acc'].values\n",
    "            resp = run['resp'].values\n",
    "            stim = run['stim'].values\n",
    "            onsets = run['onset'].values\n",
    "             \n",
    "            trial_shift = trialtype[1:] #shift trial type back and insert dummy (-1) in last index\n",
    "            trial_shift = np.append(trial_shift, -1)\n",
    "            acc_shift = acc[1:] #shift accuracy back and insert dummy (-1) in last index\n",
    "            acc_shift = np.append(acc_shift, -1)\n",
    "            resp_shift = resp[1:] #shift response back and insert dummy (-1) in last index\n",
    "            resp_shift = np.append(resp_shift, -1)\n",
    "                       \n",
    "            #grab indices matching specified criteria\n",
    "            fixed_BL_face = np.where((trialtype=='fixed')&(trial_shift=='BL')&((stim=='face1')|(stim=='face2')))[0]           \n",
    "            fixed_BL_scene = np.where((trialtype=='fixed')&(trial_shift=='BL')&((stim=='scene1')|(stim=='scene2')))[0]\n",
    "            remaining = list(range(0,180)) #remaining contains trials which dont proceed corr/incorr conds, and nonresp  \n",
    "\n",
    "            for x in fixed_BL_face:\n",
    "                remaining.remove(x) #remove fixed before face trials from all remaining\n",
    "                remaining.remove(x+1) #remove following BL trials from all remaining\n",
    "            for x in fixed_BL_scene:\n",
    "                remaining.remove(x) #remove fixed before scene trials from all remaining\n",
    "                remaining.remove(x+1) #remove following BL trials from all remaining\n",
    "                \n",
    "            #index onsets array using indices from np.where() criteria \n",
    "            fixed_BL_face_onsets = onsets[fixed_BL_face] \n",
    "            fixed_BL_scene_onsets = onsets[fixed_BL_scene] \n",
    "            remaining_onsets = onsets[remaining]\n",
    "            onsets2 = [] #onsets with combined fixed-BL pairs for mtrx\n",
    "            onset_durations = [] #need to arrange different durations by trial order\n",
    "            for y, curr_trial in enumerate(trialtype): #iterate through trialtypes \n",
    "                if curr_trial == 'fixed' and trial_shift[y] == 'BL': #if fixed followed by BL, assign duration of 8.5 sec\n",
    "                    onsets2.append(onsets[y]) #append fixed/BL onset\n",
    "                    onset_durations.append(8.5) #append duration of fixed and BL trial pairs\n",
    "                elif curr_trial == 'BL': #pass if current trialtype is BL\n",
    "                    continue\n",
    "                else: # if not fixed followed by BL or BL, assign duration of 3.0 sec\n",
    "                    onsets2.append(onsets[y])\n",
    "                    onset_durations.append(3.0) #append duration of fixed not followed by BL and cond trials\n",
    "         \n",
    "            #vstack matrix containing *ALL* onsets, durations, and amplitudes in vertical columns \n",
    "            mtrx = np.vstack((onsets2, onset_durations, np.ones(len(onsets2)))).T \n",
    "            fixed_BL_face_mtrx = np.vstack((fixed_BL_face_onsets,  np.ones(len(fixed_BL_face_onsets))*8.5,\n",
    "                                            np.ones(len(fixed_BL_face_onsets)))).T \n",
    "            fixed_BL_scene_mtrx = np.vstack((fixed_BL_scene_onsets,  np.ones(len(fixed_BL_scene_onsets))*8.5,\n",
    "                                             np.ones(len(fixed_BL_scene_onsets)))).T             \n",
    "            remaining_mtrx = np.vstack((remaining_onsets, np.ones(len(remaining_onsets))*3.0,\n",
    "                                        np.ones(len(remaining_onsets)))).T\n",
    "\n",
    "            if not os.path.exists(join(sub_dir, 'MVPA-LSS')): #if directory does not exist\n",
    "                os.makedirs(join(sub_dir, 'MVPA-LSS')) #create it\n",
    "                \n",
    "            if curr_run == '1': #if first run in stim set\n",
    "                np.savetxt(join(sub_dir, 'MVPA-LSS', 'run{0}.txt'.format(i*2+1)), mtrx, delimiter='\\t', fmt='%.4f')                \n",
    "                for trial in ['fixed_BL_face', 'fixed_BL_scene', 'remaining']: #for all trial types\n",
    "                    exec('np.savetxt(sub_dir+\"MVPA-LSS/\"+\"run{0}_{1}.txt\",{1}_mtrx,delimiter=\"\\t\",fmt=\"%.4f\")'.format(i*2+1,trial))\n",
    "            else: #if second run in stim set\n",
    "                np.savetxt(join(sub_dir, 'MVPA-LSS', 'run{0}.txt'.format(i*2+2)), mtrx, delimiter='\\t', fmt='%.4f')                \n",
    "                for trial in ['fixed_BL_face', 'fixed_BL_scene', 'remaining']:\n",
    "                    exec('np.savetxt(sub_dir+\"MVPA-LSS/\"+\"run{0}_{1}.txt\",{1}_mtrx,delimiter=\"\\t\",fmt=\"%.4f\")'.format(i*2+2,trial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
