{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vCAT GLM2\n",
    "## Create condition-specific EV files\n",
    "### Task structure: 2 sets/2 runs per set\n",
    "#### 180 trials/run: *30 BL, *50 cond, *100 fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "subs = ['sub-005', 'sub-006', 'sub-007', 'sub-008', 'sub-010', \n",
    "        'sub-012', 'sub-013', 'sub-014', 'sub-015', 'sub-016', \n",
    "        'sub-018', 'sub-019', 'sub-020', 'sub-021', 'sub-022', \n",
    "        'sub-023', 'sub-024', 'sub-025', 'sub-026', 'sub-027', \n",
    "        'sub-028', 'sub-029', 'sub-030', 'sub-031', 'sub-032']\n",
    "\n",
    "stim_sets = ['set1', 'set2']\n",
    "\n",
    "for sub in subs:\n",
    "    sub_dir = '/home/data/madlab/Mattfeld_vCAT/behav/sub-{0}/'.format(sub)\n",
    "    dir_files = sorted(glob(join(sub_dir, 'sub-{0}_simp_task*.csv'.format(sub)))) \n",
    "    print(sub, len(dir_files))\n",
    " \n",
    "    for i, curr_set in enumerate(stim_sets):\n",
    "        for curr_run in ['1', '2']:\n",
    "            if curr_run == '1':\n",
    "                run = pd.read_csv(dir_files[i*2]) #create dataframe for text files to extract EVS\n",
    "                #run = run[:-3] #removal of the last 3 trials to avoid scanner artifact\n",
    "            else:\n",
    "                run = pd.read_csv(dir_files[i*2+1])\n",
    "                #run = run[:-3]          \n",
    "        \n",
    "            trialtype = run['trialtype'].values #convert dataframes into numpy arrays\n",
    "            acc = run['acc'].values\n",
    "            resp = run['resp'].values\n",
    "            onsets = run['onset'].values\n",
    "                 \n",
    "            #grab indices matching multiple specified criteria\n",
    "            fixed_corr = np.where((acc == 1) & (trialtype == 'fixed'))[0]                                    \n",
    "            fixed_incorr = np.where((acc == 0) & (trialtype == 'fixed') & (resp != 'None'))[0]       \n",
    "            cond_corr = np.where((acc == 1) & (trialtype == 'cond'))[0]                             \n",
    "            cond_incorr = np.where((acc == 0) & (trialtype == 'cond') & (resp != 'None'))[0]                                   \n",
    "            remaining = np.where((trialtype == 'BL') | (resp == 'None'))[0] #BL and nonresponse trials\n",
    "\n",
    "\n",
    "            #index onsets array using indices from np.where() criteria\n",
    "            fixed_corr_onsets = onsets[fixed_corr]\n",
    "            fixed_incorr_onsets = onsets[fixed_incorr]\n",
    "            cond_corr_onsets = onsets[cond_corr]\n",
    "            cond_incorr_onsets = onsets[cond_incorr]\n",
    "            remaining_onsets = onsets[remaining]\n",
    "\n",
    "        \n",
    "            #v-stack matrix containing onsets, durations, and amplitudes in vertical columns for specified trial type (transposed)\n",
    "            mtrx = np.vstack((onsets, np.ones(len(onsets))*3.0, #Numpy array filled with 3's\n",
    "                              np.ones(len(onsets)))).T #Numpy array filled with 1's \n",
    "            fixed_corr_mtrx = np.vstack((fixed_corr_onsets, np.ones(len(fixed_corr_onsets))*3.0, \n",
    "                                         np.ones(len(fixed_corr_onsets)))).T \n",
    "            fixed_incorr_mtrx = np.vstack((fixed_incorr_onsets, np.ones(len(fixed_incorr_onsets))*3.0, \n",
    "                                           np.ones(len(fixed_incorr_onsets)))).T\n",
    "            cond_corr_mtrx = np.vstack((cond_corr_onsets, np.ones(len(cond_corr_onsets))*3.0, \n",
    "                                        np.ones(len(cond_corr_onsets)))).T\n",
    "            cond_incorr_mtrx = np.vstack((cond_incorr_onsets, np.ones(len(cond_incorr_onsets))*3.0, \n",
    "                                          np.ones(len(cond_incorr_onsets)))).T   \n",
    "            remaining_mtrx = np.vstack((remaining_onsets, np.ones(len(remaining_onsets))*3.0, \n",
    "                                        np.ones(len(remaining_onsets)))).T\n",
    "         \n",
    "            if not os.path.exists(join(sub_dir, 'GLM2')): #if directory does not exist\n",
    "                os.makedirs(join(sub_dir, 'GLM2')) #create it\n",
    "                \n",
    "            if curr_run == '1': #if first run in stim set\n",
    "                np.savetxt(join(sub_dir, 'GLM2', 'run{0}.txt'.format(i*2+1)), mtrx, delimiter='\\t', fmt='%.4f')                \n",
    "                for trial in ['fixed_corr', 'fixed_incorr', 'cond_corr', 'cond_incorr', 'remaining']: #for all trial types\n",
    "                    exec('np.savetxt(sub_dir+\"GLM2/\"+\"run{0}_{1}.txt\",{1}_mtrx,delimiter=\"\\t\",fmt=\"%.4f\")'.format(i*2+1,trial))\n",
    "\n",
    "            else: #if second run in stim set\n",
    "                np.savetxt(join(sub_dir, 'GLM2', 'run{0}.txt'.format(i*2+2)), mtrx, delimiter='\\t', fmt='%.4f')                \n",
    "                for trial in ['fixed_corr', 'fixed_incorr', 'cond_corr', 'cond_incorr', 'remaining']:\n",
    "                    exec('np.savetxt(sub_dir+\"GLM2/\"+\"run{0}_{1}.txt\",{1}_mtrx,delimiter=\"\\t\",fmt=\"%.4f\")'.format(i*2+2,trial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
