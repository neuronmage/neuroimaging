{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL GLM1\n",
    "### Contains only fixed-before-conditional trials without intervening BLs\n",
    "### Combines A & C trials into single regressor\n",
    "### Accounts for last three noisy volumes in Lvl 1 analysis (FSL ROI -- ExtractROI)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import nipype.pipeline as pe\n",
    "import nipype.interfaces.io as nio\n",
    "import os\n",
    "import nipype.interfaces.freesurfer as fs\n",
    "from nipype import IdentityInterface\n",
    "\n",
    "subjects_dir = '/home/data/madlab/surfaces/wmaze'\n",
    "work_dir = '/scratch/madlab/wmaze/regions_workdir'\n",
    "sink_dir = '/home/data/madlab/data/mri/wmaze/roi_analysis/fb4c_2/mask'\n",
    "\n",
    "sids = ['WMAZE_001', 'WMAZE_002', 'WMAZE_004', 'WMAZE_005', 'WMAZE_006', \n",
    "        'WMAZE_007', 'WMAZE_008', 'WMAZE_009', 'WMAZE_010', 'WMAZE_012', \n",
    "        'WMAZE_017', 'WMAZE_018', 'WMAZE_019', 'WMAZE_020', 'WMAZE_021', \n",
    "        'WMAZE_022', 'WMAZE_023', 'WMAZE_024', 'WMAZE_026', 'WMAZE_027']\n",
    "\n",
    "wf = pe.Workflow(name = 'wf')\n",
    "wf.base_dir = work_dir\n",
    "\n",
    "#Node for subject_iterable\n",
    "subj_iterable = pe.Node(IdentityInterface(fields = ['subject_id'], \n",
    "                                          mandatory_inputs = True),\n",
    "                        name = 'subj_iterable')\n",
    "subj_iterable.iterables = ('subject_id', sids)\n",
    "\n",
    "info = dict(ref_epi_file = [['subject_id']],\n",
    "            bbreg_xfm = [['subject_id']],\n",
    "            aparc_aseg = [['subject_id']])\n",
    "\n",
    "#Node Datagrabber\n",
    "datasource = pe.Node(nio.DataGrabber(infields = ['subject_id'],\n",
    "                                     outfields = info.keys()),\n",
    "                     name = 'datasource')\n",
    "datasource.inputs.base_directory = os.path.abspath('/home/data/madlab/')\n",
    "datasource.inputs.field_template = dict(ref_epi_file = 'data/mri/wmaze/preproc/%s/ref/*.nii.gz',\n",
    "                                        bbreg_xfm = 'data/mri/wmaze/preproc/%s/bbreg/_fs_register0/*.dat',\n",
    "                                        aparc_aseg = 'surfaces/wmaze/%s/mri/aparc+aseg.mgz')\n",
    "datasource.inputs.template = '*'\n",
    "datasource.inputs.template_args = info\n",
    "datasource.inputs.sort_filelist = True\n",
    "datasource.inputs.ignore_exception = False\n",
    "datasource.inputs.raise_on_empty = True\n",
    "wf.connect(subj_iterable, 'subject_id', datasource, 'subject_id')\n",
    "\n",
    "#MapNode for binarized ROI masks\n",
    "anat_mask = pe.MapNode(fs.Binarize(),\n",
    "                       iterfield = ['match', 'binary_file'], \n",
    "                       name = 'anat_mask')\n",
    "anat_mask.inputs.match = [[17], [53], #hippocampus\n",
    "                          [1002,1026], [2002,2026], #rostral and caudal anterior cingulate\n",
    "                          [12],[51]] #putamen \n",
    "                          \n",
    "anat_mask.inputs.binary_file = ['lh-hippocampus.nii.gz', 'rh-hippocampus.nii.gz',\n",
    "                                'lh-mPFC_fs.nii.gz','rh-mPFC_fs.nii.gz',\n",
    "                                'lh-putamen.nii.gz, 'rh-putamen.nii.gz]\n",
    "wf.connect(datasource, 'aparc_aseg', anat_mask, 'in_file')\n",
    "\n",
    "#MapNode to transform the masks to 1st volume of 1st run (EPI space)\n",
    "anatmask_xfm = pe.MapNode(fs.ApplyVolTransform(inverse = True,\n",
    "                                               interp = 'nearest'),\n",
    "                          iterfield = ['target_file'],\n",
    "                          name = 'anatmask_xfm')\n",
    "anatmask_xfm.inputs.subjects_dir = subjects_dir\n",
    "wf.connect(datasource, 'ref_epi_file', anatmask_xfm, 'source_file')\n",
    "wf.connect(datasource, 'bbreg_xfm', anatmask_xfm, 'reg_file')\n",
    "wf.connect(anat_mask, 'binary_file', anatmask_xfm, 'target_file')\n",
    "\n",
    "#Node Datasink\n",
    "sinker = pe.Node(nio.DataSink(infields = None),\n",
    "                 name = \"sinker\")\n",
    "sinker.inputs._outputs = {}\n",
    "sinker.inputs.base_directory = sink_dir\n",
    "sinker.inputs.ignore_exception = False\n",
    "sinker.inputs.parameterization = True\n",
    "sinker.inputs.remove_dest_dir = False\n",
    "wf.connect(anatmask_xfm, 'transformed_file', sinker, 'anat_masks')\n",
    "wf.run(plugin = 'LSF', plugin_args = {'bsub_args': '-q PQ_madlab'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROI mask specs:\n",
    "### Hippocampus (FS labels: hippocampus [17, 53])\n",
    "### Putamen (FS labels: putamen [12, 51])\n",
    "### Medial PFC (FS labels: rostral anterior cingulate [1026, 2026] & caudal anterior cingulate [1002, 2002])\n",
    "### Dorsal caudate (hand-drawn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from glob import glob\n",
    "from scipy import stats\n",
    "from math import sqrt\n",
    "import nibabel as nb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set_style(\"white\")\n",
    "sns.set_palette('muted')\n",
    "\n",
    "subs = ['WMAZE_001', 'WMAZE_002', 'WMAZE_004', 'WMAZE_005', 'WMAZE_006', \n",
    "        'WMAZE_007', 'WMAZE_008', 'WMAZE_009', 'WMAZE_010', 'WMAZE_012', \n",
    "        'WMAZE_017', 'WMAZE_018', 'WMAZE_019', 'WMAZE_020', 'WMAZE_021',  \n",
    "        'WMAZE_022', 'WMAZE_023', 'WMAZE_024', 'WMAZE_026', 'WMAZE_027']\n",
    "proj_dir = '/home/data/madlab/data/mri/wmaze' \n",
    "mask_filenames = []\n",
    "cope_files = []\n",
    "for sub in subs:\n",
    "    mask_filenames_glob = glob(proj_dir+ '/roi_analysis/anat_masks/_subject_id_'+ sub +'/_anatmask_xfm*/*')\n",
    "    mask_filenames.append(sorted(mask_filenames_glob))\n",
    "    subjcopes_glob = glob(proj_dir+ '/scndlvl/model_GLM/'+ sub +'/fixedfx/cope_*')\n",
    "    cope_files.append(sorted(subjcopes_glob))\n",
    "    if len(cope_files[-1]) == 0:\n",
    "        print(sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double-check the array indexing for masks and copes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#change first index of cope_files to indicate participant index in sids array\n",
    "for i, curr_mask in enumerate(mask_filenames[0]):\n",
    "    print(i, mask_filenames[0][i].split('/')[-1][:-7]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, curr_cope in enumerate(cope_files[0]):\n",
    "    print(i, cope_files[0][i].split('/')[-1][5:-7]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use binarized mask to obtain activation in left & right hemisphere for each region of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_data = {'subjid':[],\n",
    "            'lhhp_all_before_B_corr':[], 'rhhp_all_before_B_corr':[], \n",
    "            'lhhp_all_before_B_incorr':[], 'rhhp_all_before_B_incorr':[],            \n",
    "            'lhmpfc_all_before_B_corr':[], 'rhmpfc_all_before_B_corr':[], \n",
    "            'lhmpfc_all_before_B_incorr':[], 'rhmpfc_all_before_B_incorr':[],            \n",
    "            'lhcaud_all_before_B_corr':[], 'rhcaud_all_before_B_corr':[], \n",
    "            'lhcaud_all_before_B_incorr':[], 'rhcaud_all_before_B_incorr':[],            \n",
    "            'lhput_all_before_B_corr':[], 'rhput_all_before_B_corr':[], \n",
    "            'lhput_all_before_B_incorr':[], 'rhput_all_before_B_incorr':[]}\n",
    "\n",
    "for i in range(len(subs)):\n",
    "    all_data['subjid'].append(subs[i])\n",
    "    #ROI masks\n",
    "    lh_hp_img = nb.load(mask_filenames[i][2])\n",
    "    rh_hp_img = nb.load(mask_filenames[i][11])\n",
    "    lh_mpfc_img = nb.load(mask_filenames[i][4])\n",
    "    rh_mpfc_img = nb.load(mask_filenames[i][13])\n",
    "    lh_caud_img = nb.load(mask_filenames[i][7])\n",
    "    rh_caud_img = nb.load(mask_filenames[i][8])\n",
    "    lh_put_img = nb.load(mask_filenames[i][16])\n",
    "    rh_put_img = nb.load(mask_filenames[i][17])\n",
    "    #copes\n",
    "    all_before_B_corr_img = nb.load(cope_files[i][0])\n",
    "    all_before_B_incorr_img = nb.load(cope_files[i][1])    \n",
    "    \n",
    "    region = ['hp', 'mpfc', 'caud', 'put']\n",
    "    learn_type = ['all_before_B_corr', 'all_before_B_incorr']   \n",
    "    for r in region:\n",
    "        for l in learn_type:\n",
    "            lh_data = eval('{0}_img.get_data()[lh_{1}_img.get_data() > 0.]'.format(l,r))\n",
    "            all_data['lh{0}_{1}'.format(r,l)].append(np.mean(lh_data))            \n",
    "            rh_data = eval('{0}_img.get_data()[rh_{1}_img.get_data() > 0.]'.format(l,r))\n",
    "            all_data['rh{0}_{1}'.format(r,l)].append(np.mean(rh_data))\n",
    "    \n",
    "all_data_df = pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the two hemispheres to create one regional average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "region = ['hp', 'mpfc', 'caud', 'put']\n",
    "learn_type = ['all_before_B_corr', 'all_before_B_incorr']\n",
    "for r in region:\n",
    "    for l in learn_type:\n",
    "        all_data_df['{0}_{1}'.format(r,l)] = (all_data_df['lh{0}_{1}'.format(r,l)] \n",
    "                                              + all_data_df['rh{0}_{1}'.format(r,l)])/2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Region-specific dataframes for producing plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hp_plot = {}\n",
    "mpfc_plot = {}\n",
    "caud_plot = {}\n",
    "put_plot = {}\n",
    "\n",
    "for i in ['hp', 'mpfc', 'caud', 'put']:\n",
    "    exec('{0}_plot[\"corr\"] = all_data_df[\"{0}_all_before_B_corr\"]'.format(i))\n",
    "    exec('{0}_plot[\"incorr\"] = all_data_df[\"{0}_all_before_B_incorr\"]'.format(i))\n",
    "    exec('{0}_plot_df = pd.DataFrame.from_dict({0}_plot)'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hippocampus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in hp_plot:\n",
    "    print \"Mean {0}: \".format(key), np.mean(hp_plot['{0}'.format(key)])\n",
    "    print \"STD {0}: \".format(key), np.std(hp_plot['{0}'.format(key)])\n",
    "    print \"\"\n",
    "cohens_d=((np.average(hp_plot['corr'])-np.average(hp_plot['incorr']))/(sqrt((np.std(hp_plot['corr'],ddof=1)) \n",
    "           **2+np.std(hp_plot['incorr'],ddof = 1)**2)/2))\n",
    "print 'T-test: HPC all_before_B_corr vs. all_before_B_incorr'\n",
    "print stats.ttest_rel(hp_plot['corr'], hp_plot['incorr'])\n",
    "print \"Cohen's d = \", cohens_d\n",
    "\n",
    "N = 2\n",
    "conditions = ['FIXED before COND Corr', 'FIXED before COND Incorr']\n",
    "hp_allsubjs = [hp_plot['corr'], hp_plot['incorr']]\n",
    "ind = np.arange(N)\n",
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "ax0 = sns.boxplot(data = hp_allsubjs, color = \"#278fea\", width = 0.3)\n",
    "ax2 = sns.swarmplot(data = hp_allsubjs, color='.25')\n",
    "ax.set_xticklabels(conditions)\n",
    "ax.set_xticks(ind)\n",
    "ax.set_ylabel(\"Arbitrary units\")\n",
    "ax.set_title(\"Hippocampal Activation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medial PFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in mpfc_plot:\n",
    "    print \"Mean {0}: \".format(key), np.mean(mpfc_plot['{0}'.format(key)])\n",
    "    print \"STD {0}: \".format(key), np.std(mpfc_plot['{0}'.format(key)])\n",
    "    print \"\"\n",
    "cohens_d=((np.average(mpfc_plot['corr'])-np.average(mpfc_plot['incorr']))\n",
    "          /(sqrt((np.std(mpfc_plot['corr'],ddof=1)) \n",
    "           **2+np.std(mpfc_plot['incorr'],ddof = 1)**2)/2))\n",
    "print 'T-test: Medial PFC all_before_B_corr vs. all_before_B_incorr'\n",
    "print stats.ttest_rel(mpfc_plot['corr'], mpfc_plot['incorr'])\n",
    "print \"Cohen's d = \", cohens_d\n",
    "\n",
    "N = 2\n",
    "conditions = ['FIXED before COND Corr', 'FIXED before COND Incorr']\n",
    "mpfc_allsubjs = [mpfc_plot['corr'], mpfc_plot['incorr']]\n",
    "ind = np.arange(N)\n",
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "ax0 = sns.boxplot(data = mpfc_allsubjs, color = \"#f97401\", width = 0.3)\n",
    "ax2 = sns.swarmplot(data = mpfc_allsubjs, color='.25')\n",
    "ax.set_xticklabels(conditions)\n",
    "ax.set_xticks(ind)\n",
    "ax.set_ylabel(\"Arbitrary units\")\n",
    "ax.set_title(\"Medial PFC Activation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caudate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in caud_plot:\n",
    "    print \"Mean {0}: \".format(key), np.mean(caud_plot['{0}'.format(key)])\n",
    "    print \"STD {0}: \".format(key), np.std(caud_plot['{0}'.format(key)])\n",
    "    print \"\"\n",
    "cohens_d=((np.average(caud_plot['corr'])-np.average(caud_plot['incorr']))\n",
    "          /(sqrt((np.std(caud_plot['corr'],ddof=1)) \n",
    "           **2+np.std(caud_plot['incorr'],ddof = 1)**2)/2))\n",
    "print 'T-test: Caudate all_before_B_corr vs. all_before_B_incorr'\n",
    "print stats.ttest_rel(caud_plot['corr'], caud_plot['incorr'])\n",
    "print \"Cohen's d = \", cohens_d\n",
    "\n",
    "N = 2\n",
    "conditions = ['FIXED before COND Corr', 'FIXED before COND Incorr']\n",
    "caud_allsubjs = [caud_plot['corr'], caud_plot['incorr']]\n",
    "ind = np.arange(N)\n",
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "ax0 = sns.boxplot(data = caud_allsubjs, color = \"#f9f96d\", width = 0.3)\n",
    "ax2 = sns.swarmplot(data = caud_allsubjs, color='.25')\n",
    "ax.set_xticklabels(conditions)\n",
    "ax.set_xticks(ind)\n",
    "ax.set_ylabel(\"Arbitrary units\")\n",
    "ax.set_title(\"Caudate Activation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putamen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in put_plot:\n",
    "    print \"Mean {0}: \".format(key), np.mean(put_plot['{0}'.format(key)])\n",
    "    print \"STD {0}: \".format(key), np.std(put_plot['{0}'.format(key)])\n",
    "    print \"\"\n",
    "cohens_d=((np.average(put_plot['corr'])-np.average(put_plot['incorr']))/(sqrt((np.std(put_plot['corr'],ddof=1)) \n",
    "           **2+np.std(put_plot['incorr'],ddof = 1)**2)/2))\n",
    "print 'T-test: Putamen all_before_B_corr vs. all_before_B_incorr'\n",
    "print stats.ttest_rel(put_plot['corr'], put_plot['incorr'])\n",
    "print \"Cohen's d = \", cohens_d\n",
    "\n",
    "N = 2\n",
    "conditions = ['FIXED before COND Corr', 'FIXED before COND Incorr']\n",
    "put_allsubjs = [put_plot['corr'], put_plot['incorr']]\n",
    "ind = np.arange(N)\n",
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "ax0 = sns.boxplot(data = put_allsubjs, color = \"#c34aef\", width = 0.3)\n",
    "ax2 = sns.swarmplot(data = put_allsubjs, color='.25')\n",
    "ax.set_xticklabels(conditions)\n",
    "ax.set_xticks(ind)\n",
    "ax.set_ylabel(\"Arbitrary units\")\n",
    "ax.set_title(\"Putamen Activation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Scatterplots\n",
    "\n",
    "## - Compares avg preceding fixed activation with avg performance on conditional trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_prop_corr = []\n",
    "\n",
    "for sub in subs:\n",
    "    sub_dir = '/home/data/madlab/data/mri/wmaze/scanner_behav/{0}/'.format(sub)\n",
    "    dir_file = glob(join(sub_dir, '{0}_wmazebl_2015*.txt'.format(sub)))   \n",
    "    dir_file.sort()    \n",
    "    \n",
    "    run1 = pd.read_table(dir_file[0]) #open each run and cut off last three trials\n",
    "    run1 = run1[:-3]\n",
    "    run2 = pd.read_table(dir_file[1])\n",
    "    run2 = run2[:-3]\n",
    "    run3 = pd.read_table(dir_file[2])\n",
    "    run3 = run3[:-3]\n",
    "    run4 = pd.read_table(dir_file[3])\n",
    "    run4 = run4[:-3]\n",
    "    run5 = pd.read_table(dir_file[4])\n",
    "    run5 = run5[:-3]\n",
    "    run6 = pd.read_table(dir_file[5])\n",
    "    run6 = run6[:-3]\n",
    "    \n",
    "    all_runs = [run1, run2, run3, run4, run5, run6] #concatenate all 6 runs   \n",
    "    data_set = pd.concat(all_runs)\n",
    "    \n",
    "    trialtype = data_set['TrialType'].values #Numpy arrays for trial type and accuracy\n",
    "    correct = data_set['Correct'].values \n",
    "    \n",
    "    trial_shift = trialtype[:-1] #removing last trial and shifting down \n",
    "    trial_shift = np.insert(trial_shift, 0, -1)\n",
    "    correct_shift = correct[:-1]\n",
    "    correct_shift = np.insert(correct_shift, 0, -1)\n",
    "    #grab indices for trials matching specified criteria\n",
    "    corr = sorted(np.where(((trialtype == 'B') & (correct == 1)) & (trial_shift != 'BL'))[0])    \n",
    "    incorr = sorted(np.where(((trialtype == 'B') & (correct == 0)) & (trial_shift != 'BL'))[0])      \n",
    "    all_prop_corr.append(len(corr)/float(len(corr)+len(incorr))) #append proportion of correct trials\n",
    "\n",
    "all_data_df['prop_corr'] = all_prop_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average regional activation across all trial types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "region = ['hp', 'mpfc', 'caud', 'put']\n",
    "for r in region:\n",
    "    all_data_df['{0}_all_before_B'.format(r,l)] = (all_data_df['lh{0}_all_before_B_corr'.format(r)] \n",
    "                                                   + all_data_df['rh{0}_all_before_B_corr'.format(r)]\n",
    "                                                   + all_data_df['lh{0}_all_before_B_incorr'.format(r)] \n",
    "                                                   + all_data_df['rh{0}_all_before_B_incorr'.format(r)])/4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hippocampus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = all_data_df['prop_corr']\n",
    "y = all_data_df['hp_all_before_B']\n",
    "\n",
    "print 'FIXED --> COND', pearsonr(x,y)\n",
    "fig, ax = plt.subplots()\n",
    "ax = sns.regplot(x = 'prop_corr', y = 'hp_all_before_B', data = all_data_df)\n",
    "ax.set_ylabel('Preceding Fixed Activation')\n",
    "ax.set_xlabel('Following Conditional Performance')\n",
    "ax.set_title('Hippocampus')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mPFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = all_data_df['prop_corr']\n",
    "y = all_data_df['mpfc_all_before_B']\n",
    "\n",
    "print 'FIXED --> COND', pearsonr(x,y)\n",
    "fig, ax = plt.subplots()\n",
    "ax = sns.regplot(x = 'prop_corr', y = 'mpfc_all_before_B', color = '#f97401', data = all_data_df)\n",
    "ax.set_ylabel('Preceding Fixed Activation')\n",
    "ax.set_xlabel('Following Conditional Performance')\n",
    "ax.set_title('mPFC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caudate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = all_data_df['prop_corr']\n",
    "y = all_data_df['caud_all_before_B']\n",
    "\n",
    "print 'FIXED --> COND', pearsonr(x,y)\n",
    "fig, ax = plt.subplots()\n",
    "ax = sns.regplot(x = 'prop_corr', y = 'caud_all_before_B', color = \"#f7e200\", data = all_data_df)\n",
    "ax.set_ylabel('Preceding Fixed Activation')\n",
    "ax.set_xlabel('Following Conditional Performance')\n",
    "ax.set_title('Caudate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putamen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = all_data_df['prop_corr']\n",
    "y = all_data_df['put_all_before_B']\n",
    "\n",
    "print 'FIXED --> COND', pearsonr(x,y)\n",
    "fig, ax = plt.subplots()\n",
    "ax = sns.regplot(x = 'prop_corr', y = 'put_all_before_B', color = \"#c34aef\", data = all_data_df)\n",
    "ax.set_ylabel('Preceding Fixed Activation')\n",
    "ax.set_xlabel('Following Conditional Performance')\n",
    "ax.set_title('Putamen')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
