{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from nipype.interfaces.base import Bunch\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "base_proj_dir = '/home/data/madlab/data/mri/wmaze/scanner_behav'\n",
    "output = []\n",
    "\n",
    "subject_id = 'WMAZE_001'\n",
    "curr_set = 1\n",
    "names = []\n",
    "onsets = []\n",
    "durations = []\n",
    "amplitudes = []\n",
    "\n",
    "\n",
    "data_learning_bin1 = np.genfromtxt(base_proj_dir + \n",
    "                                   '/{0}/MRthesis/model_learn1/EVs/set{1}_l_bin_1.txt'.format(subject_id, curr_set), \n",
    "                                   dtype = str)\n",
    "\n",
    "data_learning_bin2 = np.genfromtxt(base_proj_dir + \n",
    "                                   '/{0}/MRthesis/model_learn1/EVs/set{1}_l_bin_2.txt'.format(subject_id, curr_set), \n",
    "                                   dtype = str)\n",
    "\n",
    "data_learning_bin3 = np.genfromtxt(base_proj_dir + \n",
    "                                   '/{0}/MRthesis/model_learn1/EVs/set{1}_l_bin_3.txt'.format(subject_id, curr_set), \n",
    "                                   dtype = str)\n",
    "\n",
    "data_learning_bin4 = np.genfromtxt(base_proj_dir + \n",
    "                                   '/{0}/MRthesis/model_learn1/EVs/set{1}_l_bin_4.txt'.format(subject_id, curr_set), \n",
    "                                   dtype = str)\n",
    "\n",
    "data_all_remaining = np.genfromtxt(base_proj_dir + \n",
    "                                   '/{0}/MRthesis/model_learn1/EVs/set{1}_all_remaining.txt'.format(subject_id, curr_set), \n",
    "                                   dtype = str)  \n",
    "\n",
    "data_nonresponse = np.genfromtxt(base_proj_dir +\n",
    "                                 '/{0}/MRthesis/model_learn1/EVs/set{1}_nonresponse.txt'.format(subject_id, curr_set), \n",
    "                                 dtype = str)\n",
    "\n",
    "\n",
    "sequence = ['bin1', 'bin2', 'bin3', 'bin4']\n",
    "for curr_type in sequence:\n",
    "    array_name = eval('data_learning_{0}'.format(curr_type))     \n",
    "    curr_names = ['learning_{0}'.format(curr_type)]\n",
    "    curr_onsets = map(float, array_name[:,0])\n",
    "    curr_durations = map(float, array_name[:,1])\n",
    "    curr_amplitudes = map(float, array_name[:,2])\n",
    "\n",
    "    curr_onsets = [curr_onsets]\n",
    "    curr_durations = [curr_durations]\n",
    "    curr_amplitudes = [curr_amplitudes]\n",
    "\n",
    "    names.append(curr_names) \n",
    "    onsets.append(curr_onsets)\n",
    "    durations.append(curr_durations)\n",
    "    amplitudes.append(curr_amplitudes)\n",
    "\n",
    "\n",
    "curr_names = ['all_remaining']\n",
    "curr_onsets = map(float, data_all_remaining[:,0])\n",
    "curr_durations = map(float, data_all_remaining[:,1])\n",
    "curr_amplitudes = map(float, data_all_remaining[:,2])\n",
    "\n",
    "curr_onsets = [curr_onsets]\n",
    "curr_durations = [curr_durations]\n",
    "curr_amplitudes = [curr_amplitudes] \n",
    "\n",
    "names.append(curr_names)  \n",
    "onsets.append(curr_onsets)\n",
    "durations.append(curr_durations)\n",
    "amplitudes.append(curr_amplitudes)  \n",
    "\n",
    "\n",
    "# If any element in names is a list instead of a single value, for those elements\n",
    "if any(isinstance(el, list) for el in names):\n",
    "    # Unpacks subarrays into one mega array!\n",
    "    names = [el for sublist in names for el in sublist]  \n",
    "if any(isinstance(el, list) for el in onsets):\n",
    "    onsets = [el_o for sublist_o in onsets for el_o in sublist_o]\n",
    "if any(isinstance(el, list) for el in durations):\n",
    "    durations = [el_d for sublist_d in durations for el_d in sublist_d]\n",
    "if any(isinstance(el, list) for el in amplitudes):\n",
    "    amplitudes = [el_a for sublist_a in amplitudes for el_a in sublist_a]\n",
    "\n",
    "\n",
    "output.insert(curr_set,\n",
    "              Bunch(conditions = names,\n",
    "                    onsets = deepcopy(onsets),\n",
    "                    durations = deepcopy(durations),\n",
    "                    amplitudes = deepcopy(amplitudes),\n",
    "                    tmod = None,\n",
    "                    pmod = None,\n",
    "                    regressor_names = None,\n",
    "                    regressors = None))\n",
    "\n",
    "print output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Bunch(amplitudes=[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]], conditions=['fixed_bin1', 'fixed_bin2', 'fixed_bin3', 'all_remaining'], durations=[[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0], [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0], [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0], [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0]], onsets=[[3.2155, 8.232, 28.2311, 33.2312, 53.2303, 63.23, 75.7296, 95.729, 108.2285, 138.2276, 153.2271, 160.7269, 173.2265, 190.7261, 198.2257, 215.7251, 233.2246], [245.7242, 250.724, 263.2236, 273.2233, 295.7226, 363.2204, 707.2164], [388.2197, 397.2264, 402.2263, 412.2259, 434.7251, 444.7248, 452.2245, 472.2239, 492.2232, 504.7229, 509.7227, 522.2223, 529.7221, 542.2217, 547.2215, 554.7213, 562.221, 572.2207, 582.2204, 587.2202, 599.7198, 637.2186, 647.2183, 659.7179, 667.2177, 722.2159, 727.2158, 752.2317], [3.2155, 8.232, 10.7319, 13.2318, 15.7317, 18.2316, 20.7315, 23.2313, 28.2311, 33.2312, 35.7311, 38.231, 40.7309, 43.2307, 45.7306, 48.2305, 53.2303, 55.7302, 58.2302, 63.23, 65.7299, 68.2298, 70.7298, 75.7296, 78.2295, 80.7296, 83.2294, 85.7293, 88.2292, 90.7291, 95.729, 98.2289, 100.7288, 103.2287, 108.2285, 110.7285, 113.2284, 115.7283, 118.2282, 120.7281, 123.2281, 125.728, 128.2279, 130.7278, 133.2277, 138.2276, 140.7275, 143.2276, 145.7273, 148.2273, 153.2271, 155.727, 160.7269, 163.2268, 165.7267, 168.2267, 173.2265, 175.7264, 178.2263, 180.7262, 183.2262, 185.7261, 190.7261, 193.226, 198.2257, 200.7256, 203.2255, 205.7254, 208.2254, 210.7253, 215.7251, 218.225, 220.725, 223.2249, 225.7248, 228.2247, 233.2246, 235.7245, 238.2244, 240.7243, 245.7242, 250.724, 253.2239, 255.7238, 258.2238, 263.2236, 265.7235, 268.2235, 273.2233, 275.7232, 278.2232, 280.7231, 283.223, 285.7229, 288.2228, 290.7228, 295.7226, 298.2225, 300.7224, 303.2223, 305.7222, 308.2222, 310.7221, 313.222, 315.7219, 318.2219, 320.7218, 323.2217, 325.7216, 328.2216, 330.7215, 333.2214, 335.7213, 338.2212, 340.7211, 343.2211, 345.721, 348.2209, 350.721, 353.2207, 358.2206, 363.2204, 365.7204, 368.2203, 370.7202, 375.72, 378.22, 380.7199, 383.2198, 388.2197, 393.2195, 395.7194, 398.2193, 397.2264, 402.2263, 404.7262, 407.2261, 412.2259, 414.7259, 417.2256, 419.7256, 422.2255, 424.7254, 427.2253, 429.7252, 434.7251, 437.225, 439.7249, 444.7248, 447.2247, 452.2245, 454.7245, 457.2244, 459.7243, 462.2242, 464.7241, 467.2241, 472.2239, 474.7238, 477.2237, 479.7237, 482.2236, 484.7235, 487.2234, 492.2232, 494.7232, 497.2231, 499.723, 504.7229, 509.7227, 512.2226, 514.7225, 517.2224, 522.2223, 524.7222, 529.7221, 532.222, 534.7219, 537.2218, 542.2217, 547.2215, 549.7214, 554.7213, 557.2212, 562.221, 564.7209, 567.2208, 572.2207, 574.7206, 577.2205, 582.2204, 587.2202, 589.7202, 592.2201, 594.72, 599.7198, 602.2198, 604.7197, 607.2196, 609.7195, 612.2194, 614.7193, 617.2193, 619.7192, 622.2191, 624.719, 627.219, 629.7189, 632.2188, 637.2186, 639.7185, 642.2185, 647.2183, 649.7182, 652.2182, 654.7181, 659.7179, 662.2178, 667.2177, 669.7176, 672.2175, 674.7174, 677.2174, 679.7173, 682.2172, 684.7171, 687.2171, 689.717, 692.2169, 694.7168, 697.2167, 699.7167, 702.2166, 707.2164, 709.7163, 712.2163, 717.2161, 722.2159, 727.2158, 729.7157, 732.2156, 734.7156, 737.2155, 739.7154, 742.232, 744.7319, 747.2318, 752.2317, 754.7316, 757.2315, 759.7314, 762.2313, 764.7313, 767.2312, 769.7311, 772.231, 774.731, 777.2309, 779.7308, 782.2307, 784.7306, 787.2305, 789.7305, 792.2304, 20.7315, 45.7306, 120.7281, 128.2279, 178.2263, 205.7254, 223.2249, 280.7231, 308.2222, 318.2219, 325.7216, 340.7211, 350.721, 355.7207, 390.7195, 424.7254, 457.2244, 477.2237, 614.7193, 624.719, 674.7174, 682.2172, 694.7168, 742.232, 772.231, 782.2307]], pmod=None, regressor_names=None, regressors=None, tmod=None)]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from nipype.interfaces.base import Bunch\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "base_proj_dir = '/home/data/madlab/data/mri/wmaze/scanner_behav'\n",
    "output = []\n",
    "\n",
    "subject_id = 'WMAZE_001'\n",
    "curr_set = 1\n",
    "names = []\n",
    "onsets = []\n",
    "durations = []\n",
    "amplitudes = []\n",
    "\n",
    "\n",
    "data_fixed_bin1 = np.genfromtxt(base_proj_dir + \n",
    "                                '/{0}/MRthesis/model_learn1_curve/EVs/set{1}_fixed_bin_1.txt'.format(subject_id, curr_set), \n",
    "                                dtype = str)\n",
    "\n",
    "data_fixed_bin2 = np.genfromtxt(base_proj_dir + \n",
    "                                '/{0}/MRthesis/model_learn1_curve/EVs/set{1}_fixed_bin_2.txt'.format(subject_id, curr_set), \n",
    "                                dtype = str)\n",
    "\n",
    "data_fixed_bin3 = np.genfromtxt(base_proj_dir + \n",
    "                                '/{0}/MRthesis/model_learn1_curve/EVs/set{1}_fixed_bin_3.txt'.format(subject_id, curr_set), \n",
    "                                dtype = str)\n",
    "\n",
    "data_all_remaining = np.genfromtxt(base_proj_dir + \n",
    "                            '/{0}/MRthesis/model_learn1_curve/EVs/set{1}_all_remaining_FB4C.txt'.format(subject_id, curr_set), \n",
    "                                   dtype = str)  \n",
    "\n",
    "\n",
    "sequence = ['bin1', 'bin2', 'bin3']\n",
    "for curr_type in sequence:\n",
    "    array_name = eval('data_fixed_{0}'.format(curr_type))\n",
    "    curr_names = ['fixed_{0}'.format(curr_type)]\n",
    "    if array_name.size > 0: #MORE THAN ONE TRIAL\n",
    "        #print array_name.shape        \n",
    "        curr_onsets = map(float, array_name[:,0])\n",
    "        curr_durations = map(float, array_name[:,1])\n",
    "        curr_amplitudes = map(float, array_name[:,2])\n",
    "        \n",
    "        curr_onsets = [curr_onsets]\n",
    "        curr_durations = [curr_durations]\n",
    "        curr_amplitudes = [curr_amplitudes]\n",
    "\n",
    "    elif array_name.size == 3: #ONLY ONE ERROR \n",
    "        curr_onsets = [float(array_name[0])]\n",
    "        curr_durations = [float(array_name[1])]\n",
    "        curr_amplitudes = [float(array_name[2])]\n",
    "    \n",
    "        curr_onsets = [curr_onsets]\n",
    "        curr_durations = [curr_durations]\n",
    "        curr_amplitudes = [curr_amplitudes]\n",
    "\n",
    "    \n",
    "    names.append(curr_names) \n",
    "    onsets.append(curr_onsets)\n",
    "    durations.append(curr_durations)\n",
    "    amplitudes.append(curr_amplitudes)\n",
    "\n",
    "curr_names = ['all_remaining']\n",
    "curr_onsets = map(float, data_all_remaining[:,0])\n",
    "curr_durations = map(float, data_all_remaining[:,1])\n",
    "curr_amplitudes = map(float, data_all_remaining[:,2])\n",
    "\n",
    "curr_onsets = [curr_onsets]\n",
    "curr_durations = [curr_durations]\n",
    "curr_amplitudes = [curr_amplitudes] \n",
    "\n",
    "\n",
    "names.append(curr_names)  \n",
    "onsets.append(curr_onsets)\n",
    "durations.append(curr_durations)\n",
    "amplitudes.append(curr_amplitudes)  \n",
    "\n",
    "\n",
    "# If any element in names is a list instead of a single value, for those elements\n",
    "if any(isinstance(el, list) for el in names):\n",
    "    # Unpacks subarrays into one mega array!\n",
    "    names = [el for sublist in names for el in sublist]  \n",
    "if any(isinstance(el, list) for el in onsets):\n",
    "    onsets = [el_o for sublist_o in onsets for el_o in sublist_o]\n",
    "if any(isinstance(el, list) for el in durations):\n",
    "    durations = [el_d for sublist_d in durations for el_d in sublist_d]\n",
    "if any(isinstance(el, list) for el in amplitudes):\n",
    "    amplitudes = [el_a for sublist_a in amplitudes for el_a in sublist_a]\n",
    "\n",
    "\n",
    "output.insert(curr_set,\n",
    "              Bunch(conditions = names,\n",
    "                    onsets = deepcopy(onsets),\n",
    "                    durations = deepcopy(durations),\n",
    "                    amplitudes = deepcopy(amplitudes),\n",
    "                    tmod = None,\n",
    "                    pmod = None,\n",
    "                    regressor_names = None,\n",
    "                    regressors = None))\n",
    "print output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "info = output\n",
    "contrasts = []\n",
    "j = info[0]\n",
    "cont_all = ['AllVsBase', 'T', j.conditions, [1. / len(j.conditions)] * len(j.conditions)]\n",
    "contrasts.append(cont_all)\n",
    "# For each EV list name received from the bunch\n",
    "for curr_cond in j.conditions:\n",
    "    curr_cont = [curr_cond, 'T', [curr_cond], [1]]\n",
    "    contrasts.append(curr_cont)\n",
    "\n",
    "# contrasts between individual bins    \n",
    "if 'learning_bin1' in j.conditions and 'learning_bin2' in j.conditions:\n",
    "    cont_bin1_vs_bin2 = ['bin1_minus_bin2', 'T', ['learning_bin1','learning_bin2'], [1, -1]]\n",
    "    cont_bin2_vs_bin1 = ['bin2_minus_bin1', 'T', ['learning_bin2','learning_bin1'], [1, -1]]\n",
    "    contrasts.append(cont_bin1_vs_bin2)\n",
    "    contrasts.append(cont_bin2_vs_bin1)\n",
    "if 'learning_bin1' in j.conditions and 'learning_bin3' in j.conditions:\n",
    "    cont_bin1_vs_bin3 = ['bin1_minus_bin3', 'T', ['learning_bin1','learning_bin3'], [1, -1]]\n",
    "    cont_bin3_vs_bin1 = ['bin3_minus_bin1', 'T', ['learning_bin3','learning_bin1'], [1, -1]]\n",
    "    contrasts.append(cont_bin1_vs_bin3)\n",
    "    contrasts.append(cont_bin3_vs_bin1)\n",
    "if 'learning_bin1' in j.conditions and 'learning_bin4' in j.conditions:\n",
    "    cont_bin1_vs_bin4 = ['bin1_minus_bin4', 'T', ['learning_bin1','learning_bin4'], [1, -1]]\n",
    "    cont_bin4_vs_bin1 = ['bin4_minus_bin1', 'T', ['learning_bin4','learning_bin1'], [1, -1]]\n",
    "    contrasts.append(cont_bin1_vs_bin4)\n",
    "    contrasts.append(cont_bin4_vs_bin1)\n",
    "if 'learning_bin2' in j.conditions and 'learning_bin3' in j.conditions:\n",
    "    cont_bin2_vs_bin3 = ['bin2_minus_bin3', 'T', ['learning_bin2','learning_bin3'], [1, -1]]\n",
    "    cont_bin3_vs_bin2 = ['bin3_minus_bin2', 'T', ['learning_bin3','learning_bin2'], [1, -1]]\n",
    "    contrasts.append(cont_bin2_vs_bin3)\n",
    "    contrasts.append(cont_bin3_vs_bin2)\n",
    "if 'learning_bin2' in j.conditions and 'learning_bin4' in j.conditions:\n",
    "    cont_bin2_vs_bin4 = ['bin2_minus_bin4', 'T', ['learning_bin2','learning_bin4'], [1, -1]]\n",
    "    cont_bin4_vs_bin2 = ['bin4_minus_bin2', 'T', ['learning_bin4','learning_bin2'], [1, -1]]\n",
    "    contrasts.append(cont_bin2_vs_bin4)\n",
    "    contrasts.append(cont_bin4_vs_bin2)\n",
    "if 'learning_bin3' in j.conditions and 'learning_bin4' in j.conditions:\n",
    "    cont_bin3_vs_bin4 = ['bin3_minus_bin4', 'T', ['learning_bin3','learning_bin4'], [1, -1]]\n",
    "    cont_bin4_vs_bin3 = ['bin4_minus_bin3', 'T', ['learning_bin4','learning_bin3'], [1, -1]]\n",
    "    contrasts.append(cont_bin3_vs_bin4)\n",
    "    contrasts.append(cont_bin4_vs_bin3)\t\n",
    "if 'learning_bin1' in j.conditions and 'learning_bin2' in j.conditions and 'learning_bin3' in j.conditions and 'learning_bin4' in j.conditions:\n",
    "    cont_low_vs_high = ['low_minus_high', 'T', ['learning_bin1','learning_bin2','learning_bin3','learning_bin4'], [.5,.5,-.5,-.5]]\n",
    "    cont_high_vs_low = ['high_minus_low', 'T', ['learning_bin1','learning_bin2','learning_bin3','learning_bin4'], [-.5,-.5,.5,.5]]\n",
    "    cont_out_vs_mid = ['out_minus_mid', 'T', ['learning_bin1','learning_bin2','learning_bin3','learning_bin4'], [.5,-.5,-.5,.5]]\n",
    "    cont_mid_vs_out = ['mid_minus_out', 'T', ['learning_bin1','learning_bin2','learning_bin3','learning_bin4'], [-.5,.5,.5,-.5]]\n",
    "    contrasts.append(cont_low_vs_high)\n",
    "    contrasts.append(cont_high_vs_low)\n",
    "    contrasts.append(cont_out_vs_mid)\n",
    "    contrasts.append(cont_mid_vs_out)\n",
    "print contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cons = contrasts\n",
    "subs = []\n",
    "# For each contrast in the set\n",
    "for i, con in enumerate(cons):\n",
    "   # Append a tuple containing \"cope#\" and \"cope#+name\" \n",
    "   subs.append(('cope%d.'%(i + 1), 'cope%02d_%s.'%(i + 1, con[0])))\n",
    "   subs.append(('varcope%d.'%(i + 1), 'varcope%02d_%s.'%(i + 1, con[0])))\n",
    "   subs.append(('zstat%d.'%(i + 1), 'zstat%02d_%s.'%(i + 1, con[0])))\n",
    "   subs.append(('tstat%d.'%(i + 1), 'tstat%02d_%s.'%(i + 1, con[0])))        \n",
    "print subs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "subjinfo = [Bunch(amplitudes=[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], \n",
    "                          [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], \n",
    "                          [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], \n",
    "                          [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], \n",
    "                          [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
    "                           1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, \n",
    "                           1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, \n",
    "                           1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, \n",
    "                           1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, \n",
    "                           1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, \n",
    "                           1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, \n",
    "                           1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, \n",
    "                           1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, \n",
    "                           1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, \n",
    "                           1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, \n",
    "                           1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, \n",
    "                           1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, \n",
    "                           1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, \n",
    "                           1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]], \n",
    "              conditions=['learning_bin1', 'learning_bin2', 'learning_bin3', 'learning_bin4', 'all_remaining'], \n",
    "              durations=[[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0], \n",
    "                         [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0], \n",
    "                         [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0], \n",
    "                         [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0], \n",
    "                         [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, \n",
    "                          3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, \n",
    "                          3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, \n",
    "                          3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, \n",
    "                          3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, \n",
    "                          3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0,\n",
    "                          3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, \n",
    "                          3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, \n",
    "                          3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0,\n",
    "                          3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, \n",
    "                          3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, \n",
    "                          3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, \n",
    "                          3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, \n",
    "                          3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, \n",
    "                          3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0]], \n",
    "              onsets=[[3.2155, 8.232, 28.2311, 33.2312, 53.2303, 63.23, 75.7296, 95.729, 108.2285, 138.2276, 153.2271, \n",
    "                       160.7269, 173.2265], \n",
    "                      [190.7261, 198.2257, 215.7251, 233.2246, 245.7242, 250.724, 263.2236, 273.2233, 295.7226,\n",
    "                       363.2204, 375.72, 388.2197, 706.436, 716.4357], \n",
    "                      [396.446, 401.4458, 411.4455, 433.9447, 443.9444, 451.4441, 636.4382, 646.4379, 658.9375, \n",
    "                       666.4372, 721.4355, 726.4354, 751.4512], \n",
    "                      [471.4435, 491.4428, 503.9424, 508.9423, 521.4418, 528.9416, 541.4412, 546.4411, 553.9408, \n",
    "                       561.4406, 571.4403, 581.4399, 586.4398, 598.9394], \n",
    "                      [3.2155, 8.232, 13.2318, 15.7317, 18.2316, 20.7315, 23.2313, 28.2311, 33.2312, 38.231, 40.7309, \n",
    "                       43.2307, 45.7306, 48.2305, 53.2303, 58.2302, 60.7301, 63.23, 68.2298, 70.7298, 73.2297, 75.7296, \n",
    "                       80.7296, 83.2294, 85.7293, 88.2292, 90.7291, 93.229, 95.729, 100.7288, 103.2287, 105.7286, \n",
    "                       108.2285, 113.2284, 115.7283, 118.2282, 120.7281, 123.2281, 128.2279, 130.7278, 133.2277, \n",
    "                       135.7277, 138.2276, 143.2276, 145.7273, 148.2273, 150.7272, 153.2271, 158.2269, 160.7269, \n",
    "                       163.2268, 165.7267, 168.2267, 170.7265, 173.2265, 178.2263, 180.7262, 185.7261, 188.2262, \n",
    "                       190.7261, 193.226, 195.7257, 198.2257, 203.2255, 205.7254, 208.2254, 213.2252, 215.7251, 220.725, \n",
    "                       223.2249, 225.7248, 230.7246, 233.2246, 238.2244, 240.7243, 243.2242, 245.7242, 250.724, 255.7238,\n",
    "                       258.2238, 260.7237, 263.2236, 265.7235, 268.2235, 273.2233, 278.2232, 280.7231, 283.223, 288.2228,\n",
    "                       290.7228, 293.2226, 295.7226, 298.2225, 300.7224, 303.2223, 305.7222, 308.2222, 310.7221, 313.222,\n",
    "                       315.7219, 318.2219, 320.7218, 325.7216, 328.2216, 333.2214, 335.7213, 338.2212, 340.7211, \n",
    "                       343.2211, 348.2209, 350.721, 353.2207, 363.2204, 365.7204, 368.2203, 370.7202, 373.2201, 375.72, \n",
    "                       380.7199, 383.2198, 385.7197, 388.2197, 393.2195, 398.2193, 393.9294, 396.446, 401.4458, 406.4457, \n",
    "                       408.9456, 411.4455, 413.9454, 416.4452, 418.9451, 421.445, 423.945, 426.4449, 428.9448, 431.4447, \n",
    "                       433.9447, 438.9445, 441.4444, 443.9444, 448.9442, 451.4441, 456.4439, 458.9439, 463.9437, \n",
    "                       466.4436, 468.9435, 471.4435, 476.4433, 478.9432, 481.4431, 483.9431, 486.443, 488.9429, \n",
    "                       491.4428, 493.9427, 496.4426, 498.9426, 501.4425, 503.9424, 508.9423, 513.9421, 516.442, \n",
    "                       518.9419, 521.4418, 523.9418, 526.4417, 528.9416, 533.9415, 536.4414, 538.9413, 541.4412, \n",
    "                       546.4411, 551.4409, 553.9408, 558.9407, 561.4406, 566.4404, 568.9404, 571.4403, 573.9401, \n",
    "                       576.4401, 578.94, 581.4399, 586.4398, 588.9397, 591.4396, 593.9396, 596.4395, 598.9394, 603.9392, \n",
    "                       606.4392, 608.9391, 611.439, 613.9389, 616.4388, 621.4387, 623.9386, 631.4384, 633.9383, \n",
    "                       636.4382, 641.438, 643.9379, 646.4379, 651.4377, 653.9376, 656.4376, 658.9375, 663.9373, \n",
    "                       666.4372, 671.4371, 673.937, 676.4369, 681.4368, 683.9367, 686.4366, 688.9365, 691.4364, \n",
    "                       693.9364, 696.4363, 701.4361, 703.9361, 706.436, 711.4358, 713.9357, 716.4357, 721.4355, \n",
    "                       726.4354, 728.9353, 731.4352, 733.9351, 736.435, 738.935, 741.4515, 743.9515, 746.4514, \n",
    "                       748.9513, 751.4512, 753.9511, 756.4511, 758.951, 761.4509, 763.9508, 766.4508, 768.9507, \n",
    "                       771.4506, 773.9505, 778.9504, 781.4503, 783.9502, 788.95, 791.45]], \n",
    "              pmod=None, \n",
    "              regressor_names=None, \n",
    "              regressors=None, \n",
    "              tmod=None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subjinfo = info\n",
    "regressor_file = '/home/data/madlab/data/mri/wmaze/preproc/WMAZE_001/noise/set1_merged_filter_regressors.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print type(subjinfo)\n",
    "print type(regressor_file)\n",
    "#print info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#index Bunch so it will not act like a list\n",
    "subjinfo = subjinfo[0]\n",
    "\n",
    "motion_noise_params = []\n",
    "motion_noi_par_names = ['Pitch (rad)', 'Roll (rad)', 'Yaw (rad)', \n",
    "                        'Tx (mm)', 'Ty (mm)', 'Tz (mm)',\n",
    "                        'Pitch_1d', 'Roll_1d', 'Yaw_1d', \n",
    "                        'Tx_1d', 'Ty_1d', 'Tz_1d',\n",
    "                        'Norm (mm)', \n",
    "                        'LG_1stOrd', 'LG_2ndOrd', 'LG_3rdOrd', 'LG_4thOrd']\n",
    "\n",
    "#open the filter regressor file as a numpy array\n",
    "motion_noise_file = np.genfromtxt(regressor_file)\n",
    "\n",
    "#append an empty array for each column of the filter regressor file\n",
    "for param_column in range(motion_noise_file.shape[1]):    \n",
    "    motion_noise_params.append([])\n",
    "\n",
    "#if there are more than 17 columns in the filter regressors file\n",
    "#create a new column name and append it to the names array\n",
    "if motion_noise_file.shape[1] > 17:\n",
    "    for num_out in range(motion_noise_file.shape[1] - 17):\n",
    "        out_name = 'out_{0}'.format(num_out + 1)\n",
    "        motion_noi_par_names.append(out_name)\n",
    "\n",
    "#get the motion noise params in their respective arrays \n",
    "for param_num in range(motion_noise_file.shape[1]):\n",
    "    motion_noise_params[param_num] = motion_noise_file[:, param_num].tolist()\n",
    "\n",
    "#make these parameteres into arrays to allow appending\n",
    "if subjinfo.regressor_names == None: \n",
    "    subjinfo.regressor_names = []\n",
    "if subjinfo.regressors == None: \n",
    "    subjinfo.regressors = []\n",
    "\n",
    "#iterate through names to append names and param arrays individually (otherwise you get weird nested arrays)    \n",
    "for i, curr_name in enumerate(motion_noi_par_names):\n",
    "    subjinfo.regressor_names.append(motion_noi_par_names[i])\n",
    "    subjinfo.regressors.append(motion_noise_params[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print subjinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "motion_noise_params = []\n",
    "motion_noi_par_names = []\n",
    "\n",
    "# If each instance of files is not a list, make it one\n",
    "if not isinstance(regressor_file, list):\n",
    "    regressor_file = [regressor_file]\n",
    "# If each instance of subjinfo is not a list, make it one\n",
    "if not isinstance(subjinfo, list):\n",
    "    subjinfo = [subjinfo]\n",
    "    \n",
    "# For each instance of files\n",
    "for j,i in enumerate(regressor_file):\n",
    "    curr_mot_noi_par_names = ['Pitch (rad)', 'Roll (rad)', 'Yaw (rad)', \n",
    "                              'Tx (mm)', 'Ty (mm)', 'Tz (mm)',\n",
    "                              'Pitch_1d', 'Roll_1d', 'Yaw_1d', \n",
    "                              'Tx_1d', 'Ty_1d', 'Tz_1d',\n",
    "                              'Norm (mm)', \n",
    "                              'LG_1stOrd', 'LG_2ndOrd', 'LG_3rdOrd', 'LG_4thOrd']\n",
    "    # Numpy array of each motion noise files\n",
    "    a_orig = np.genfromtxt(i)\n",
    "    a = a_orig[:-3]\n",
    "    motion_noise_params.append([[]] * a.shape[1])\n",
    "    #print motion_noise_params\n",
    "    # If there are more than 17 motion noise parameters\n",
    "    if a.shape[1] > 17:\n",
    "        # For those additional noise parameters over 17\n",
    "        for num_out in range(a.shape[1] - 17):\n",
    "            # Give it a name\n",
    "            out_name = 'out_{0}'.format(num_out + 1)\n",
    "            curr_mot_noi_par_names.append(out_name)\n",
    "    # For each instance in the second column of a\n",
    "    for z in range(a.shape[1]):\n",
    "        motion_noise_params[j][z] = a[:, z].tolist()\n",
    "    motion_noi_par_names.append(curr_mot_noi_par_names)\n",
    "    #print motion_noi_par_names\n",
    "#print subjinfo    \n",
    "# For each instace of subjinfo   \n",
    "#print motion_noise_params\n",
    "for j,i in enumerate(subjinfo):\n",
    "    # If there are are no regressor names\n",
    "    if i.regressor_names == None: \n",
    "        i.regressor_names = []\n",
    "    #print i.regressor_names\n",
    "    # If there are no regressors\n",
    "    if i.regressors == None: \n",
    "        i.regressors = []\n",
    "    \n",
    "    # For each instance of motion_noise_params in the current iteration of subjinfo\n",
    "    for j3, i3 in enumerate(motion_noise_params[j]):\n",
    "        i.regressor_names.append(motion_noi_par_names[j][j3])\n",
    "        #print i.regressor_names\n",
    "        i.regressors.append(i3)          \n",
    "print subjinfo[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
