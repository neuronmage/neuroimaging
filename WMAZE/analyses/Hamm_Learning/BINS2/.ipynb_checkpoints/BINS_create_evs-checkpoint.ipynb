{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model BINS\n",
    "## Learning --> 3 bins based on learning curve\n",
    "## Fixed & Conditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import shutil \n",
    "import os\n",
    "from os.path import join, split, basename\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from pylab import *\n",
    "\n",
    "#subs = ['WMAZE_001']\n",
    "\n",
    "subs = ['WMAZE_001', 'WMAZE_002', 'WMAZE_004', 'WMAZE_005', 'WMAZE_006',\n",
    "        'WMAZE_007', 'WMAZE_008', 'WMAZE_009', 'WMAZE_010', 'WMAZE_012',\n",
    "        'WMAZE_017', 'WMAZE_018', 'WMAZE_019', 'WMAZE_020', 'WMAZE_021',\n",
    "        'WMAZE_022', 'WMAZE_023', 'WMAZE_024', 'WMAZE_026', 'WMAZE_027']\n",
    "sets = ['set1', 'set2', 'set3']\n",
    "\n",
    "for sub in subs:\n",
    "    sub_dir = '/home/data/madlab/Mattfeld_WMAZE/sourcedata/behav/{0}'.format(sub) #base directory    \n",
    "    behav_runs = sorted(glob(join(sub_dir, '{0}_wmazebl_2015*.txt'.format(sub)))) #behavioral files\n",
    "    frst_deriv_files = sorted(glob(join(sub_dir, 'Bprime_pmode_set*.txt'))) #derivative files       \n",
    "    learning_files = sorted(glob(join(sub_dir, 'B_pmode_set*.txt'))) #learning curve         \n",
    "    \n",
    "    for i, curr_set in enumerate(sets):\n",
    "        deriv_file = np.loadtxt(frst_deriv_files[i])\n",
    "        learning_curve = np.loadtxt(learning_files[i])      \n",
    "        behav_run1 = pd.read_table(behav_runs[i*2])\n",
    "        behav_run2 = pd.read_table(behav_runs[i*2+1]) \n",
    "\n",
    "        behav_os = np.empty(320, dtype=object)\n",
    "        behav_os[:160] = behav_run1['StimOnset'].values\n",
    "        behav_os[160:] = behav_run2['StimOnset'].values + (197*2) #number of volumes x TR \n",
    "\n",
    "        behav_resp = np.empty(320, dtype=object)\n",
    "        behav_resp[:160] = behav_run1['Resp'].values\n",
    "        behav_resp[160:] = behav_run2['Resp'].values\n",
    "\n",
    "        behav_type = np.empty(320, dtype=object)\n",
    "        behav_type[:160] = behav_run1['TrialType'].values\n",
    "        behav_type[160:] = behav_run2['TrialType'].values\n",
    "        \n",
    "        trial_shift = behav_type[:-1] \n",
    "        trial_shift = np.insert(trial_shift,0,-1) #brings everything down 1 to match orig, places -1 at [0]\n",
    "        trial_shift2 = behav_type[1:] \n",
    "        trial_shift2 = np.append(trial_shift2,-1) #brings everything up 1 to match orig, appends -1 to last index      \n",
    "                \n",
    "               \n",
    "        ##GET ALL B's, CREATE LIST OF BAD B TRIAL INDICES\n",
    "        b_indices = np.where((behav_type=='B'))[0] #indices of all Bs in original dataset w/o BL trials\n",
    "        b_BL_indices = np.where((behav_type=='B')&(trial_shift=='BL'))[0] #grabs B trials with preceeding BLs\n",
    "        bad_Bs = [] \n",
    "        bad_Bs.extend(b_BL_indices)\n",
    "        for curr_B in b_indices: #isolate bad Bs for removal in learning curve/derivative\n",
    "            if not curr_B in bad_Bs:\n",
    "                if behav_resp[curr_B]=='NR': #identify in B trials which are non-response\n",
    "                    bad_Bs.append(curr_B)   \n",
    "                if curr_B in [0,157,158,159,160,317,318,319]: #first and last 3 Bs per run\n",
    "                    bad_Bs.append(curr_B)\n",
    "        bad_Bs.sort()     \n",
    "        bad_B_ind = sorted([j for j, f in enumerate(b_indices) if f in bad_Bs])  #get indices for bad Bs within group of Bs   \n",
    "        bad_B_ind = bad_B_ind[::-1] #reverse order of Bs to be removed\n",
    "        bad_B_onsets = behav_os[bad_Bs]\n",
    "        \n",
    "        ##All remaining for FIXED Analysis##\n",
    "        all_remaining_FIXED = np.where((trial_shift2!='B')|(behav_type=='BL')) #get all trials not before Bs, also baselines \n",
    "        all_remaining_FIXED_onsets = behav_os[all_remaining_FIXED[0]] \n",
    "        all_remaining_FIXED_mtrx = np.vstack((all_remaining_FIXED_onsets, np.ones(len(all_remaining_FIXED_onsets))*2.5,\n",
    "                                              np.ones(len(all_remaining_FIXED_onsets)))).T\n",
    "        ##All remaining for COND Analysis##\n",
    "        all_remaining_COND = np.where((behav_type!='B')) #get everything that isn't B   \n",
    "        all_remaining_COND_onsets = behav_os[all_remaining_COND[0]]\n",
    "        all_remaining_COND_onsets = sorted(np.hstack((all_remaining_COND_onsets, bad_B_onsets)))\n",
    "        all_remaining_COND_mtrx = np.vstack((all_remaining_COND_onsets, np.ones(len(all_remaining_COND_onsets))*2.5,\n",
    "                                             np.ones(len(all_remaining_COND_onsets)))).T\n",
    "        \n",
    "                              \n",
    "        ###LEARNING CURVE FILES\n",
    "        temp = list(learning_curve[:-1]) #create a temp learning_curve\n",
    "        for curr_bad_B in bad_B_ind: #pop out the bad Bs\n",
    "            temp.pop(curr_bad_B)  \n",
    "        new_learning_val = np.array(temp) ##learning curve values for good_Bs indices\n",
    "        sort_learning_indices = np.argsort(new_learning_val) ##provides sorted indices from low to high \n",
    "        \n",
    "        ##CREATE NEW LIST OF B INDICES WITH BAD B INDICES REMOVED\n",
    "        temp1 = list(b_indices)\n",
    "        for curr_bad_B in bad_B_ind:\n",
    "            temp1.pop(curr_bad_B) #remove the bad Bs from the B-list\n",
    "        good_Bs = np.array(temp1) #index (original behavior file) for good B trials \n",
    "        learning_ind = good_Bs[sort_learning_indices]   \n",
    "        \n",
    "        #divide corrected learning curve into 3 bins\n",
    "        l_bin1 = sorted(learning_ind[:len(learning_ind)/3])\n",
    "        l_bin2 = sorted(learning_ind[len(learning_ind)/3:len(learning_ind)*2/3])\n",
    "        l_bin3 = sorted(learning_ind[len(learning_ind)*2/3:])        \n",
    "          \n",
    "        ####COND####\n",
    "                \n",
    "        #get onsets for trials in each bin\n",
    "        cond_bin1_onsets = behav_os[l_bin1]\n",
    "        cond_bin2_onsets = behav_os[l_bin2]\n",
    "        cond_bin3_onsets = behav_os[l_bin3]\n",
    "        \n",
    "        #use v-stack to vertically stack onsets, duration, & amplitude\n",
    "        cond_mtrx = np.vstack((behav_os,np.ones(len(behav_os))*2.5,np.ones(len(behav_os)))).T   \n",
    "        cond_bin1_mtrx = np.vstack((cond_bin1_onsets,np.ones(len(cond_bin1_onsets))*2.5,np.ones(len(cond_bin1_onsets)))).T\n",
    "        cond_bin2_mtrx = np.vstack((cond_bin2_onsets,np.ones(len(cond_bin2_onsets))*2.5,np.ones(len(cond_bin2_onsets)))).T        \n",
    "        cond_bin3_mtrx = np.vstack((cond_bin3_onsets,np.ones(len(cond_bin3_onsets))*2.5,np.ones(len(cond_bin3_onsets)))).T  \n",
    "        \n",
    "        ####FIXED####\n",
    "        \n",
    "        #subtract 1 from each value to get index of the fixed preceding\n",
    "        fixed_bin1_ind = [x - 1 for x in l_bin1]\n",
    "        fixed_bin2_ind = [x - 1 for x in l_bin2]\n",
    "        fixed_bin3_ind = [x - 1 for x in l_bin3]\n",
    "        \n",
    "        #get onsets for trials in each bin\n",
    "        fixed_bin1_onsets = behav_os[fixed_bin1_ind]\n",
    "        fixed_bin2_onsets = behav_os[fixed_bin2_ind]\n",
    "        fixed_bin3_onsets = behav_os[fixed_bin3_ind]\n",
    "        \n",
    "        #use v-stack to vertically stack onsets, duration, & amplitude\n",
    "        fixed_mtrx = np.vstack((behav_os,np.ones(len(behav_os))*2.5,np.ones(len(behav_os)))).T   \n",
    "        fixed_bin1_mtrx = np.vstack((fixed_bin1_onsets,np.ones(len(fixed_bin1_onsets))*2.5,np.ones(len(fixed_bin1_onsets)))).T\n",
    "        fixed_bin2_mtrx = np.vstack((fixed_bin2_onsets,np.ones(len(fixed_bin2_onsets))*2.5,np.ones(len(fixed_bin2_onsets)))).T        \n",
    "        fixed_bin3_mtrx = np.vstack((fixed_bin3_onsets,np.ones(len(fixed_bin3_onsets))*2.5,np.ones(len(fixed_bin3_onsets)))).T              \n",
    "\n",
    "        if not os.path.exists(join(sub_dir, 'model_BINS/')):\n",
    "            os.makedirs(join(sub_dir, 'model_BINS/'))\n",
    "        \n",
    "        #write EVs to .txt file\n",
    "        for trial in ['cond', 'cond_bin1', 'cond_bin2', 'cond_bin3', 'all_remaining_COND',\n",
    "                      'fixed', 'fixed_bin1', 'fixed_bin2', 'fixed_bin3', 'all_remaining_FIXED']: \n",
    "            exec('np.savetxt(sub_dir+\"/model_BINS/\"+\"{0}_{1}.txt\",{1}_mtrx,delimiter=\"\\t\",fmt=\"%.4f\")'.format(curr_set,trial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
