{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 3 1-3-2\n",
    "### Contains only fixed-before-conditional trials without intervening BLs\n",
    "### Combines A & C trials into single regressor\n",
    "### Accounts for last three noisy volumes in Lvl 1 analysis (FSL ROI -- ExtractROI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compares activation for regions of interest using binarized masks:\n",
    "### Hippocampus (FS labels: hippocampus [17, 53])\n",
    "### Dorsal caudate (hand-drawn by Mandy)\n",
    "### Putamen (FS labels: putamen [12, 51])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import nibabel as nb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_palette('muted')\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "sids = ['WMAZE_001', 'WMAZE_002', 'WMAZE_004', 'WMAZE_005', 'WMAZE_006', \n",
    "        'WMAZE_007', 'WMAZE_008', 'WMAZE_009', 'WMAZE_010', 'WMAZE_012', \n",
    "        'WMAZE_017', 'WMAZE_018', 'WMAZE_019', 'WMAZE_020', 'WMAZE_021',  \n",
    "        'WMAZE_022', 'WMAZE_023', 'WMAZE_024', 'WMAZE_026', 'WMAZE_027']\n",
    "#sids = ['WMAZE_001']\n",
    "\n",
    "proj_dir = '/home/data/madlab/data/mri/wmaze'\n",
    " \n",
    "mask_filenames = []\n",
    "cope_files = []\n",
    "\n",
    "for SID in sids:\n",
    "    mask_filenames_glob = glob(proj_dir + '/roi_analysis/MRthesis/fb4c_2/mask/anat_masks/_subject_id_' \n",
    "                               + SID + '/_anatmask_xfm*/*')\n",
    "    mask_filenames_glob.sort()\n",
    "    mask_filenames.append(mask_filenames_glob)\n",
    "        \n",
    "    subjcopes_glob = glob(proj_dir + '/scndlvl/wmaze_MRthesis/fixed_before_conditional/model3_1-3-2/' \n",
    "                          + SID + '/fixedfx/cope_*')\n",
    "    subjcopes_glob.sort()\n",
    "    cope_files.append(subjcopes_glob)\n",
    "    if len(cope_files[-1]) == 0 or len(cope_files[-1]) != 5:\n",
    "        print(SID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell to double-check the array indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#change first index of cope_files to indicate participant index in sids array\n",
    "for i, curr_mask in enumerate(mask_filenames[0]):\n",
    "    print(i, mask_filenames[0][i].split('/')[-1][:-7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, curr_cope in enumerate(cope_files[0]):\n",
    "    print(i, cope_files[0][i].split('/')[-1][5:-7]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use binarized mask to obtain activation in left & right hemisphere for each region of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data = {}\n",
    "weighted_data = {}\n",
    "all_voxs = {'hp':[], 'mpfc':[], 'caud':[], 'put':[]}\n",
    "\n",
    "for r in ['hp', 'mpfc', 'caud', 'put']:\n",
    "    for acc in ['corr', 'incorr']:\n",
    "        all_data['{0}'.format(r)] = {'corr':[], 'incorr':[]}\n",
    "\n",
    "for i in range(len(sids)):\n",
    "    #hpc_fb4c['subjid'].append(sids[i]) \n",
    "    lh_hp_img = nb.load(mask_filenames[i][2])\n",
    "    rh_hp_img = nb.load(mask_filenames[i][11])\n",
    "    lh_mpfc_img = nb.load(mask_filenames[i][4])\n",
    "    rh_mpfc_img = nb.load(mask_filenames[i][13])\n",
    "    lh_caud_img = nb.load(mask_filenames[i][7])\n",
    "    rh_caud_img = nb.load(mask_filenames[i][8])\n",
    "    lh_put_img = nb.load(mask_filenames[i][16])\n",
    "    rh_put_img = nb.load(mask_filenames[i][17])\n",
    "\n",
    "    for key in all_voxs:\n",
    "        voxs = eval('sum(sum(sum(lh_{0}_img.get_data() + rh_{0}_img.get_data())))'.format(key))\n",
    "        all_voxs['{0}'.format(key)].append(voxs)\n",
    "    \n",
    "    all_before_B_corr_img = nb.load(cope_files[i][0])\n",
    "    all_before_B_incorr_img = nb.load(cope_files[i][1])    \n",
    "\n",
    "    for key in all_data:\n",
    "        for acc in ['corr', 'incorr']:\n",
    "            lh_data = eval('np.mean(all_before_B_{0}_img.get_data()[lh_{1}_img.get_data() > 0.])'.format(acc,key))            \n",
    "            rh_data = eval('np.mean(all_before_B_{0}_img.get_data()[rh_{1}_img.get_data() > 0.])'.format(acc,key))\n",
    "            all_data['{0}'.format(key)]['{0}'.format(acc)].append((lh_data + rh_data)/2.)\n",
    "                        \n",
    "for key in all_data:\n",
    "    exec('{0}_fb4c = all_data[\"{0}\"]'.format(key))\n",
    "    exec('{0}_voxs = np.array(all_voxs[\"{0}\"])'.format(key))\n",
    "    for acc in ['corr', 'incorr']:\n",
    "        exec('weighted_data[\"{0}_{1}\"] = {0}_fb4c[\"{1}\"] * {0}_voxs'.format(key, acc))\n",
    "        \n",
    "weighted_data_df = pd.DataFrame(weighted_data)\n",
    "all_voxs_df = pd.DataFrame(all_voxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00598125448458\n"
     ]
    }
   ],
   "source": [
    "#print hp_fb4c['corr'][0], hp_voxs[0]\n",
    "#print weighted_data['hp_corr'] \n",
    "\n",
    "x = sum(sum(sum(all_before_B_corr_img.get_data())))\n",
    "print hp_voxs[0]/x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caud</th>\n",
       "      <th>hp</th>\n",
       "      <th>mpfc</th>\n",
       "      <th>put</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>265.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>731.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>267.0</td>\n",
       "      <td>562.0</td>\n",
       "      <td>639.0</td>\n",
       "      <td>791.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>278.0</td>\n",
       "      <td>429.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>559.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>241.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>497.0</td>\n",
       "      <td>767.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>239.0</td>\n",
       "      <td>443.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>628.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>300.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>631.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>227.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>703.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>320.0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>553.0</td>\n",
       "      <td>686.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>317.0</td>\n",
       "      <td>466.0</td>\n",
       "      <td>474.0</td>\n",
       "      <td>708.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>271.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>464.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>287.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>753.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>244.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>643.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>264.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>627.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>289.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>447.0</td>\n",
       "      <td>655.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>281.0</td>\n",
       "      <td>484.0</td>\n",
       "      <td>467.0</td>\n",
       "      <td>701.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>266.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>552.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>273.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>613.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>299.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>588.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>334.0</td>\n",
       "      <td>521.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>332.0</td>\n",
       "      <td>529.0</td>\n",
       "      <td>607.0</td>\n",
       "      <td>547.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     caud     hp   mpfc    put\n",
       "0   265.0  523.0  468.0  731.0\n",
       "1   267.0  562.0  639.0  791.0\n",
       "2   278.0  429.0  480.0  559.0\n",
       "3   241.0  464.0  497.0  767.0\n",
       "4   239.0  443.0  463.0  628.0\n",
       "5   300.0  517.0  582.0  631.0\n",
       "6   227.0  499.0  448.0  703.0\n",
       "7   320.0  525.0  553.0  686.0\n",
       "8   317.0  466.0  474.0  708.0\n",
       "9   271.0  353.0  534.0  464.0\n",
       "10  287.0  563.0  545.0  753.0\n",
       "11  244.0  453.0  479.0  643.0\n",
       "12  264.0  512.0  570.0  627.0\n",
       "13  289.0  460.0  447.0  655.0\n",
       "14  281.0  484.0  467.0  701.0\n",
       "15  266.0  471.0  482.0  552.0\n",
       "16  273.0  437.0  390.0  613.0\n",
       "17  299.0  457.0  416.0  588.0\n",
       "18  334.0  521.0  512.0  660.0\n",
       "19  332.0  529.0  607.0  547.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_voxs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caud    279.70\n",
      "hp      483.40\n",
      "mpfc    502.65\n",
      "put     650.35\n",
      "dtype: float64\n",
      "\n",
      "caud    30.578802\n",
      "hp      50.391520\n",
      "mpfc    64.231715\n",
      "put     82.926267\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print all_voxs_df.mean()\n",
    "print \"\"\n",
    "print all_voxs_df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print stats.ttest_rel(all_voxs_df['hp'], all_voxs_df['mpfc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "for key in ['hp', 'mpfc']:\n",
    "    print \"Mean {0}: \".format(key), np.mean(all_voxs_df['{0}'.format(key)])\n",
    "    print \"STD {0}: \".format(key), np.std(all_voxs_df['{0}'.format(key)])\n",
    "    print \"\"\n",
    "print \"Paired-Samples t-Test:\", stats.ttest_rel(all_voxs_df['hp'], all_voxs_df['mpfc'])\n",
    "cohens_d = ((np.average(all_voxs_df['hp']) - np.average(all_voxs_df['mpfc'])) \n",
    "            / (sqrt((np.std(all_voxs_df['hp'], ddof = 1)) ** 2 + np.std( all_voxs_df['mpfc'], ddof = 1) ** 2) / 2))\n",
    "print \"Cohen's d = \", cohens_d\n",
    "\n",
    "N = 2\n",
    "conditions = ['HPC', 'mPFC']\n",
    "hp_allsubjs = [all_voxs_df['hp'], all_voxs_df['mpfc']]\n",
    "ind = np.arange(N)\n",
    "fig, ax = plt.subplots(figsize = (6,5))\n",
    "ax0 = sns.boxplot(data = hp_allsubjs, width = 0.3, linewidth = 2)\n",
    "ax2 = sns.swarmplot(data = hp_allsubjs, color='.25')\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(conditions)\n",
    "plt.savefig(\"/home/arenf001/voxels.png\", dpi = 1080)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weighted_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hippocampus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "for acc in ['corr', 'incorr']:\n",
    "    print \"Mean HPC_{0}: \".format(acc), np.mean(weighted_data_df['hp_{0}'.format(acc)])\n",
    "    print \"STD HPC {0}: \".format(acc), np.std(weighted_data_df['hp_{0}'.format(acc)])\n",
    "    print \"\"\n",
    "print \"Paired-Samples t-Test:\", stats.ttest_rel(weighted_data_df['hp_corr'], weighted_data_df['hp_incorr'])\n",
    "cohens_d = ((np.average(weighted_data_df['hp_corr']) - np.average(weighted_data_df['hp_incorr'])) \n",
    "            / (sqrt((np.std(weighted_data_df['hp_corr'], ddof = 1)) \n",
    "            ** 2 + np.std(weighted_data_df['hp_incorr'], ddof = 1) ** 2) / 2))\n",
    "print \"Cohen's d = \", cohens_d\n",
    "\n",
    "N = 2\n",
    "conditions = ['Correct', 'Incorrect']\n",
    "hp_allsubjs = [weighted_data_df['hp_corr'], weighted_data_df['hp_incorr']]\n",
    "ind = np.arange(N)\n",
    "fig, ax = plt.subplots(figsize = (6,5))\n",
    "ax0 = sns.boxplot(data = hp_allsubjs, color = \"#278fea\", width = 0.3)\n",
    "ax2 = sns.swarmplot(data = hp_allsubjs, color='.25')\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(conditions)\n",
    "ax.set_ylabel(\"Arbitrary units\")\n",
    "ax.set_ylim(-4000,3000)\n",
    "ax.set_title(\"Hippocampus\")\n",
    "plt.savefig(\"/home/arenf001/weightedHPC.png\", dpi = 1080)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## mPFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for acc in ['corr', 'incorr']:\n",
    "    print \"Mean mPFC_{0}: \".format(acc), np.mean(weighted_data_df['mpfc_{0}'.format(acc)])\n",
    "    print \"STD mPFC {0}: \".format(acc), np.std(weighted_data_df['mpfc_{0}'.format(acc)])\n",
    "    print \"\"\n",
    "print \"Paired-Samples t-Test:\", stats.ttest_rel(weighted_data_df['mpfc_corr'], weighted_data_df['mpfc_incorr'])\n",
    "N = 2\n",
    "conditions = ['Correct', 'Incorrect']\n",
    "mPFC_allsubjs = [weighted_data_df['mpfc_corr'], weighted_data_df['mpfc_incorr']]\n",
    "ind = np.arange(N)\n",
    "fig, ax = plt.subplots(figsize = (6,5))\n",
    "ax0 = sns.boxplot(data = mPFC_allsubjs, color = \"#f97401\", width = 0.3)\n",
    "ax2 = sns.swarmplot(data = mPFC_allsubjs, color='.25')\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(conditions)\n",
    "ax.set_ylabel(\"Arbitrary units\")\n",
    "ax.set_title(\"Medial PFC\")\n",
    "plt.savefig(\"/home/arenf001/weightedMPFC.png\", dpi = 1080)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caudate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for acc in ['corr', 'incorr']:\n",
    "    print \"Mean Caudate_{0}: \".format(acc), np.mean(weighted_data_df['caud_{0}'.format(acc)])\n",
    "    print \"STD Caudate {0}: \".format(acc), np.std(weighted_data_df['caud_{0}'.format(acc)])\n",
    "    print \"\"\n",
    "print \"Paired-Samples t-Test:\", stats.ttest_rel(weighted_data_df['caud_corr'], weighted_data_df['caud_incorr'])\n",
    "N = 2\n",
    "conditions = ['Correct', 'Incorrect']\n",
    "caud_allsubjs = [weighted_data_df['caud_corr'], weighted_data_df['caud_incorr']]\n",
    "ind = np.arange(N)\n",
    "fig, ax = plt.subplots(figsize = (6,5))\n",
    "ax0 = sns.boxplot(data = caud_allsubjs, color = \"#f9f96d\", width = 0.3)\n",
    "ax2 = sns.swarmplot(data =  caud_allsubjs, color='.25')\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(conditions)\n",
    "ax.set_ylabel(\"Arbitrary units\")\n",
    "ax.set_title(\"Caudate\")\n",
    "plt.savefig(\"/home/arenf001/weightedCAUD.png\", dpi = 1080)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putamen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for acc in ['corr', 'incorr']:\n",
    "    print \"Mean Putamen {0}: \".format(acc), np.mean(weighted_data_df['put_{0}'.format(acc)])\n",
    "    print \"STD Putamen {0}: \".format(acc), np.std(weighted_data_df['put_{0}'.format(acc)])\n",
    "    print \"\"\n",
    "print \"Paired-Samples t-Test:\", stats.ttest_rel(weighted_data_df['put_corr'], weighted_data_df['put_incorr'])\n",
    "N = 2\n",
    "conditions = ['Correct', 'Incorrect']\n",
    "put_allsubjs = [weighted_data_df['put_corr'], weighted_data_df['put_incorr']]\n",
    "ind = np.arange(N)\n",
    "fig, ax = plt.subplots(figsize = (6,5))\n",
    "ax0 = sns.boxplot(data = put_allsubjs, color = \"#c34aef\", width = 0.3)\n",
    "ax2 = sns.swarmplot(data =  put_allsubjs, color='.25')\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(conditions)\n",
    "ax.set_ylabel(\"Arbitrary units\")\n",
    "ax.set_title(\"Putamen\")\n",
    "plt.savefig(\"/home/arenf001/weightedPUT.png\", dpi = 1080)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
