{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 3 1-3-2\n",
    "### Contains only fixed-before-conditional trials without intervening BLs\n",
    "### Combines A & C trials into single regressor\n",
    "### Accounts for last three noisy volumes in Lvl 1 analysis (FSL ROI -- ExtractROI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compares activation for regions of interest using binarized masks:\n",
    "### Hippocampus (FS labels: hippocampus [17, 53])\n",
    "### Dorsal caudate (hand-drawn by Mandy)\n",
    "### Putamen (FS labels: putamen [12, 51])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "#Removed WMAZE_006 and WMAZE_023  \n",
    "sids = ['WMAZE_001', 'WMAZE_002', 'WMAZE_004', 'WMAZE_005', \n",
    "        'WMAZE_007', 'WMAZE_008', 'WMAZE_009', 'WMAZE_010', 'WMAZE_012',\n",
    "        'WMAZE_017', 'WMAZE_018', 'WMAZE_019', 'WMAZE_020', 'WMAZE_021',  \n",
    "        'WMAZE_022', 'WMAZE_024', 'WMAZE_026', 'WMAZE_027']\n",
    "proj_dir = '/home/data/madlab/data/mri/wmaze'\n",
    " \n",
    "mask_filenames = []\n",
    "cope_files = []\n",
    "\n",
    "for SID in sids:\n",
    "    mask_filenames_glob = glob(proj_dir + '/roi_analysis/model3_betaseries/mask/anat_masks/_subject_id_' \n",
    "                               + SID + '/_anatmask_xfm*/*')\n",
    "    mask_filenames_glob.sort()\n",
    "    mask_filenames.append(sorted(mask_filenames_glob))\n",
    "    subjcopes_glob = glob(proj_dir + '/frstlvl/wmaze_MRthesis/fixed_before_conditional/model3_2-3-2-4/11-11window/merge_copes/'\n",
    "                          + SID + '/merged/cope_*')\n",
    "    subjcopes_glob.sort()\n",
    "    cope_files.append(sorted(subjcopes_glob))\n",
    "    if len(cope_files[-1]) == 0:\n",
    "        print(SID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell to double-check the array indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'lh-dlPFC_lausanne_warped')\n",
      "(1, 'lh-hippocampus_warped')\n",
      "(2, 'lh-mPFC_fs-3reg_warped')\n",
      "(3, 'lh-mPFC_lausanne_warped')\n",
      "(4, 'lh-mPFC_rac-only_warped')\n",
      "(5, 'lh-mPFC_warped')\n",
      "(6, 'lh-motor_warped')\n",
      "(7, 'lh-putamen_warped')\n",
      "(8, 'lh_caudate_anat_mask_warped')\n",
      "(9, 'rh-dlPFC_lausanne_warped')\n",
      "(10, 'rh-hippocampus_warped')\n",
      "(11, 'rh-mPFC_warped')\n",
      "(12, 'rh-putamen_warped')\n",
      "(13, 'rh_caudate_anat_mask_warped')\n",
      "(14, 'rh-mPFC_fs-3reg_warped')\n",
      "(15, 'rh-mPFC_lausanne_warped')\n",
      "(16, 'rh-mPFC_rac-only_warped')\n",
      "(17, 'rh-motor_warped')\n",
      "(18, 'lh-mPFC_rac-cac_warped')\n",
      "(19, 'rh-mPFC_rac-cac_warped')\n"
     ]
    }
   ],
   "source": [
    "#change first index of cope_files to indicate participant index in sids array\n",
    "for i, curr_mask in enumerate(mask_filenames[0]):\n",
    "    print(i, mask_filenames[0][i].split('/')[-1][:-7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'all_before_B_corr')\n",
      "(1, 'all_before_B_incorr')\n",
      "(2, 'all_corr_minus_all_incorr')\n",
      "(3, 'all_incorr_minus_all_corr')\n",
      "(4, 'all_remaining')\n"
     ]
    }
   ],
   "source": [
    "for i, curr_cope in enumerate(cope_files[0]):\n",
    "    print(i, cope_files[0][i].split('/')[-1][5:-7]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use binarized mask to obtain activation in left & right hemisphere for each region of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data = {}\n",
    "weighted_data = {}\n",
    "all_voxs = {'dlpfc':[], 'motor':[]}\n",
    "\n",
    "for r in ['dlpfc', 'motor']:\n",
    "    for acc in ['corr', 'incorr']:\n",
    "        all_data['{0}'.format(r)] = {'corr':[], 'incorr':[]}\n",
    "\n",
    "for i in range(len(sids)):\n",
    "    #hpc_fb4c['subjid'].append(sids[i]) \n",
    "    lh_dlpfc_img = nb.load(mask_filenames[i][1])\n",
    "    rh_dlpfc_img = nb.load(mask_filenames[i][9])\n",
    "    lh_motor_img = nb.load(mask_filenames[i][6])\n",
    "    rh_motor_img = nb.load(mask_filenames[i][17])\n",
    "\n",
    "\n",
    "    for key in all_voxs:\n",
    "        voxs = eval('sum(sum(sum(lh_{0}_img.get_data() + rh_{0}_img.get_data())))'.format(key))\n",
    "        all_voxs['{0}'.format(key)].append(voxs)\n",
    "    \n",
    "    all_before_B_corr_img = nb.load(cope_files[i][0])\n",
    "    all_before_B_incorr_img = nb.load(cope_files[i][1])    \n",
    "\n",
    "    for key in all_data:\n",
    "        for acc in ['corr', 'incorr']:\n",
    "            lh_data = eval('np.mean(all_before_B_{0}_img.get_data()[lh_{1}_img.get_data() > 0.])'.format(acc,key))            \n",
    "            rh_data = eval('np.mean(all_before_B_{0}_img.get_data()[rh_{1}_img.get_data() > 0.])'.format(acc,key))\n",
    "            all_data['{0}'.format(key)]['{0}'.format(acc)].append((lh_data + rh_data)/2.)\n",
    "                        \n",
    "for key in all_data:\n",
    "    exec('{0}_fb4c = all_data[\"{0}\"]'.format(key))\n",
    "    exec('{0}_voxs = np.array(all_voxs[\"{0}\"])'.format(key))\n",
    "    for acc in ['corr', 'incorr']:\n",
    "        exec('weighted_data[\"{0}_{1}\"] = {0}_fb4c[\"{1}\"] * {0}_voxs'.format(key, acc))\n",
    "        \n",
    "weighted_data_df = pd.DataFrame(weighted_data)\n",
    "all_voxs_df = pd.DataFrame(all_voxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00081293 -0.00086465 -0.00313269  0.00074035 -0.00022202 -0.00155934\n",
      " -0.00048681 -0.0005726  -0.00052145 -0.00168403 -0.00049743]\n"
     ]
    }
   ],
   "source": [
    "#print hp_fb4c['corr'][0], hp_voxs[0]\n",
    "#print weighted_data['hp_corr'] \n",
    "\n",
    "x = sum(sum(sum(all_before_B_corr_img.get_data())))\n",
    "print dlpfc_voxs[0]/x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dlpfc</th>\n",
       "      <th>motor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>508.0</td>\n",
       "      <td>1668.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>594.0</td>\n",
       "      <td>2245.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>452.0</td>\n",
       "      <td>1814.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>435.0</td>\n",
       "      <td>2216.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>461.0</td>\n",
       "      <td>1892.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>424.0</td>\n",
       "      <td>1842.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>554.0</td>\n",
       "      <td>1787.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>460.0</td>\n",
       "      <td>1876.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>391.0</td>\n",
       "      <td>1822.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>478.0</td>\n",
       "      <td>1926.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>432.0</td>\n",
       "      <td>1635.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>467.0</td>\n",
       "      <td>2104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>447.0</td>\n",
       "      <td>1756.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>440.0</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>404.0</td>\n",
       "      <td>1720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>437.0</td>\n",
       "      <td>1801.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>417.0</td>\n",
       "      <td>2363.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>478.0</td>\n",
       "      <td>1926.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dlpfc   motor\n",
       "0   508.0  1668.0\n",
       "1   594.0  2245.0\n",
       "2   452.0  1814.0\n",
       "3   435.0  2216.0\n",
       "4   461.0  1892.0\n",
       "5   424.0  1842.0\n",
       "6   554.0  1787.0\n",
       "7   460.0  1876.0\n",
       "8   391.0  1822.0\n",
       "9   478.0  1926.0\n",
       "10  432.0  1635.0\n",
       "11  467.0  2104.0\n",
       "12  447.0  1756.0\n",
       "13  440.0  2015.0\n",
       "14  404.0  1720.0\n",
       "15  437.0  1801.0\n",
       "16  417.0  2363.0\n",
       "17  478.0  1926.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_voxs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlpfc     459.944444\n",
      "motor    1911.555556\n",
      "dtype: float64\n",
      "\n",
      "dlpfc     50.530681\n",
      "motor    203.539047\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print all_voxs_df.mean()\n",
    "print \"\"\n",
    "print all_voxs_df.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## print stats.ttest_rel(all_voxs_df['hp'], all_voxs_df['mpfc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "for key in ['hp', 'mpfc']:\n",
    "    print \"Mean {0}: \".format(key), np.mean(all_voxs_df['{0}'.format(key)])\n",
    "    print \"STD {0}: \".format(key), np.std(all_voxs_df['{0}'.format(key)])\n",
    "    print \"\"\n",
    "print \"Paired-Samples t-Test:\", stats.ttest_rel(all_voxs_df['hp'], all_voxs_df['mpfc'])\n",
    "cohens_d = ((np.average(all_voxs_df['hp']) - np.average(all_voxs_df['mpfc'])) \n",
    "            / (sqrt((np.std(all_voxs_df['hp'], ddof = 1)) ** 2 + np.std( all_voxs_df['mpfc'], ddof = 1) ** 2) / 2))\n",
    "print \"Cohen's d = \", cohens_d\n",
    "\n",
    "N = 2\n",
    "conditions = ['HPC', 'mPFC']\n",
    "hp_allsubjs = [all_voxs_df['hp'], all_voxs_df['mpfc']]\n",
    "ind = np.arange(N)\n",
    "fig, ax = plt.subplots(figsize = (6,5))\n",
    "ax0 = sns.boxplot(data = hp_allsubjs, width = 0.3, linewidth = 2)\n",
    "ax2 = sns.swarmplot(data = hp_allsubjs, color='.25')\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(conditions)\n",
    "plt.savefig(\"/home/arenf001/voxels.png\", dpi = 1080)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weighted_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hippocampus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "for acc in ['corr', 'incorr']:\n",
    "    print \"Mean HPC_{0}: \".format(acc), np.mean(weighted_data_df['hp_{0}'.format(acc)])\n",
    "    print \"STD HPC {0}: \".format(acc), np.std(weighted_data_df['hp_{0}'.format(acc)])\n",
    "    print \"\"\n",
    "print \"Paired-Samples t-Test:\", stats.ttest_rel(weighted_data_df['hp_corr'], weighted_data_df['hp_incorr'])\n",
    "cohens_d = ((np.average(weighted_data_df['hp_corr']) - np.average(weighted_data_df['hp_incorr'])) \n",
    "            / (sqrt((np.std(weighted_data_df['hp_corr'], ddof = 1)) \n",
    "            ** 2 + np.std(weighted_data_df['hp_incorr'], ddof = 1) ** 2) / 2))\n",
    "print \"Cohen's d = \", cohens_d\n",
    "\n",
    "N = 2\n",
    "conditions = ['Correct', 'Incorrect']\n",
    "hp_allsubjs = [weighted_data_df['hp_corr'], weighted_data_df['hp_incorr']]\n",
    "ind = np.arange(N)\n",
    "fig, ax = plt.subplots(figsize = (6,5))\n",
    "ax0 = sns.boxplot(data = hp_allsubjs, color = \"#278fea\", width = 0.3)\n",
    "ax2 = sns.swarmplot(data = hp_allsubjs, color='.25')\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(conditions)\n",
    "ax.set_ylabel(\"Arbitrary units\")\n",
    "ax.set_ylim(-4000,3000)\n",
    "ax.set_title(\"Hippocampus\")\n",
    "plt.savefig(\"/home/arenf001/weightedHPC.png\", dpi = 1080)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## mPFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for acc in ['corr', 'incorr']:\n",
    "    print \"Mean mPFC_{0}: \".format(acc), np.mean(weighted_data_df['mpfc_{0}'.format(acc)])\n",
    "    print \"STD mPFC {0}: \".format(acc), np.std(weighted_data_df['mpfc_{0}'.format(acc)])\n",
    "    print \"\"\n",
    "print \"Paired-Samples t-Test:\", stats.ttest_rel(weighted_data_df['mpfc_corr'], weighted_data_df['mpfc_incorr'])\n",
    "N = 2\n",
    "conditions = ['Correct', 'Incorrect']\n",
    "mPFC_allsubjs = [weighted_data_df['mpfc_corr'], weighted_data_df['mpfc_incorr']]\n",
    "ind = np.arange(N)\n",
    "fig, ax = plt.subplots(figsize = (6,5))\n",
    "ax0 = sns.boxplot(data = mPFC_allsubjs, color = \"#f97401\", width = 0.3)\n",
    "ax2 = sns.swarmplot(data = mPFC_allsubjs, color='.25')\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(conditions)\n",
    "ax.set_ylabel(\"Arbitrary units\")\n",
    "ax.set_title(\"Medial PFC\")\n",
    "plt.savefig(\"/home/arenf001/weightedMPFC.png\", dpi = 1080)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caudate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for acc in ['corr', 'incorr']:\n",
    "    print \"Mean Caudate_{0}: \".format(acc), np.mean(weighted_data_df['caud_{0}'.format(acc)])\n",
    "    print \"STD Caudate {0}: \".format(acc), np.std(weighted_data_df['caud_{0}'.format(acc)])\n",
    "    print \"\"\n",
    "print \"Paired-Samples t-Test:\", stats.ttest_rel(weighted_data_df['caud_corr'], weighted_data_df['caud_incorr'])\n",
    "N = 2\n",
    "conditions = ['Correct', 'Incorrect']\n",
    "caud_allsubjs = [weighted_data_df['caud_corr'], weighted_data_df['caud_incorr']]\n",
    "ind = np.arange(N)\n",
    "fig, ax = plt.subplots(figsize = (6,5))\n",
    "ax0 = sns.boxplot(data = caud_allsubjs, color = \"#f9f96d\", width = 0.3)\n",
    "ax2 = sns.swarmplot(data =  caud_allsubjs, color='.25')\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(conditions)\n",
    "ax.set_ylabel(\"Arbitrary units\")\n",
    "ax.set_title(\"Caudate\")\n",
    "plt.savefig(\"/home/arenf001/weightedCAUD.png\", dpi = 1080)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putamen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for acc in ['corr', 'incorr']:\n",
    "    print \"Mean Putamen {0}: \".format(acc), np.mean(weighted_data_df['put_{0}'.format(acc)])\n",
    "    print \"STD Putamen {0}: \".format(acc), np.std(weighted_data_df['put_{0}'.format(acc)])\n",
    "    print \"\"\n",
    "print \"Paired-Samples t-Test:\", stats.ttest_rel(weighted_data_df['put_corr'], weighted_data_df['put_incorr'])\n",
    "N = 2\n",
    "conditions = ['Correct', 'Incorrect']\n",
    "put_allsubjs = [weighted_data_df['put_corr'], weighted_data_df['put_incorr']]\n",
    "ind = np.arange(N)\n",
    "fig, ax = plt.subplots(figsize = (6,5))\n",
    "ax0 = sns.boxplot(data = put_allsubjs, color = \"#c34aef\", width = 0.3)\n",
    "ax2 = sns.swarmplot(data =  put_allsubjs, color='.25')\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(conditions)\n",
    "ax.set_ylabel(\"Arbitrary units\")\n",
    "ax.set_title(\"Putamen\")\n",
    "plt.savefig(\"/home/arenf001/weightedPUT.png\", dpi = 1080)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
