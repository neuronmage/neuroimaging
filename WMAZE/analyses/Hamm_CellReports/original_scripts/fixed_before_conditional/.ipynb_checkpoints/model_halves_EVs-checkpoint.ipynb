{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model HALVES\n",
    "## Compares periods of learning and nonlearning between early (run1) and late (run2)\n",
    "\n",
    "### Important notes for noobs:\n",
    "#### 1. 80 conditional trials per stimulus set anchor entire script logic - 40 per run (2 runs).\n",
    "#### 2. Certain conditional trials are considered \"bad\" (i.e. if they fall on the first or in last 3 trials), and must be avoided.\n",
    "#### 3. This script is a clusterfuck of indexing... pay very close attention to what the values of each array represent (see comments). Failing to do so *will* result in major problems!\n",
    "#### 4. If you get lost, use print statements to walk yourself through the logic. It is sound... just complicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import shutil \n",
    "import os\n",
    "from os.path import join, split, basename\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onset_sort(x):\n",
    "    x = x.split('_')[-1]\n",
    "    return(x[5:-8])\n",
    "\n",
    "subs = ['WMAZE_001']\n",
    "'''\n",
    "subs = ['WMAZE_002', 'WMAZE_004', 'WMAZE_005', 'WMAZE_006',\n",
    "        'WMAZE_007', 'WMAZE_008', 'WMAZE_009', 'WMAZE_010', 'WMAZE_012',\n",
    "        'WMAZE_017', 'WMAZE_018', 'WMAZE_019', 'WMAZE_020', 'WMAZE_021',\n",
    "        'WMAZE_022', 'WMAZE_023', 'WMAZE_024', 'WMAZE_026', 'WMAZE_027']\n",
    "'''\n",
    "\n",
    "sets = ['set1', 'set2', 'set3']\n",
    "runs = ['run1', 'run2', 'run3', 'run4', 'run5', 'run6']\n",
    "\n",
    "#collect all files for each subject\n",
    "for sub in subs:\n",
    "    sub_dir = '/home/data/madlab/data/mri/wmaze/' #base directory\n",
    "    save_dir = '/home/data/madlab/data/mri/wmaze/scanner_behav/{0}/MRthesis/model_HALVES/'.format(sub)\n",
    "    \n",
    "    if not os.path.exists(save_dir): \n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    #grab the derivative files created from the set-based learning analysis\n",
    "    frst_deriv_files = glob(join(sub_dir, 'scanner_behav/{0}/Bprime_pmode_set*.txt'.format(sub))) \n",
    "    frst_deriv_files.sort()     \n",
    "    #grab the learning curve file for B trials\n",
    "    learning_files = glob(join(sub_dir, 'scanner_behav/{0}/B_pmode_set*.txt'.format(sub))) \n",
    "    learning_files.sort()    \n",
    "    #grab the behavioral files for all runs\n",
    "    behav_runs = glob(join(sub_dir, 'scanner_behav/{0}/{0}_wmazebl_2015*.txt'.format(sub))) \n",
    "    behav_runs.sort()\n",
    "    \n",
    "    \n",
    "    for i, curr_set in enumerate(sets): #load derivative and learning curve files\n",
    "        deriv_file = np.loadtxt(frst_deriv_files[i])\n",
    "        learning_curve = np.loadtxt(learning_files[i]) \n",
    "                \n",
    "        #load behavioral files into Pandas\n",
    "        behav_run1 = pd.read_table(behav_runs[i*2])\n",
    "        behav_run2 = pd.read_table(behav_runs[i*2+1])\n",
    "                \n",
    "        #info concerning onset time\n",
    "        behav_os = np.empty(320, dtype=object)\n",
    "        behav_os[:160] = behav_run1['StimOnset'].values\n",
    "        behav_os[160:] = behav_run2['StimOnset'].values        \n",
    "        #info concerning subject response\n",
    "        behav_resp = np.empty(320, dtype=object)\n",
    "        behav_resp[:160] = behav_run1['Resp'].values\n",
    "        behav_resp[160:] = behav_run2['Resp'].values        \n",
    "        #info concerning trial type\n",
    "        behav_type = np.empty(320, dtype=object)\n",
    "        behav_type[:160] = behav_run1['TrialType'].values\n",
    "        behav_type[160:] = behav_run2['TrialType'].values\n",
    "                \n",
    "        b_indices = np.where((behav_type == 'B'))[0] #Bs in the original dataset without preceeding BL trials\n",
    "        trial_shift = behav_type[:-1] \n",
    "        trial_shift = np.insert(trial_shift, 0, -1) #shifted array to identify preceding BLs\n",
    "        b_BL_indices = np.where((behav_type == 'B') & (trial_shift == 'BL'))[0] #B trials with preceeding BLs       \n",
    "        \n",
    "        \n",
    "        #isolate bad Bs for removal in learning curve/derivative files\n",
    "        #value represents index among all trials (original behavioral file) \n",
    "        bad_Bs = [] \n",
    "        bad_Bs.extend(b_BL_indices)\n",
    "        for curr_B in b_indices:\n",
    "            if not curr_B in bad_Bs:\n",
    "                if behav_resp[curr_B] == 'NR': #identify in B trials which are non-response\n",
    "                    bad_Bs.append(curr_B)    \n",
    "                if curr_B in [0, 157, 158, 159, 160, 317, 318, 319]: #indices if B trial comes first \n",
    "                    bad_Bs.append(curr_B)\n",
    "        bad_Bs.sort() \n",
    "        #print bad_Bs           \n",
    "        \n",
    "        \n",
    "        #value represents index among only B trials \n",
    "        #used to match and remove bad Bs from learning curve/derivative arrays        \n",
    "        bad_B_ind = [j for j, f in enumerate(b_indices) if f in bad_Bs] #get indices for bad Bs within group of Bs\n",
    "        bad_B_ind.sort()\n",
    "        bad_B_ind = bad_B_ind[::-1] #reverse order of Bs to be removed \n",
    "        #print bad_B_ind \n",
    "          \n",
    "            \n",
    "        #LEARNING CURVE WITH BAD B'S REMOVED\n",
    "        temp2 = list(learning_curve) #create a temp version of learning_curve\n",
    "        for curr_bad_B in bad_B_ind: \n",
    "            temp2.pop(curr_bad_B) #pop out the bad Bs starting from the end   \n",
    "        new_learning = np.array(temp2) #save without the removed Bs\n",
    "        #print new_learning\n",
    "     \n",
    "        \n",
    "        #DERIV FILES WITH BAD B'S REMOVED\n",
    "        temp = list(deriv_file)\n",
    "        for curr_bad_B in bad_B_ind:\n",
    "            temp.pop(curr_bad_B)   \n",
    "        new_deriv = np.array(temp[1:]) \n",
    "        print len(new_deriv)\n",
    "        learning = np.where(new_deriv > 0)[0]\n",
    "        print len(learning), learning\n",
    "        nonlearning = np.where(new_deriv <= 0)[0]\n",
    "        #use list comprehension to quickly identify relevant B trials for each regressor\n",
    "        run1_learn = [j for j, f in enumerate(learning) if f <= 40] #any B in learn with an index of < 40 (run 1)\n",
    "        run2_learn = [j for j, f in enumerate(learning) if f > 40] #any B in learn with an index of > 40 (run 2)\n",
    "        run1_nonlearn = [j for j, f in enumerate(nonlearning) if f <= 40]\n",
    "        run2_nonlearn = [j for j, f in enumerate(nonlearning) if f > 40]\n",
    "        #print \"Run1\", run1_learn\n",
    "        #print \"Run2\", run2_learn\n",
    "         \n",
    "        #remove the bad Bs from the B-list\n",
    "        temp4 = list(b_indices)\n",
    "        for curr_bad_B in bad_B_ind:\n",
    "            temp4.pop(curr_bad_B)\n",
    "        good_Bs = np.array(temp4)\n",
    "        #print \"Good Bs\", len(good_Bs)\n",
    "\n",
    "        run1_learn_ind = good_Bs[run1_learn]\n",
    "        run1_fixed_learn = [x - 1 for x in run1_learn_ind]\n",
    "        #print \"learn ind\", run1_learn_ind\n",
    "        \n",
    "        run2_learn_ind = good_Bs[run2_learn]\n",
    "        run2_fixed_learn = [x - 1 for x in run2_learn_ind]\n",
    "        run1_nonlearn_ind = good_Bs[run1_nonlearn]\n",
    "        run1_fixed_nonlearn = [x - 1 for x in run1_nonlearn_ind]\n",
    "        run2_nonlearn_ind = good_Bs[run2_nonlearn]\n",
    "        run2_fixed_nonlearn = [x - 1 for x in run2_nonlearn_ind]\n",
    "        \n",
    "        run1_learn_os = behav_os[run1_fixed_learn]\n",
    "        run2_learn_os = behav_os[run2_fixed_learn]\n",
    "        run1_nonlearn_os = behav_os[run1_fixed_nonlearn]\n",
    "        run2_nonlearn_os = behav_os[run2_fixed_nonlearn]\n",
    "        \n",
    "        \n",
    "        run1_learn_mtrx = np.vstack((run1_learn_os,\n",
    "                                     np.ones(len(run1_learn_os)) * 3.0,\n",
    "                                     np.ones(len(run1_learn_os)))).T\n",
    "        \n",
    "        run2_learn_mtrx = np.vstack((run2_learn_os,\n",
    "                                     np.ones(len(run2_learn_os)) * 3.0,\n",
    "                                     np.ones(len(run2_learn_os)))).T\n",
    "        \n",
    "        run1_nonlearn_mtrx = np.vstack((run1_nonlearn_os,\n",
    "                                        np.ones(len(run1_nonlearn_os)) * 3.0,\n",
    "                                        np.ones(len(run1_nonlearn_os)))).T\n",
    "        \n",
    "        run2_nonlearn_mtrx = np.vstack((run2_nonlearn_os,\n",
    "                                        np.ones(len(run2_nonlearn_os)) * 3.0,\n",
    "                                        np.ones(len(run2_nonlearn_os)))).T\n",
    "        \n",
    "\n",
    "        np.savetxt(save_dir + '{0}_run1_learn.txt'.format(curr_set), run1_learn_mtrx, delimiter='\\t', fmt='%.4f')\n",
    "        np.savetxt(save_dir + '{0}_run2_learn.txt'.format(curr_set), run2_learn_mtrx, delimiter='\\t', fmt='%.4f')\n",
    "        np.savetxt(save_dir + '{0}_run1_nonlearn.txt'.format(curr_set), run1_nonlearn_mtrx, delimiter='\\t', fmt='%.4f')\n",
    "        np.savetxt(save_dir + '{0}_run2_nonlearn.txt'.format(curr_set), run2_nonlearn_mtrx, delimiter='\\t', fmt='%.4f')      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
