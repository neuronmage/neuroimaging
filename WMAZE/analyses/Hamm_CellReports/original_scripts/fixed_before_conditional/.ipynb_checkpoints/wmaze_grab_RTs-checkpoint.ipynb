{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Array containing subject ids\n",
    "\n",
    "#subs = ['WMAZE_001']\n",
    "\n",
    "subs = ['WMAZE_001', 'WMAZE_002', 'WMAZE_004', 'WMAZE_005', 'WMAZE_006',\n",
    "        'WMAZE_007', 'WMAZE_008', 'WMAZE_009', 'WMAZE_010', 'WMAZE_012',\n",
    "        'WMAZE_017', 'WMAZE_018', 'WMAZE_019', 'WMAZE_020', 'WMAZE_021',\n",
    "        'WMAZE_022', 'WMAZE_023', 'WMAZE_024', 'WMAZE_026', 'WMAZE_027']\n",
    "\n",
    "\n",
    "# Array containing the three sets\n",
    "stim_sets = ['set1', 'set2', 'set3']\n",
    "\n",
    "# Loop to grab correct 6 run text files for each subject\n",
    "for sub in subs:\n",
    "    # Array containing path to behavior files\n",
    "    sub_dir = '/home/data/madlab/data/mri/wmaze/scanner_behav/{0}/'.format(sub)\n",
    "    # Array containing current sub's 6 behavior file runs\n",
    "    dir_file = glob(join(sub_dir, '{0}_wmazebl_2015*.txt'.format(sub)))    \n",
    "    # Sort current sub's txt files in order of run\n",
    "    dir_file.sort() \n",
    "\n",
    "       \n",
    "    # Loop through each of the set types \n",
    "    for i, curr_set in enumerate(stim_sets):\n",
    "        # Create dataframe for text files to extract RTs\n",
    "        # Run 1\n",
    "        run1 = pd.read_table(dir_file[i * 2])\n",
    "        # Replace all \"NaN\" values with maximum task length (3 seconds)\n",
    "        run1['RT'] = run1['RT'].replace(['nan'], 3)\n",
    "        # Run 2\n",
    "        run2 = pd.read_table(dir_file[i * 2 + 1])\n",
    "        run2['RT'] = run2['RT'].replace(['nan'], 3)\n",
    "\n",
    "        \n",
    "        # Convert dataframes into numpy arrays \n",
    "        # Run 1\n",
    "        run1_rts = run1['RT'].values\n",
    "        \n",
    "        # Run 2\n",
    "        run2_rts = run2['RT'].values\n",
    "        \n",
    "\n",
    "        # If the output directory does not exist\n",
    "        if not os.path.exists(join(sub_dir, 'MRthesis/', 'RTs/')):\n",
    "            # Create it\n",
    "            os.makedirs(join(sub_dir, 'MRthesis/', 'RTs/')) \n",
    "\n",
    "\n",
    "        # Run 1     \n",
    "        # Create EV text file for Set_-Run 1 ALL RTs\n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'RTs/' + \n",
    "                   'run{0}_RTs.txt'.format(i * 2 + 1), \n",
    "                   run1_rts, delimiter='\\t', fmt='%.8f')\n",
    "\n",
    "        # Run 2 \n",
    "        # Create EV text file for Set_-run2 ALL onsets/durations/amplitudes\n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'RTs/' + \n",
    "                   'run{0}_RTs.txt'.format(i * 2 + 2), \n",
    "                   run2_rts, delimiter='\\t', fmt='%.8f')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
