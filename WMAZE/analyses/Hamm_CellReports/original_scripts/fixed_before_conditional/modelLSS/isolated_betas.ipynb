{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolating trials of learning -- all 21 together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subs = ['WMAZE_004']\n",
    "\n",
    "subs = ['WMAZE_001', 'WMAZE_002', 'WMAZE_004', 'WMAZE_005', 'WMAZE_006',\n",
    "        'WMAZE_007', 'WMAZE_008', 'WMAZE_009', 'WMAZE_010', 'WMAZE_012',\n",
    "        'WMAZE_017', 'WMAZE_018', 'WMAZE_019', 'WMAZE_020', 'WMAZE_021',\n",
    "        'WMAZE_022', 'WMAZE_023', 'WMAZE_024', 'WMAZE_026', 'WMAZE_027']\n",
    "\n",
    "\n",
    "sets = ['set1', 'set2', 'set3']\n",
    "\n",
    "\n",
    "for sub in subs:\n",
    "    sub_dir = '/home/data/madlab/data/mri/wmaze/scanner_behav/{0}/'.format(sub)\n",
    "    frst_deriv_files = glob(join(sub_dir, 'Bprime_pmode_set*.txt'))    \n",
    "    frst_deriv_files.sort() \n",
    "    behav_runs = glob(join(sub_dir, '{0}_wmazebl_2015*.txt'.format(sub))) \n",
    "    behav_runs.sort()\n",
    "    #print behav_runs\n",
    "    #print frst_deriv_files\n",
    "    \n",
    "    for i, curr_set in enumerate(sets):\n",
    "        behav_run1 = pd.read_table(behav_runs[i*2])\n",
    "        behav_run2 = pd.read_table(behav_runs[i*2+1])\n",
    "        \n",
    "        behav_set = np.empty(320, dtype=object)    \n",
    "        behav_os = np.empty(320, dtype=object)\n",
    "        behav_set[:160] = behav_run1['TrialType'].values\n",
    "        behav_set[160:] = behav_run2['TrialType'].values\n",
    "        behav_os[:160] = behav_run1['StimOnset'].values\n",
    "        behav_os[160:] = behav_run2['StimOnset'].values\n",
    "        #print behav_set\n",
    "        \n",
    "        deriv_file = np.loadtxt(frst_deriv_files[i])\n",
    "        #print deriv_file[i]\n",
    "        deriv_file = deriv_file[10:]\n",
    "        #deriv_file = deriv_file[:-10]\n",
    "        #print len(deriv_file)\n",
    "        #plt.plot(deriv_file) \n",
    "        #grabs the index of the largest derivative\n",
    "        target_trial = np.argmax(deriv_file)+10\n",
    "        #print target_trial\n",
    "\n",
    "        #indices of all Bs in the original dataset\n",
    "        #used to help place the target trial back into ordinal context\n",
    "        b_indices = np.where(behav_set == 'B')[0]\n",
    "        #print b_indices\n",
    "        \n",
    "        #grab the 20 B trials surrounding the target B\n",
    "        b_learning = b_indices[target_trial-10:target_trial+11]\n",
    "        #print b_learning\n",
    "        #grabs the trial immediately preceeding each B isolated\n",
    "        b4_Bs = b_learning-1\n",
    "        #print b4_Bs\n",
    "        \n",
    "        #\n",
    "        #gets the fixed trial before condition when BLs are between\n",
    "        for i, curr_b4 in enumerate(b4_Bs):\n",
    "            while behav_set[b4_Bs[i]] == \"BL\":\n",
    "                b4_Bs[i] -= 1\n",
    "        \n",
    "        #grabs the original fixed trials after accounting for unwanted BLs     \n",
    "        fixed_learning_all21_onsets = behav_os[b4_Bs]\n",
    "        \n",
    "        \n",
    "        fixed_learning_all21_mtrx = np.vstack((fixed_learning_all21_onsets, \n",
    "                                               np.ones(len(fixed_learning_all21_onsets)) * 3.0,\n",
    "                                               np.ones(len(fixed_learning_all21_onsets)))).T\n",
    "        \n",
    "        \n",
    "        if not os.path.exists(join(sub_dir, 'MRthesis/', 'modelLSS_targ_all21/', 'EVs/')):\n",
    "            os.makedirs(join(sub_dir, 'MRthesis/', 'modelLSS_targ_all21/', 'EVs/')) \n",
    "             \n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'modelLSS_targ_all21/' + 'EVs/' + \n",
    "                   'fixed_learning_all21_{0}.txt'.format(curr_set), \n",
    "                   fixed_learning_all21_mtrx, delimiter = '\\t', fmt = '%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subs = ['WMAZE_004']\n",
    "\n",
    "subs = ['WMAZE_001', 'WMAZE_002', 'WMAZE_004', 'WMAZE_005', 'WMAZE_006',\n",
    "        'WMAZE_007', 'WMAZE_008', 'WMAZE_009', 'WMAZE_010', 'WMAZE_012',\n",
    "        'WMAZE_017', 'WMAZE_018', 'WMAZE_019', 'WMAZE_020', 'WMAZE_021',\n",
    "        'WMAZE_022', 'WMAZE_023', 'WMAZE_024', 'WMAZE_026', 'WMAZE_027']\n",
    "\n",
    "\n",
    "sets = ['set1', 'set2', 'set3']\n",
    "\n",
    "\n",
    "for sub in subs:\n",
    "    sub_dir = '/home/data/madlab/data/mri/wmaze/scanner_behav/{0}/'.format(sub)\n",
    "    frst_deriv_files = glob(join(sub_dir, 'Bprime_pmode_set*.txt'))    \n",
    "    frst_deriv_files.sort() \n",
    "    behav_runs = glob(join(sub_dir, '{0}_wmazebl_2015*.txt'.format(sub))) \n",
    "    behav_runs.sort()\n",
    "    #print behav_runs\n",
    "    #print frst_deriv_files\n",
    "    \n",
    "    for i, curr_set in enumerate(sets):\n",
    "        behav_run1 = pd.read_table(behav_runs[i*2])\n",
    "        behav_run2 = pd.read_table(behav_runs[i*2+1])\n",
    "        \n",
    "        behav_set = np.empty(320, dtype=object)    \n",
    "        behav_os = np.empty(320, dtype=object)\n",
    "        behav_set[:160] = behav_run1['TrialType'].values\n",
    "        behav_set[160:] = behav_run2['TrialType'].values\n",
    "        behav_os[:160] = behav_run1['StimOnset'].values\n",
    "        behav_os[160:] = behav_run2['StimOnset'].values\n",
    "        #print behav_set\n",
    "        \n",
    "        deriv_file = np.loadtxt(frst_deriv_files[i])\n",
    "        #print deriv_file[i]\n",
    "        deriv_file = deriv_file[10:]\n",
    "        #deriv_file = deriv_file[:-10]\n",
    "        #print len(deriv_file)\n",
    "        #plt.plot(deriv_file) \n",
    "        #grabs the index of the largest derivative\n",
    "        target_trial = np.argmax(deriv_file)+10\n",
    "        #print target_trial\n",
    "\n",
    "        #indices of all Bs in the original dataset\n",
    "        #used to help place the target trial back into ordinal context\n",
    "        b_indices = np.where(behav_set == 'B')[0]\n",
    "        #print b_indices\n",
    "        \n",
    "        #grab the 20 B trials surrounding the target B\n",
    "        b_learning = b_indices[target_trial-10:target_trial+11]\n",
    "        #print b_learning\n",
    "        #grabs the trial immediately preceeding each B isolated\n",
    "        b4_Bs = b_learning-1\n",
    "        #print b4_Bs\n",
    "        \n",
    "        #\n",
    "        #gets the fixed trial before condition when BLs are between\n",
    "        for i, curr_b4 in enumerate(b4_Bs):\n",
    "            while behav_set[b4_Bs[i]] == \"BL\":\n",
    "                b4_Bs[i] -= 1\n",
    "        \n",
    "        fixed_learning_10before_onsets = behav_os[b4_Bs[:10]]\n",
    "        fixed_learning_10after_onsets = behav_os[b4_Bs[11:]]\n",
    "        \n",
    "        \n",
    "        fixed_learning_10before_mtrx = np.vstack((fixed_learning_10before_onsets, \n",
    "                                                 np.ones(len(fixed_learning_10before_onsets)) * 3.0,\n",
    "                                                 np.ones(len(fixed_learning_10before_onsets)))).T\n",
    "        \n",
    "        fixed_learning_10after_mtrx = np.vstack((fixed_learning_10after_onsets, \n",
    "                                                 np.ones(len(fixed_learning_10after_onsets)) * 3.0,\n",
    "                                                 np.ones(len(fixed_learning_10after_onsets)))).T\n",
    "        \n",
    "        \n",
    "        if not os.path.exists(join(sub_dir, 'MRthesis/', 'modelLSS_targ_split20/', 'EVs/')):\n",
    "            os.makedirs(join(sub_dir, 'MRthesis/', 'modelLSS_targ_split20/', 'EVs/')) \n",
    "             \n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'modelLSS_targ_split20/' + 'EVs/' + \n",
    "                   'fixed_learning_10before_{0}.txt'.format(curr_set), \n",
    "                   fixed_learning_10before_mtrx, delimiter = '\\t', fmt = '%.4f')\n",
    "        \n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'modelLSS_targ_split20/' + 'EVs/' + \n",
    "                   'fixed_learning_10after_{0}.txt'.format(curr_set), \n",
    "                   fixed_learning_10after_mtrx, delimiter = '\\t', fmt = '%.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two possible paths:\n",
    "\n",
    "### 1. Need to decode the naming scheme of the LSS model 1st level copes against the indices isolated above\n",
    "#### Problem - LSS model only included FIXED/COND pairing that were immediately preceeding one another. The current design is considering all B trials, including those following one or more BL trials.\n",
    "#### Solution - Must rework current B isolation script to disregard Bs following BL trials. However, this method would disrupt the period targeted, introducing noise by including trials outside the initial 10 trial radius.\n",
    "### 2. Create new EV files and rerun level 1 analysis for only the isolated conditional trials\n",
    "#### Problem - Time investment to reconduct level 1 analysis. May be preferential to solution 1 -- this method conserves the period of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
