{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolating trials of learning -- all 21 together\n",
    "### Creating EV for last 3 trials -- regressor of no interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[393.2194887 395.7194259 398.2193459 393.23054272699994 395.730469679\n",
      " 398.23040357400004]\n",
      "[393.224062 395.723982915 398.22387968199996 393.229417731 395.729320233\n",
      " 398.22924446900004]\n",
      "[393.217419481 395.717318663 398.21728546 393.221853965 395.72179721699996\n",
      " 398.22169941699997]\n"
     ]
    }
   ],
   "source": [
    "subs = ['WMAZE_001']\n",
    "\n",
    "#subs = ['WMAZE_001', 'WMAZE_002', 'WMAZE_004', 'WMAZE_005', 'WMAZE_006',\n",
    "#        'WMAZE_007', 'WMAZE_008', 'WMAZE_009', 'WMAZE_010', 'WMAZE_012',\n",
    "#        'WMAZE_017', 'WMAZE_018', 'WMAZE_019', 'WMAZE_020', 'WMAZE_021',\n",
    "#        'WMAZE_022', 'WMAZE_023', 'WMAZE_024', 'WMAZE_026', 'WMAZE_027']\n",
    "\n",
    "\n",
    "sets = ['set1', 'set2', 'set3']\n",
    "\n",
    "\n",
    "for sub in subs:\n",
    "    sub_dir = '/home/data/madlab/data/mri/wmaze/scanner_behav/{0}/'.format(sub)\n",
    "    frst_deriv_files = glob(join(sub_dir, 'Bprime_pmode_set*.txt'))    \n",
    "    frst_deriv_files.sort() \n",
    "    behav_runs = glob(join(sub_dir, '{0}_wmazebl_2015*.txt'.format(sub))) \n",
    "    behav_runs.sort()\n",
    "    #print behav_runs\n",
    "    #print frst_deriv_files\n",
    "    \n",
    "    for i, curr_set in enumerate(sets):\n",
    "        behav_run1_orig = pd.read_table(behav_runs[i*2])\n",
    "        behav_run2_orig = pd.read_table(behav_runs[i*2+1])\n",
    "        behav_orig_os = np.empty(320, dtype=object)\n",
    "        behav_orig_os[:160] = behav_run1_orig['StimOnset'].values\n",
    "        behav_orig_os[160:] = behav_run2_orig['StimOnset'].values       \n",
    "        \n",
    "        behav_run1 = behav_run1_orig[:-3]\n",
    "        behav_run2 = behav_run2_orig[:-3]\n",
    "     \n",
    "        behav_set = np.empty(314, dtype=object)    \n",
    "        behav_os = np.empty(314, dtype=object)\n",
    "        behav_acc = np.empty(314, dtype=object)\n",
    "        behav_resp = np.empty(314, dtype=object)\n",
    "        behav_set[:157] = behav_run1['TrialType'].values\n",
    "        behav_set[157:] = behav_run2['TrialType'].values\n",
    "        behav_os[:157] = behav_run1['StimOnset'].values\n",
    "        behav_os[157:] = behav_run2['StimOnset'].values\n",
    "        behav_acc[:157] = behav_run1['Correct'].values\n",
    "        behav_acc[157:] = behav_run2['Correct'].values\n",
    "        behav_resp[:157] = behav_run1['Resp'].values\n",
    "        behav_resp[157:] = behav_run2['Resp'].values\n",
    "        #print behav_set\n",
    "        \n",
    "        deriv_file = np.loadtxt(frst_deriv_files[i])\n",
    "        #print deriv_file[i]\n",
    "        deriv_file = deriv_file[10:]\n",
    "        deriv_file = deriv_file[:-10]\n",
    "        #print len(deriv_file)\n",
    "        #plt.plot(deriv_file) \n",
    "        #grabs the index of the largest derivative\n",
    "        target_trial = np.argmax(deriv_file)+10\n",
    "        #print target_trial\n",
    "\n",
    "        #indices of all Bs in the original dataset\n",
    "        #used to help place the target trial back into ordinal context\n",
    "        b_indices = np.where(behav_set == 'B')[0]\n",
    "        #print type(b_indices)\n",
    "        \n",
    "        #grab the 20 B trials surrounding the target B\n",
    "        b_learning = b_indices[target_trial-10:target_trial+11]\n",
    "        #print b_learning\n",
    "        #grabs the trial immediately preceeding each B isolated\n",
    "        b4_Bs = b_learning-1\n",
    "        #print b4_Bs\n",
    "        \n",
    "        #gets the fixed trial before condition when BLs are between\n",
    "        for i, curr_b4 in enumerate(b4_Bs):\n",
    "            while behav_set[b4_Bs[i]] == \"BL\" or behav_resp[b4_Bs[i]] == \"NR\":\n",
    "                b4_Bs[i] -= 1\n",
    "        #b4_Bs = the indices of the isolated FX before COND trials within the original dataset        \n",
    "        #print b4_Bs\n",
    "        \n",
    "        #use list comprehension to check the response value and\n",
    "        #get everything that isn't in the b4_Bs and is not a nonresponse\n",
    "        all_exp_targ = [i for i, resp_val in enumerate(behav_resp) if not i in b4_Bs and resp_val != 'NR']\n",
    "        #print all_exp_targ\n",
    "\n",
    "        #print fixed_learning_all21_onsets\n",
    "        fixed_learning_all21_acc = behav_acc[b_learning]\n",
    "        #print fixed_learning_all21_acc\n",
    "        fixed_learning_all21_resp = behav_resp[b_learning]\n",
    "        #print fixed_learning_all21_resp\n",
    "        \n",
    "        # Categorizing the isolated list into individual regressors\n",
    "        iso_FX_before_COND_corr = b4_Bs[np.where((fixed_learning_all21_acc == 1))]     \n",
    "        #print (iso_FX_before_COND_corr)\n",
    "        \n",
    "        iso_FX_before_COND_incorr = b4_Bs[np.where((fixed_learning_all21_acc == 0))]\n",
    "        #print (iso_FX_before_COND_incorr)\n",
    "        \n",
    "        # all_remaining should contain B, BL, and non-isolated A/C trials, but not NR\n",
    "        all_remaining = np.array(all_exp_targ)\n",
    "        #print all_remaining\n",
    "        \n",
    "        nonresponse = np.where((behav_resp == 'NR'))\n",
    "        #print nonresponse\n",
    "       \n",
    "    \n",
    "        #print last3_1\n",
    "        \n",
    "        #grabs the original fixed trial onsets after accounting for BLs     \n",
    "        iso_FX_before_COND_corr_onsets = behav_os[iso_FX_before_COND_corr]\n",
    "        iso_FX_before_COND_incorr_onsets = behav_os[iso_FX_before_COND_incorr]\n",
    "        all_remaining_onsets = behav_os[all_remaining]\n",
    "        nonresponse_onsets = behav_os[nonresponse]\n",
    "        last3_onsets = np.hstack((behav_orig_os[157:160], behav_orig_os[317:320]))\n",
    "        #print last3_onsets\n",
    "        \n",
    "        all_mtrx = np.vstack((behav_os,\n",
    "                              np.ones(len(behav_os)) * 3.0,\n",
    "                              np.ones(len(behav_os)))).T\n",
    "        \n",
    "               \n",
    "        iso_FX_before_COND_corr_mtrx = np.vstack((iso_FX_before_COND_corr_onsets, \n",
    "                                                  np.ones(len(iso_FX_before_COND_corr_onsets)) * 3.0,\n",
    "                                                  np.ones(len(iso_FX_before_COND_corr_onsets)))).T\n",
    "        \n",
    "        iso_FX_before_COND_incorr_mtrx = np.vstack((iso_FX_before_COND_incorr_onsets, \n",
    "                                                    np.ones(len(iso_FX_before_COND_incorr_onsets)) * 3.0,\n",
    "                                                    np.ones(len(iso_FX_before_COND_incorr_onsets)))).T\n",
    "        \n",
    "        all_remaining_mtrx = np.vstack((all_remaining_onsets, \n",
    "                                        np.ones(len(all_remaining_onsets)) * 3.0,\n",
    "                                        np.ones(len(all_remaining_onsets)))).T\n",
    "        \n",
    "        nonresponse_mtrx = np.vstack((nonresponse_onsets, \n",
    "                                      np.ones(len(nonresponse_onsets)) * 3.0,\n",
    "                                      np.ones(len(nonresponse_onsets)))).T\n",
    "        \n",
    "        last3_mtrx = np.vstack((last3_onsets, \n",
    "                                np.ones(len(last3_onsets)) * 3.0,\n",
    "                                np.ones(len(last3_onsets)))).T\n",
    "        \n",
    "        \n",
    "        if not os.path.exists(join(sub_dir, 'MRthesis/', 'model5_LSS_3-1_all21/', 'EVs/')):\n",
    "            os.makedirs(join(sub_dir, 'MRthesis/', 'model5_LSS_3-1_all21/', 'EVs/')) \n",
    "             \n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'model5_LSS_3-1_all21/' + 'EVs/' + \n",
    "                   '{0}_all21.txt'.format(curr_set), \n",
    "                   all_mtrx, delimiter = '\\t', fmt = '%.4f')\n",
    "        \n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'model5_LSS_3-1_all21/' + 'EVs/' + \n",
    "                   '{0}_all21_FX_before_COND_corr.txt'.format(curr_set), \n",
    "                   iso_FX_before_COND_corr_mtrx, delimiter = '\\t', fmt = '%.4f')\n",
    "        \n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'model5_LSS_3-1_all21/' + 'EVs/' + \n",
    "                   '{0}_all21_FX_before_COND_incorr.txt'.format(curr_set), \n",
    "                   iso_FX_before_COND_incorr_mtrx, delimiter = '\\t', fmt = '%.4f')\n",
    "        \n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'model5_LSS_3-1_all21/' + 'EVs/' + \n",
    "                   '{0}_all21_all_remaining.txt'.format(curr_set), \n",
    "                   all_remaining_mtrx, delimiter = '\\t', fmt = '%.4f')  \n",
    "        \n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'model5_LSS_3-1_all21/' + 'EVs/' + \n",
    "                   '{0}_all21_nonresponse.txt'.format(curr_set), \n",
    "                   nonresponse_mtrx, delimiter = '\\t', fmt = '%.4f')  \n",
    "        \n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'model5_LSS_3-1_all21/' + 'EVs/' + \n",
    "                   '{0}_all21_last3.txt'.format(curr_set), \n",
    "                   last3_mtrx, delimiter = '\\t', fmt = '%.4f')  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#subs = ['WMAZE_006']\n",
    "\n",
    "subs = ['WMAZE_001', 'WMAZE_002', 'WMAZE_004', 'WMAZE_005', 'WMAZE_006',\n",
    "        'WMAZE_007', 'WMAZE_008', 'WMAZE_009', 'WMAZE_010', 'WMAZE_012',\n",
    "        'WMAZE_017', 'WMAZE_018', 'WMAZE_019', 'WMAZE_020', 'WMAZE_021',\n",
    "        'WMAZE_022', 'WMAZE_023', 'WMAZE_024', 'WMAZE_026', 'WMAZE_027']\n",
    "\n",
    "\n",
    "sets = ['set1', 'set2', 'set3']\n",
    "\n",
    "\n",
    "for sub in subs:\n",
    "    sub_dir = '/home/data/madlab/data/mri/wmaze/scanner_behav/{0}/'.format(sub)\n",
    "    frst_deriv_files = glob(join(sub_dir, 'Bprime_pmode_set*.txt'))    \n",
    "    frst_deriv_files.sort() \n",
    "    behav_runs = glob(join(sub_dir, '{0}_wmazebl_2015*.txt'.format(sub))) \n",
    "    behav_runs.sort()\n",
    "    #print behav_runs\n",
    "    #print frst_deriv_files\n",
    "    \n",
    "    for i, curr_set in enumerate(sets):\n",
    "        behav_run1 = pd.read_table(behav_runs[i*2])\n",
    "        behav_run2 = pd.read_table(behav_runs[i*2+1])\n",
    "        \n",
    "        #removal of the last 3 trials to avoid scanner artifact\n",
    "        behav_run1 = behav_run1[:-3]\n",
    "        #print len(run1)\n",
    "        behav_run2 = behav_run2[:-3]\n",
    "        \n",
    "        behav_set = np.empty(314, dtype=object)    \n",
    "        behav_os = np.empty(314, dtype=object)\n",
    "        behav_acc = np.empty(314, dtype=object)\n",
    "        behav_resp = np.empty(314, dtype=object)\n",
    "        behav_set[:157] = behav_run1['TrialType'].values\n",
    "        behav_set[157:] = behav_run2['TrialType'].values\n",
    "        behav_os[:157] = behav_run1['StimOnset'].values\n",
    "        behav_os[157:] = behav_run2['StimOnset'].values\n",
    "        behav_acc[:157] = behav_run1['Correct'].values\n",
    "        behav_acc[157:] = behav_run2['Correct'].values\n",
    "        behav_resp[:157] = behav_run1['Resp'].values\n",
    "        behav_resp[157:] = behav_run2['Resp'].values\n",
    "        #print behav_set\n",
    "        \n",
    "        deriv_file = np.loadtxt(frst_deriv_files[i])\n",
    "        #print deriv_file[i]\n",
    "        deriv_file = deriv_file[10:]\n",
    "        deriv_file = deriv_file[:-10]\n",
    "        #print len(deriv_file)\n",
    "        #plt.plot(deriv_file) \n",
    "        #grabs the index of the largest derivative\n",
    "        target_trial = np.argmax(deriv_file)+10\n",
    "        #print target_trial\n",
    "\n",
    "        #indices of all Bs in the original dataset\n",
    "        #used to help place the target trial back into ordinal context\n",
    "        b_indices = np.where(behav_set == 'B')[0]\n",
    "        #print type(b_indices)\n",
    "        \n",
    "        #grab the 20 B trials surrounding the target B\n",
    "        b_learning = b_indices[target_trial-10:target_trial+11]\n",
    "        #print b_learning\n",
    "        #grabs the trial immediately preceeding each B isolated\n",
    "        b4_Bs = b_learning-1\n",
    "        #print b4_Bs\n",
    "        \n",
    "        #gets the fixed trial before condition when BLs are between\n",
    "        for i, curr_b4 in enumerate(b4_Bs):\n",
    "            while behav_set[b4_Bs[i]] == \"BL\" or behav_resp[b4_Bs[i]] == \"NR\":\n",
    "                b4_Bs[i] -= 1\n",
    "        #b4_Bs = the indices of the isolated FX before COND trials within the original dataset        \n",
    "        #print b4_Bs\n",
    "        \n",
    "        all_exp_targ = [i for i, resp_val in enumerate(behav_resp) if not i in b4_Bs and resp_val != 'NR']\n",
    "        #print all_exp_targ\n",
    "\n",
    "        \n",
    "        fixed_learning_all21_acc = behav_acc[b_learning]\n",
    "        #print fixed_learning_all21_acc\n",
    "        fl_acc_10before = fixed_learning_all21_acc[:10]\n",
    "        #print fl_acc_10before\n",
    "        fl_acc_10after = fixed_learning_all21_acc[11:]\n",
    "        #print fl_acc_10after\n",
    "        fixed_learning_all21_resp = behav_resp[b_learning]\n",
    "        \n",
    "        \n",
    "        # Categorizing the isolated list into individual regressors\n",
    "        frst10_FX_before_COND_corr = b4_Bs[np.where((fl_acc_10before == 1))]        \n",
    "        #print (iso_FX_before_COND_corr)\n",
    "        frst10_FX_before_COND_incorr = b4_Bs[np.where((fl_acc_10before == 0))]\n",
    "        last10_FX_before_COND_corr = b4_Bs[np.where((fl_acc_10after == 1))]        \n",
    "        #print (iso_FX_before_COND_corr)\n",
    "        last10_FX_before_COND_incorr = b4_Bs[np.where((fl_acc_10after == 0))]\n",
    "        #print (iso_FX_before_COND_incorr)\n",
    "        # all_remaining should contain B, BL, and non-isolated A/C trials, but not NR\n",
    "        all_remaining = np.array(all_exp_targ)\n",
    "        #print all_remaining\n",
    "        nonresponse = np.where((behav_resp == 'NR'))\n",
    "        #print nonresponse\n",
    "        \n",
    "        #grabs onsets   \n",
    "        frst10_FX_before_COND_corr_onsets = behav_os[frst10_FX_before_COND_corr]      \n",
    "        frst10_FX_before_COND_incorr_onsets = behav_os[frst10_FX_before_COND_incorr]\n",
    "        last10_FX_before_COND_corr_onsets = behav_os[last10_FX_before_COND_corr]      \n",
    "        last10_FX_before_COND_incorr_onsets = behav_os[last10_FX_before_COND_incorr]\n",
    "        #grabs onsets for all remaining and nonresponse\n",
    "        all_remaining_onsets = behav_os[all_remaining]\n",
    "        nonresponse_onsets = behav_os[nonresponse]\n",
    "        \n",
    "        all_mtrx = np.vstack((behav_os,\n",
    "                              np.ones(len(behav_os)) * 3.0,\n",
    "                              np.ones(len(behav_os)))).T\n",
    "        \n",
    "               \n",
    "        frst10_FX_before_COND_corr_mtrx = np.vstack((frst10_FX_before_COND_corr_onsets, \n",
    "                                                     np.ones(len(frst10_FX_before_COND_corr_onsets)) * 3.0,\n",
    "                                                     np.ones(len(frst10_FX_before_COND_corr_onsets)))).T\n",
    "        \n",
    "        last10_FX_before_COND_corr_mtrx = np.vstack((last10_FX_before_COND_corr_onsets, \n",
    "                                                    np.ones(len(last10_FX_before_COND_corr_onsets)) * 3.0,\n",
    "                                                    np.ones(len(last10_FX_before_COND_corr_onsets)))).T        \n",
    "        \n",
    "        frst10_FX_before_COND_incorr_mtrx = np.vstack((frst10_FX_before_COND_incorr_onsets, \n",
    "                                                       np.ones(len(frst10_FX_before_COND_incorr_onsets)) * 3.0,\n",
    "                                                       np.ones(len(frst10_FX_before_COND_incorr_onsets)))).T\n",
    "        \n",
    "        last10_FX_before_COND_incorr_mtrx = np.vstack((last10_FX_before_COND_incorr_onsets, \n",
    "                                                       np.ones(len(last10_FX_before_COND_incorr_onsets)) * 3.0,\n",
    "                                                       np.ones(len(last10_FX_before_COND_incorr_onsets)))).T\n",
    "        \n",
    "        all_remaining_mtrx = np.vstack((all_remaining_onsets, \n",
    "                                        np.ones(len(all_remaining_onsets)) * 3.0,\n",
    "                                        np.ones(len(all_remaining_onsets)))).T\n",
    "        \n",
    "        nonresponse_mtrx = np.vstack((nonresponse_onsets, \n",
    "                                      np.ones(len(nonresponse_onsets)) * 3.0,\n",
    "                                      np.ones(len(nonresponse_onsets)))).T\n",
    "        \n",
    "        \n",
    "        if not os.path.exists(join(sub_dir, 'MRthesis/', 'model5_LSS_targ_split10/', 'EVs/')):\n",
    "            os.makedirs(join(sub_dir, 'MRthesis/', 'model5_LSS_targ_split10/', 'EVs/')) \n",
    "\n",
    "             \n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'model5_LSS_targ_split10/' + 'EVs/' + \n",
    "                   '{0}_all_split10.txt'.format(curr_set), \n",
    "                   all_mtrx, delimiter = '\\t', fmt = '%.4f')\n",
    "        \n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'model5_LSS_targ_split10/' + 'EVs/' + \n",
    "                   '{0}_10before_FX_before_COND_corr.txt'.format(curr_set), \n",
    "                   frst10_FX_before_COND_corr_mtrx, delimiter = '\\t', fmt = '%.4f')\n",
    "        \n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'model5_LSS_targ_split10/' + 'EVs/' + \n",
    "                   '{0}_10after_FX_before_COND_corr.txt'.format(curr_set), \n",
    "                   last10_FX_before_COND_corr_mtrx, delimiter = '\\t', fmt = '%.4f')\n",
    "        \n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'model5_LSS_targ_split10/' + 'EVs/' + \n",
    "                   '{0}_10before_FX_before_COND_incorr.txt'.format(curr_set), \n",
    "                   frst10_FX_before_COND_incorr_mtrx, delimiter = '\\t', fmt = '%.4f')\n",
    " \n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'model5_LSS_targ_split10/' + 'EVs/' + \n",
    "                   '{0}_10after_FX_before_COND_incorr.txt'.format(curr_set), \n",
    "                   last10_FX_before_COND_incorr_mtrx, delimiter = '\\t', fmt = '%.4f')\n",
    " \n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'model5_LSS_targ_split10/' + 'EVs/' + \n",
    "                   '{0}_all_remaining.txt'.format(curr_set), \n",
    "                   all_remaining_mtrx, delimiter = '\\t', fmt = '%.4f')  \n",
    "        \n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'model5_LSS_targ_split10/' + 'EVs/' + \n",
    "                   '{0}_nonresponse.txt'.format(curr_set), \n",
    "                   nonresponse_mtrx, delimiter = '\\t', fmt = '%.4f')  \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split10 version -- no distinction concerning accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subs = ['WMAZE_001']\n",
    "\n",
    "#subs = ['WMAZE_001', 'WMAZE_002', 'WMAZE_004', 'WMAZE_005', 'WMAZE_006',\n",
    "#        'WMAZE_007', 'WMAZE_008', 'WMAZE_009', 'WMAZE_010', 'WMAZE_012',\n",
    "#        'WMAZE_017', 'WMAZE_018', 'WMAZE_019', 'WMAZE_020', 'WMAZE_021',\n",
    "#        'WMAZE_022', 'WMAZE_023', 'WMAZE_024', 'WMAZE_026', 'WMAZE_027']\n",
    "\n",
    "\n",
    "sets = ['set1', 'set2', 'set3']\n",
    "\n",
    "\n",
    "for sub in subs:\n",
    "    sub_dir = '/home/data/madlab/data/mri/wmaze/scanner_behav/{0}/'.format(sub)\n",
    "    frst_deriv_files = glob(join(sub_dir, 'Bprime_pmode_set*.txt'))    \n",
    "    frst_deriv_files.sort() \n",
    "    behav_runs = glob(join(sub_dir, '{0}_wmazebl_2015*.txt'.format(sub))) \n",
    "    behav_runs.sort()\n",
    "    #print behav_runs\n",
    "    #print frst_deriv_files\n",
    "    \n",
    "    for i, curr_set in enumerate(sets):\n",
    "        behav_run1 = pd.read_table(behav_runs[i*2])\n",
    "        behav_run2 = pd.read_table(behav_runs[i*2+1])\n",
    "        \n",
    "        #removal of the last 3 trials to avoid scanner artifact\n",
    "        behav_run1 = behav_run1[:-3]\n",
    "        #print len(run1)\n",
    "        behav_run2 = behav_run2[:-3]\n",
    "        \n",
    "        behav_set = np.empty(314, dtype=object)    \n",
    "        behav_os = np.empty(314, dtype=object)\n",
    "        behav_acc = np.empty(314, dtype=object)\n",
    "        behav_resp = np.empty(314, dtype=object)\n",
    "        behav_set[:157] = behav_run1['TrialType'].values\n",
    "        behav_set[157:] = behav_run2['TrialType'].values\n",
    "        behav_os[:157] = behav_run1['StimOnset'].values\n",
    "        behav_os[157:] = behav_run2['StimOnset'].values\n",
    "        behav_acc[:157] = behav_run1['Correct'].values\n",
    "        behav_acc[157:] = behav_run2['Correct'].values\n",
    "        behav_resp[:157] = behav_run1['Resp'].values\n",
    "        behav_resp[157:] = behav_run2['Resp'].values\n",
    "        #print behav_set\n",
    "        \n",
    "        deriv_file = np.loadtxt(frst_deriv_files[i])\n",
    "        #print deriv_file[i]\n",
    "        deriv_file = deriv_file[10:]\n",
    "        deriv_file = deriv_file[:-10]\n",
    "        #print len(deriv_file)\n",
    "        #plt.plot(deriv_file) \n",
    "        #grabs the index of the largest derivative\n",
    "        target_trial = np.argmax(deriv_file)+10\n",
    "        #print target_trial\n",
    "\n",
    "        #indices of all Bs in the original dataset\n",
    "        #used to help place the target trial back into ordinal context\n",
    "        b_indices = np.where(behav_set == 'B')[0]\n",
    "        #print type(b_indices)\n",
    "        \n",
    "        #grab the 20 B trials surrounding the target B\n",
    "        b_learning = b_indices[target_trial-10:target_trial+11]\n",
    "        #print b_learning\n",
    "        #grabs the trial immediately preceeding each B isolated\n",
    "        b4_Bs = b_learning-1\n",
    "        #print b4_Bs\n",
    "        \n",
    "        #gets the fixed trial before condition when BLs are between\n",
    "        for i, curr_b4 in enumerate(b4_Bs):\n",
    "            while behav_set[b4_Bs[i]] == \"BL\" or behav_resp[b4_Bs[i]] == \"NR\":\n",
    "                b4_Bs[i] -= 1\n",
    "        #b4_Bs = the indices of the isolated FX before COND trials within the original dataset        \n",
    "        #print b4_Bs\n",
    "        \n",
    "        all_exp_targ = [i for i, resp_val in enumerate(behav_resp) if not i in b4_Bs and resp_val != 'NR']\n",
    "        #print all_exp_targ\n",
    "\n",
    "        \n",
    "        fixed_learning_all21_acc = behav_acc[b_learning]\n",
    "        #print fixed_learning_all21_acc\n",
    "        fl_acc_10before = fixed_learning_all21_acc[:10]\n",
    "        #print fl_acc_10before\n",
    "        fl_acc_10after = fixed_learning_all21_acc[11:]\n",
    "        #print fl_acc_10after\n",
    "        fixed_learning_all21_resp = behav_resp[b_learning]\n",
    "        \n",
    "        \n",
    "        # Categorizing the isolated list into individual regressors\n",
    "        frst10_FX_before_COND = b4_Bs[:10]        \n",
    "        last10_FX_before_COND = b4_Bs[11:]        \n",
    "        #print (iso_FX_before_COND)\n",
    "\n",
    "        # all_remaining should contain B, BL, and non-isolated A/C trials, but not NR\n",
    "        all_remaining = np.array(all_exp_targ)\n",
    "        #print all_remaining\n",
    "        nonresponse = np.where((behav_resp == 'NR'))\n",
    "        #print nonresponse\n",
    "        \n",
    "        #grabs onsets   \n",
    "        frst10_FX_before_COND_onsets = behav_os[frst10_FX_before_COND] \n",
    "        last10_FX_before_COND_onsets = behav_os[last10_FX_before_COND]\n",
    "        #grabs onsets for all remaining and nonresponse\n",
    "        all_remaining_onsets = behav_os[all_remaining]\n",
    "        nonresponse_onsets = behav_os[nonresponse]\n",
    "        \n",
    "        all_mtrx = np.vstack((behav_os,\n",
    "                              np.ones(len(behav_os)) * 3.0,\n",
    "                              np.ones(len(behav_os)))).T\n",
    "        \n",
    "               \n",
    "        frst10_FX_before_COND_mtrx = np.vstack((frst10_FX_before_COND_onsets, \n",
    "                                                     np.ones(len(frst10_FX_before_COND_onsets)) * 3.0,\n",
    "                                                     np.ones(len(frst10_FX_before_COND_onsets)))).T\n",
    "        \n",
    "        last10_FX_before_COND_mtrx = np.vstack((last10_FX_before_COND_onsets, \n",
    "                                                    np.ones(len(last10_FX_before_COND_onsets)) * 3.0,\n",
    "                                                    np.ones(len(last10_FX_before_COND_onsets)))).T        \n",
    "        \n",
    "        all_remaining_mtrx = np.vstack((all_remaining_onsets, \n",
    "                                        np.ones(len(all_remaining_onsets)) * 3.0,\n",
    "                                        np.ones(len(all_remaining_onsets)))).T\n",
    "        \n",
    "        nonresponse_mtrx = np.vstack((nonresponse_onsets, \n",
    "                                      np.ones(len(nonresponse_onsets)) * 3.0,\n",
    "                                      np.ones(len(nonresponse_onsets)))).T\n",
    "        \n",
    "        \n",
    "        if not os.path.exists(join(sub_dir, 'MRthesis/', 'model5_LSS_noacc_split10/', 'EVs/')):\n",
    "            os.makedirs(join(sub_dir, 'MRthesis/', 'model5_LSS_noacc_split10/', 'EVs/')) \n",
    "\n",
    "             \n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'model5_LSS_noacc_split10/' + 'EVs/' + \n",
    "                   '{0}_all_split10.txt'.format(curr_set), \n",
    "                   all_mtrx, delimiter = '\\t', fmt = '%.4f')\n",
    "        \n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'model5_LSS_noacc_split10/' + 'EVs/' + \n",
    "                   '{0}_10before_FX_before_COND.txt'.format(curr_set), \n",
    "                   frst10_FX_before_COND_mtrx, delimiter = '\\t', fmt = '%.4f')\n",
    " \n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'model5_LSS_noacc_split10/' + 'EVs/' + \n",
    "                   '{0}_10after_FX_before_COND.txt'.format(curr_set), \n",
    "                   last10_FX_before_COND_mtrx, delimiter = '\\t', fmt = '%.4f')\n",
    " \n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'model5_LSS_noacc_split10/' + 'EVs/' + \n",
    "                   '{0}_all_remaining.txt'.format(curr_set), \n",
    "                   all_remaining_mtrx, delimiter = '\\t', fmt = '%.4f')  \n",
    "        \n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'model5_LSS_noacc_split10/' + 'EVs/' + \n",
    "                   '{0}_nonresponse.txt'.format(curr_set), \n",
    "                   nonresponse_mtrx, delimiter = '\\t', fmt = '%.4f')  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
