{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5: Version 3-1\n",
    "## Includes fixed before conditional with intervening BL trials\n",
    "## Collapses fixed A & C trials into a single EV/cope: \"all before_B\"\n",
    "### Models the three last volumes in each run to statistically account for noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/madlab/envs/wmaze_madlab_env/lib/python2.7/site-packages/ipykernel_launcher.py:104: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "/home/data/madlab/envs/wmaze_madlab_env/lib/python2.7/site-packages/ipykernel_launcher.py:105: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "/home/data/madlab/envs/wmaze_madlab_env/lib/python2.7/site-packages/ipykernel_launcher.py:106: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "/home/data/madlab/envs/wmaze_madlab_env/lib/python2.7/site-packages/ipykernel_launcher.py:94: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "/home/data/madlab/envs/wmaze_madlab_env/lib/python2.7/site-packages/ipykernel_launcher.py:96: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "/home/data/madlab/envs/wmaze_madlab_env/lib/python2.7/site-packages/ipykernel_launcher.py:97: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    }
   ],
   "source": [
    "# Array containing subject ids\n",
    "\n",
    "#subs = ['WMAZE_001']\n",
    "\n",
    "subs = ['WMAZE_001', 'WMAZE_002', 'WMAZE_004', 'WMAZE_005', 'WMAZE_006',\n",
    "        'WMAZE_007', 'WMAZE_008', 'WMAZE_009', 'WMAZE_010', 'WMAZE_012',\n",
    "        'WMAZE_017', 'WMAZE_018', 'WMAZE_019', 'WMAZE_020', 'WMAZE_021',\n",
    "        'WMAZE_022', 'WMAZE_023', 'WMAZE_024', 'WMAZE_026', 'WMAZE_027']\n",
    "\n",
    "# Array containing the three sets\n",
    "stim_sets = ['set1', 'set2', 'set3']\n",
    "\n",
    "# Loop to grab correct 6 run text files for each subject\n",
    "for sub in subs:\n",
    "    # Array containing path to behavior files\n",
    "    sub_dir = '/home/data/madlab/data/mri/wmaze/scanner_behav/{0}/'.format(sub)\n",
    "    # Array containing current sub's 6 behavior file runs\n",
    "    dir_file = glob(join(sub_dir, '{0}_wmazebl_2015*.txt'.format(sub)))    \n",
    "    # Sort current sub's txt files in order of run\n",
    "    dir_file.sort() \n",
    "\n",
    "       \n",
    "    # Loop through each of the set types \n",
    "    for i, curr_set in enumerate(stim_sets):\n",
    "        # Create dataframe for text files to extract EVS\n",
    "        run1_orig = pd.read_table(dir_file[i * 2])\n",
    "        run2_orig = pd.read_table(dir_file[i * 2 + 1])\n",
    "        run1_orig_os = run1_orig['StimOnset'].values\n",
    "        run2_orig_os = run2_orig['StimOnset'].values\n",
    "        \n",
    "        \n",
    "        #removal of the last 3 trials to avoid scanner artifact\n",
    "        run1 = run1_orig[:-3]\n",
    "        run2 = run2_orig[:-3]\n",
    "        \n",
    "      \n",
    "        # Remove BL trials -- lets you grab the fixed before conditional with intervening BL trials \n",
    "        noBL_run1 = run1.query('TrialType != \"BL\"')       \n",
    "        noBL_run2 = run2.query('TrialType != \"BL\"') \n",
    "        \n",
    "        # Without BLs\n",
    "        run1_trialtype = noBL_run1['TrialType'].values\n",
    "        run1_correct = noBL_run1['Correct'].values\n",
    "        run1_resp = noBL_run1['Resp'].values\n",
    "        \n",
    "        run2_trialtype = noBL_run2['TrialType'].values\n",
    "        run2_correct = noBL_run2['Correct'].values\n",
    "        run2_resp = noBL_run2['Resp'].values\n",
    "\n",
    " \n",
    "        # Shift the TrialType column up by 1 and insert dummy element into the first index\n",
    "        # Run 1\n",
    "        run1_trial_shift = run1_trialtype[1:] \n",
    "        run1_trial_shift = np.insert(run1_trial_shift, -1, -1)\n",
    "        # Run 2\n",
    "        run2_trial_shift = run2_trialtype[1:]\n",
    "        run2_trial_shift = np.insert(run2_trial_shift, -1, -1)\n",
    "\n",
    "        # Shift the Correct column up by 1 and insert dummy element into the first index\n",
    "        # Run 1\n",
    "        run1_correct_shift = run1_correct[1:]\n",
    "        run1_correct_shift = np.insert(run1_correct_shift, -1, -1)\n",
    "        # Run 2\n",
    "        run2_correct_shift = run2_correct[1:]\n",
    "        run2_correct_shift = np.insert(run2_correct_shift, -1, -1)\n",
    "        \n",
    "        \n",
    "        # Same as above, but maintaining BL trials -- for use in all_remaining EV to model BL trials\n",
    "        # With BLs\n",
    "        run1_trialtypeBL = run1['TrialType'].values\n",
    "        run1_correctBL = run1['Correct'].values\n",
    "        run1_respBL = run1['Resp'].values \n",
    "        run2_trialtypeBL = run2['TrialType'].values\n",
    "        run2_correctBL = run2['Correct'].values\n",
    "        run2_respBL = run2['Resp'].values\n",
    "        \n",
    "        # Shift the TrialType column up by 1 and insert dummy element into the first index\n",
    "        run1_trial_shiftBL = run1_trialtypeBL[1:] \n",
    "        run1_trial_shiftBL = np.insert(run1_trial_shiftBL, -1, -1)\n",
    "        run2_trial_shiftBL = run2_trialtypeBL[1:]\n",
    "        run2_trial_shiftBL = np.insert(run2_trial_shiftBL, -1, -1)\n",
    "\n",
    "        # Same for Correct column\n",
    "        run1_correct_shiftBL = run1_correctBL[1:]\n",
    "        run1_correct_shiftBL = np.insert(run1_correct_shiftBL, -1, -1)\n",
    "        run2_correct_shiftBL = run2_correctBL[1:]\n",
    "        run2_correct_shiftBL = np.insert(run2_correct_shiftBL, -1, -1)\n",
    "       \n",
    "        \n",
    "        # Run 1\n",
    "        run1_all_before_B_corr = np.where((run1_trial_shift == 'B') & (run1_correct_shift == 1))\n",
    "        run1_all_before_B_incorr = np.where((run1_trial_shift == 'B') & (run1_correct_shift == 0))\n",
    "        #grabs all but BL and NR\n",
    "        run1_all_but_BLNR = np.where((run1_trial_shift != 'B') & (run1_resp != 'NR'))\n",
    "        #use separate BL inclusive array to grab BL trials\n",
    "        run1_BL_only = np.where((run1_trialtypeBL == 'BL') & (run1_respBL != 'NR'))\n",
    "        run1_nonresponse = np.where((run1_respBL == 'NR'))\n",
    "                \n",
    "\n",
    "        # Run 2\n",
    "        run2_all_before_B_corr = np.where((run2_trial_shift == 'B') & (run2_correct_shift == 1))\n",
    "        #print run2_A_before_B_corr\n",
    "        run2_all_before_B_incorr = np.where((run2_trial_shift == 'B') & (run2_correct_shift == 0))\n",
    "        run2_all_but_BLNR = np.where((run2_trial_shift != 'B') & (run2_resp != 'NR'))\n",
    "        run2_BL_only = np.where((run2_trialtypeBL == 'BL') & (run2_respBL != 'NR'))\n",
    "        run2_nonresponse = np.where((run2_respBL == 'NR'))\n",
    "\n",
    "\n",
    "        # All onsets\n",
    "        run1_onsets = noBL_run1['StimOnset']\n",
    "        run2_onsets = noBL_run2['StimOnset']\n",
    "        run1BL_onsets = run1['StimOnset']\n",
    "        run2BL_onsets = run2['StimOnset']\n",
    "\n",
    "        # Run 1 \n",
    "        # Only A followed by correct B onsets  \n",
    "        run1_all_before_B_corr_onsets = run1_onsets.values[run1_all_before_B_corr[0]]\n",
    "        # Only A followed by incorrect B onsets \n",
    "        run1_all_before_B_incorr_onsets = run1_onsets.values[run1_all_before_B_incorr[0]]\n",
    "        # All but BL and NR \n",
    "        run1_all_but_BLNR_onsets = run1_onsets.values[run1_all_but_BLNR[0]]\n",
    "        # Just BL trials\n",
    "        run1_BL_only_onsets = run1BL_onsets.values[run1_BL_only[0]]\n",
    "        # Non-response trials\n",
    "        run1_nonresponse_onsets = run1BL_onsets.values[run1_nonresponse[0]]\n",
    "        #print run1_all_but_BLNR_onsets\n",
    "        #print run1_BL_only_onsets          \n",
    "        run1_all_remaining_onsets = np.hstack((run1_all_but_BLNR_onsets, run1_BL_only_onsets))\n",
    "        #print run1_all_remaining\n",
    "        run1_all_remaining_onsets.sort()\n",
    "        #print run1_all_remaining\n",
    "        run1_last3_onsets = run1_orig_os[157:160]\n",
    "        \n",
    "        # Run 2 \n",
    "        run2_all_before_B_corr_onsets = run2_onsets.values[run2_all_before_B_corr[0]] \n",
    "        #print run2_all_before_B_corr_onsets\n",
    "        run2_all_before_B_incorr_onsets = run2_onsets.values[run2_all_before_B_incorr[0]]\n",
    "        run2_all_but_BLNR_onsets = run2_onsets.values[run2_all_but_BLNR[0]]\n",
    "        run2_BL_only_onsets = run2BL_onsets.values[run2_BL_only[0]]\n",
    "        run2_nonresponse_onsets = run2BL_onsets.values[run2_nonresponse[0]]\n",
    "        run2_all_remaining_onsets = np.hstack((run2_all_but_BLNR_onsets, run2_BL_only_onsets))\n",
    "        run2_all_remaining_onsets.sort()\n",
    "        run2_last3_onsets = run2_orig_os[157:160]\n",
    "\n",
    "\n",
    "        # Run 1              \n",
    "        # Use v-stack to create a matrix containing *ALL* onsets, durations, and amplitudes in vertical columns \n",
    "        run1_mtrx = np.vstack((run1_onsets,\n",
    "                               # Numpy array filled with 3's\n",
    "                               np.ones(len(run1_onsets)) * 3.0,\n",
    "                               # Numpy array filled with 1's\n",
    "                               np.ones(len(run1_onsets)))).T\n",
    "\n",
    "        # CORRECT fixed before B ONLY\n",
    "        run1_all_before_B_corr_mtrx = np.vstack((run1_all_before_B_corr_onsets, \n",
    "                                                 np.ones(len(run1_all_before_B_corr_onsets)) * 3.0,\n",
    "                                                 np.ones(len(run1_all_before_B_corr_onsets)))).T\n",
    "\n",
    "        # INCORRECT fixed before B ONLY  \n",
    "        run1_all_before_B_incorr_mtrx = np.vstack((run1_all_before_B_incorr_onsets,\n",
    "                                                   np.ones(len(run1_all_before_B_incorr_onsets)) * 3.0,\n",
    "                                                   np.ones(len(run1_all_before_B_incorr_onsets)))).T\n",
    "\n",
    "\n",
    "        # ALL REMAINING TRIALS\n",
    "        run1_all_remaining_mtrx = np.vstack((run1_all_remaining_onsets,\n",
    "                                             np.ones(len(run1_all_remaining_onsets)) * 3.0,\n",
    "                                             np.ones(len(run1_all_remaining_onsets)))).T\n",
    "        \n",
    "        # NONRESPONSE TRIALS\n",
    "        run1_nonresponse_mtrx = np.vstack((run1_nonresponse_onsets,\n",
    "                                           np.ones(len(run1_nonresponse_onsets)) * 3.0,\n",
    "                                           np.ones(len(run1_nonresponse_onsets)))).T\n",
    "        \n",
    "        # LAST 3 TRIALS\n",
    "        run1_last3_mtrx = np.vstack((run1_last3_onsets,\n",
    "                                     np.ones(len(run1_last3_onsets)) * 3.0,\n",
    "                                     np.ones(len(run1_last3_onsets)))).T\n",
    "        \n",
    "\n",
    "        # RUN 2              \n",
    "        # Use v-stack to create a matrix containing *ALL* onsets, durations, and amplitudes in vertical columns \n",
    "        run2_mtrx = np.vstack((run2_onsets,\n",
    "                               # Numpy array filled with 3's\n",
    "                               np.ones(len(run2_onsets)) * 3.0,\n",
    "                               # Numpy array filled with 1's\n",
    "                               np.ones(len(run2_onsets)))).T\n",
    "\n",
    "        # CORRECT fixed before B ONLY\n",
    "        run2_all_before_B_corr_mtrx = np.vstack((run2_all_before_B_corr_onsets, \n",
    "                                                 np.ones(len(run2_all_before_B_corr_onsets)) * 3.0,\n",
    "                                                 np.ones(len(run2_all_before_B_corr_onsets)))).T\n",
    "\n",
    "        # INCORRECT fixed before B ONLY  \n",
    "        run2_all_before_B_incorr_mtrx = np.vstack((run2_all_before_B_incorr_onsets,\n",
    "                                                   np.ones(len(run2_all_before_B_incorr_onsets)) * 3.0,\n",
    "                                                   np.ones(len(run2_all_before_B_incorr_onsets)))).T\n",
    "\n",
    "        # ALL REMAINING TRIALS\n",
    "        run2_all_remaining_mtrx = np.vstack((run2_all_remaining_onsets,\n",
    "                                             np.ones(len(run2_all_remaining_onsets)) * 3.0,\n",
    "                                             np.ones(len(run2_all_remaining_onsets)))).T\n",
    "        \n",
    "        # NONRESPONSE TRIALS\n",
    "        run2_nonresponse_mtrx = np.vstack((run2_nonresponse_onsets,\n",
    "                                           np.ones(len(run2_nonresponse_onsets)) * 3.0,\n",
    "                                           np.ones(len(run2_nonresponse_onsets)))).T\n",
    "        \n",
    "        # LAST 3 TRIALS\n",
    "        run2_last3_mtrx = np.vstack((run2_last3_onsets,\n",
    "                                     np.ones(len(run2_last3_onsets)) * 3.0,\n",
    "                                     np.ones(len(run2_last3_onsets)))).T\n",
    "        \n",
    "\n",
    "        # If the output directory does not exist\n",
    "        if not os.path.exists(join(sub_dir, 'MRthesis/', 'model5LSS_orig_3-1/', 'EVs/')):\n",
    "            # Create it\n",
    "            os.makedirs(join(sub_dir, 'MRthesis/', 'model5LSS_orig_3-1/', 'EVs/')) \n",
    "\n",
    "\n",
    "        # Run 1     \n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'model5LSS_orig_3-1/' + 'EVs/' + \n",
    "                   'run{0}.txt'.format(i * 2 + 1), \n",
    "                   run1_mtrx, delimiter='\\t', fmt='%.4f')\n",
    "\n",
    "        # A before CORRECT B ONLY\n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'model5LSS_orig_3-1/' + 'EVs/' + \n",
    "                   'run{0}_all_before_B_corr.txt'.format(i * 2 + 1), \n",
    "                   run1_all_before_B_corr_mtrx, delimiter='\\t', fmt='%.4f')\n",
    "\n",
    "        # A before INCORRECT B ONLY\n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'model5LSS_orig_3-1/' + 'EVs/' + \n",
    "                   'run{0}_all_before_B_incorr.txt'.format(i * 2 + 1), \n",
    "                   run1_all_before_B_incorr_mtrx, delimiter='\\t', fmt='%.4f')\n",
    "\n",
    "     \n",
    "        # All-remaining ONLY\n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'model5LSS_orig_3-1/' + 'EVs/' + \n",
    "                   'run{0}_all_remaining.txt'.format(i * 2 + 1), \n",
    "                   run1_all_remaining_mtrx, delimiter='\\t', fmt='%.4f')\n",
    "                   \n",
    "        # Nonresponse ONLY\n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'model5LSS_orig_3-1/' + 'EVs/' + \n",
    "                   'run{0}_nonresponse.txt'.format(i * 2 + 1), \n",
    "                   run1_nonresponse_mtrx, delimiter='\\t', fmt='%.4f')  \n",
    "        \n",
    "        # Last 3 trials ONLY\n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'model5LSS_orig_3-1/' + 'EVs/' + \n",
    "                   'run{0}_last3.txt'.format(i * 2 + 1), \n",
    "                   run1_last3_mtrx, delimiter='\\t', fmt='%.4f')  \n",
    "\n",
    "\n",
    "        # Run 2    \n",
    "        # Create EV text file for Set_-Run 2 ALL onsets/durations/amplitudes\n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'model5LSS_orig_3-1/' + 'EVs/' + \n",
    "                   'run{0}.txt'.format(i * 2 + 2), \n",
    "                   run2_mtrx, delimiter='\\t', fmt='%.4f')\n",
    "\n",
    "        # A before CORRECT B ONLY\n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'model5LSS_orig_3-1/' + 'EVs/' + \n",
    "                   'run{0}_all_before_B_corr.txt'.format(i * 2 + 2), \n",
    "                   run2_all_before_B_corr_mtrx, delimiter='\\t', fmt='%.4f')\n",
    "\n",
    "        # A before INCORRECT B ONLY\n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'model5LSS_orig_3-1/' + 'EVs/' + \n",
    "                   'run{0}_all_before_B_incorr.txt'.format(i * 2 + 2), \n",
    "                   run2_all_before_B_incorr_mtrx, delimiter='\\t', fmt='%.4f')\n",
    "        \n",
    "        # All-remaining ONLY\n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'model5LSS_orig_3-1/' + 'EVs/' + \n",
    "                   'run{0}_all_remaining.txt'.format(i * 2 + 2), \n",
    "                   run2_all_remaining_mtrx, delimiter='\\t', fmt='%.4f')\n",
    "                   \n",
    "        # Nonresponse ONLY\n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'model5LSS_orig_3-1/' + 'EVs/' + \n",
    "                   'run{0}_nonresponse.txt'.format(i * 2 + 2), \n",
    "                   run2_nonresponse_mtrx, delimiter='\\t', fmt='%.4f')\n",
    "        \n",
    "        # Last 3 trials ONLY\n",
    "        np.savetxt(sub_dir + '/MRthesis/' + 'model5LSS_orig_3-1/' + 'EVs/' + \n",
    "                   'run{0}_last3.txt'.format(i * 2 + 2), \n",
    "                   run2_last3_mtrx, delimiter='\\t', fmt='%.4f')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Array containing subject ids\n",
    "\n",
    "#subs = ['WMAZE_001']\n",
    "\n",
    "subs = ['WMAZE_001', 'WMAZE_002', 'WMAZE_003', 'WMAZE_004', 'WMAZE_005',\n",
    "        'WMAZE_006', 'WMAZE_007', 'WMAZE_008', 'WMAZE_009', 'WMAZE_010', \n",
    "        'WMAZE_017', 'WMAZE_018', 'WMAZE_019', 'WMAZE_020', 'WMAZE_021',\n",
    "        'WMAZE_022', 'WMAZE_023', 'WMAZE_024', 'WMAZE_026', 'WMAZE_027']\n",
    "\n",
    "\n",
    "# Array containing the three sets\n",
    "stim_sets = ['set1', 'set2', 'set3']\n",
    "\n",
    "count_table = {}\n",
    "ctstd_table = {}\n",
    "rt_table = {}\n",
    "rtstd_table = {}\n",
    "\n",
    "# Loop to grab correct 6 run text files for each subject\n",
    "for sub in subs:\n",
    "    ct_dict = {}\n",
    "    rt_dict = {}\n",
    "    # Array containing path to behavior files\n",
    "    sub_dir = '/home/data/madlab/data/mri/wmaze/scanner_behav/{0}/'.format(sub)\n",
    "    # Array containing current sub's 6 behavior file runs\n",
    "    dir_file = glob(join(sub_dir, '{0}_wmazebl_2015*.txt'.format(sub)))    \n",
    "    # Sort current sub's txt files in order of run\n",
    "    dir_file.sort() \n",
    "\n",
    "       \n",
    "    # Loop through each of the set types \n",
    "    for i, curr_set in enumerate(stim_sets):\n",
    "        # Create dataframe for text files to extract EVS\n",
    "        # Run 1\n",
    "        run1 = pd.read_table(dir_file[i * 2])\n",
    "        # Run 2\n",
    "        run2 = pd.read_table(dir_file[i * 2 + 1])\n",
    "\n",
    "\n",
    "        noBL_run1 = run1.query('TrialType != \"BL\"')       \n",
    "        noBL_run2 = run2.query('TrialType != \"BL\"')\n",
    "\n",
    "\n",
    "        # Convert dataframes into numpy arrays for trial type and correct/incorrect\n",
    "        # Run 1\n",
    "        run1_trialtype = noBL_run1['TrialType'].values\n",
    "        run1_correct = noBL_run1['Correct'].values\n",
    "        # Run 2\n",
    "        run2_trialtype = noBL_run2['TrialType'].values\n",
    "        run2_correct = noBL_run2['Correct'].values\n",
    "\n",
    "        # Shift the TrialType column up by 1 and insert dummy element into the first index\n",
    "        # Run 1\n",
    "        run1_trial_shift = run1_trialtype[1:] \n",
    "        run1_trial_shift = np.insert(run1_trial_shift, run1_trial_shift.shape[0], -1)\n",
    "        \n",
    "        # Run 2\n",
    "        run2_trial_shift = run2_trialtype[1:]\n",
    "        run2_trial_shift = np.insert(run2_trial_shift, run2_trial_shift.shape[0], -1)\n",
    "\n",
    "        # Shift the Correct column up by 1 and insert dummy element into the first index\n",
    "        # Run 1\n",
    "        run1_correct_shift = run1_correct[1:]\n",
    "        run1_correct_shift = np.insert(run1_correct_shift, -1, -1)\n",
    "        # Run 2\n",
    "        run2_correct_shift = run2_correct[1:]\n",
    "        run2_correct_shift = np.insert(run2_correct_shift, -1, -1)\n",
    "       \n",
    "        \n",
    "        # Run 1\n",
    "        # Grab rows where: correct A before correct B\n",
    "        run1_corr_A_before_corr_B = np.where((run1_trialtype == 'A') & (run1_correct == 1)\n",
    "                                             & (run1_trial_shift == 'B') & (run1_correct_shift == 1))\n",
    "                                             \n",
    "        \n",
    "        # Grab rows where: incorrect A before correct B\n",
    "        run1_incorr_A_before_corr_B = np.where((run1_trialtype == 'A') & (run1_correct == 0)\n",
    "                                               & (run1_trial_shift == 'B') & (run1_correct_shift == 1))\n",
    "                                              \n",
    "        \n",
    "        # Grab rows where: correct A before correct B\n",
    "        run1_corr_A_before_incorr_B = np.where((run1_trialtype == 'A') & (run1_correct == 1)\n",
    "                                               & (run1_trial_shift == 'B') & (run1_correct_shift == 0))\n",
    "                                              \n",
    "        \n",
    "        # Grab rows where: incorrect A before correct B\n",
    "        run1_incorr_A_before_incorr_B = np.where((run1_trialtype == 'A') & (run1_correct == 0)\n",
    "                                                 & (run1_trial_shift == 'B') & (run1_correct_shift == 0))\n",
    "                                                \n",
    "        \n",
    "        # Grab rows where: correct C before correct B\n",
    "        run1_corr_C_before_corr_B = np.where((run1_trialtype == 'C') & (run1_correct == 1)\n",
    "                                             & (run1_trial_shift == 'B') & (run1_correct_shift == 1))\n",
    "                                            \n",
    "        \n",
    "        # Grab rows where: incorrect C after correct B\n",
    "        run1_incorr_C_before_corr_B = np.where((run1_trialtype == 'C') & (run1_correct == 0)\n",
    "                                               & (run1_trial_shift == 'B') & (run1_correct_shift == 1))\n",
    "                                              \n",
    "        \n",
    "        # Grab rows where: correct C after corr or incorrect B\n",
    "        run1_corr_C_before_incorr_B = np.where((run1_trialtype == 'C') & (run1_correct == 1)\n",
    "                                               & (run1_trial_shift == 'B') & (run1_correct_shift == 0))\n",
    "                                              \n",
    "        \n",
    "        # Grab rows where: incorrect C after incorrect B\n",
    "        run1_incorr_C_before_incorr_B = np.where((run1_trialtype == 'C') & (run1_correct == 0) \n",
    "                                                 & (run1_trial_shift == 'B') & (run1_correct_shift == 0))\n",
    "                                                \n",
    "\n",
    "        \n",
    "\n",
    "        # Run 2\n",
    "        # Grab rows where: correct B after corr or incorr A\n",
    "        run2_corr_A_before_corr_B = np.where((run2_trialtype == 'A') & (run2_correct == 1)\n",
    "                                             & (run2_trial_shift == 'B') & (run2_correct_shift == 1))\n",
    "                                            \n",
    "        \n",
    "        # Grab rows where: correct B after incorr A\n",
    "        run2_incorr_A_before_corr_B = np.where((run2_trialtype == 'A') & (run2_correct == 0) \n",
    "                                                &(run2_trial_shift == 'B') & (run2_correct_shift == 1))                                           \n",
    "        \n",
    "        # Grab rows where: incorrect B after corr or incorr A\n",
    "        run2_corr_A_before_incorr_B = np.where((run2_trialtype == 'A') & (run2_correct == 1) \n",
    "                                               & (run2_trial_shift == 'B') & (run2_correct_shift == 0))\n",
    "                                               \n",
    "        # Grab rows where: incorrect B after incorr A\n",
    "        run2_incorr_A_before_incorr_B = np.where((run2_trialtype == 'A') & (run2_correct == 0) \n",
    "                                                 & (run2_trial_shift == 'B') & (run2_correct_shift == 0))\n",
    "                                                \n",
    "        # Grab rows where: correct B after corr or incorr C\n",
    "        run2_corr_C_before_corr_B = np.where((run2_trialtype == 'C') & (run2_correct == 1)\n",
    "                                             & (run2_trial_shift == 'B') & (run2_correct_shift == 1))\n",
    "                                            \n",
    "        # Grab rows where: correct B after incorr C\n",
    "        run2_incorr_C_before_corr_B = np.where((run2_trialtype == 'C') & (run2_correct == 0) \n",
    "                                               & (run2_trial_shift == 'B') & (run2_correct_shift == 1))\n",
    "                                              \n",
    "        # Grab rows where: incorrect B after corr or incorr C\n",
    "        run2_corr_C_before_incorr_B = np.where((run2_trialtype == 'C') & (run2_correct == 1) \n",
    "                                               & (run2_trial_shift == 'B') & (run2_correct_shift == 0))\n",
    "                                              \n",
    "        # Grab rows where: incorrect B after incorr C\n",
    "        run2_incorr_C_before_incorr_B = np.where((run2_trialtype == 'C') & (run2_correct == 0) \n",
    "                                                 & (run2_trial_shift == 'B') & (run2_correct_shift == 0))\n",
    "                                                \n",
    "        #print run1_corr_A_before_corr_B\n",
    "        \n",
    "        # All RTs\n",
    "        run1_RTs = noBL_run1['RT']\n",
    "        run2_RTs = noBL_run2['RT']\n",
    "        \n",
    "        # Run 1  \n",
    "        run1_corr_A_before_corr_B_RTs = run1_RTs.values[run1_corr_A_before_corr_B[0]]\n",
    "        run1_incorr_A_before_corr_B_RTs = run1_RTs.values[run1_incorr_A_before_corr_B[0]]\n",
    "        run1_corr_A_before_incorr_B_RTs = run1_RTs.values[run1_corr_A_before_incorr_B[0]]\n",
    "        run1_incorr_A_before_incorr_B_RTs = run1_RTs.values[run1_incorr_A_before_incorr_B[0]]  \n",
    "        \n",
    "        run1_corr_C_before_corr_B_RTs = run1_RTs.values[run1_corr_C_before_corr_B[0]]\n",
    "        run1_incorr_C_before_corr_B_RTs = run1_RTs.values[run1_incorr_C_before_corr_B[0]]\n",
    "        run1_corr_C_before_incorr_B_RTs = run1_RTs.values[run1_corr_C_before_incorr_B[0]]\n",
    "        run1_incorr_C_before_incorr_B_RTs = run1_RTs.values[run1_incorr_C_before_incorr_B[0]]\n",
    "\n",
    "        # Run 2 \n",
    "        run2_corr_A_before_corr_B_RTs = run2_RTs.values[run2_corr_A_before_corr_B[0]]\n",
    "        run2_incorr_A_before_corr_B_RTs = run2_RTs.values[run2_incorr_A_before_corr_B[0]]\n",
    "        run2_corr_A_before_incorr_B_RTs = run2_RTs.values[run2_corr_A_before_incorr_B[0]]\n",
    "        run2_incorr_A_before_incorr_B_RTs = run2_RTs.values[run2_incorr_A_before_incorr_B[0]]\n",
    "        \n",
    "        run2_corr_C_before_corr_B_RTs = run2_RTs.values[run2_corr_C_before_corr_B[0]]\n",
    "        run2_incorr_C_before_corr_B_RTs = run2_RTs.values[run2_incorr_C_before_corr_B[0]]\n",
    "        run2_corr_C_before_incorr_B_RTs = run2_RTs.values[run2_corr_C_before_incorr_B[0]]\n",
    "        run2_incorr_C_before_incorr_B_RTs = run2_RTs.values[run2_incorr_C_before_incorr_B[0]]\n",
    "    \n",
    "        \n",
    "        #Creation of a flexible naming convention for dictionary keys & contents        \n",
    "        for acc in ['corr', 'incorr']:\n",
    "            for acc2 in ['corr', 'incorr']:\n",
    "                for trialtype in ['A', 'C']:\n",
    "                    curr_name = '{0}_{1}_before_{2}_B'.format(acc, trialtype, acc2)\n",
    "                    rt_name = '{0}_{1}_before_{2}_B_RTs'.format(acc, trialtype, acc2)\n",
    "                    if not curr_name in ct_dict:\n",
    "                        ct_dict[curr_name] = []\n",
    "                    ct_dict[curr_name].append(len(eval('run1_' + curr_name)[0]))\n",
    "                    ct_dict[curr_name].append(len(eval('run2_' + curr_name)[0]))\n",
    "                    if not rt_name in rt_dict:\n",
    "                        rt_dict[rt_name] = []\n",
    "                    rt_eval = eval('run1_' + rt_name)\n",
    "                    # Remove NaN from counts\n",
    "                    rt_notNaN = np.where(rt_eval >= 0)\n",
    "                    rt_notNaN = rt_eval[rt_notNaN[0]]           \n",
    "                    if rt_notNaN.shape[0] == 0:\n",
    "                        rt_dict[rt_name].append(None)                       \n",
    "                    else:\n",
    "                        rt_dict[rt_name].append(np.average(rt_notNaN))\n",
    "                        \n",
    "                    rt_eval = eval('run2_' + rt_name)\n",
    "                    # Remove NaN from RT calculations\n",
    "                    rt_notNaN = np.where(rt_eval >= 0)\n",
    "                    rt_notNaN = rt_eval[rt_notNaN[0]]           \n",
    "                    if rt_notNaN.shape[0] == 0:\n",
    "                        rt_dict[rt_name].append(None)                       \n",
    "                    else:\n",
    "                        rt_dict[rt_name].append(np.average(rt_notNaN))                   \n",
    "    \n",
    "    for key in ct_dict:\n",
    "        ct_dict[key] = np.sum(ct_dict[key])\n",
    "        if not key in count_table:\n",
    "            count_table[key] = []\n",
    "        count_table[key].append(ct_dict[key])\n",
    "        \n",
    "        \n",
    "    for key in rt_dict:\n",
    "        rt_notNONE = np.where(np.array(rt_dict[key]) >= 0)\n",
    "        #print rt_notNONE\n",
    "        rt_dict[key] = np.average(np.array(rt_dict[key])[rt_notNONE[0]])\n",
    "        if not key in rt_table:\n",
    "            rt_table[key] = []\n",
    "        rt_table[key].append(rt_dict[key])\n",
    "\n",
    "        \n",
    "df = pd.DataFrame(count_table, index = subs) \n",
    "df2 = pd.DataFrame(rt_table, index = subs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ct_avg = {}\n",
    "ct_std = {}\n",
    "\n",
    "for curr_key in count_table:\n",
    "    ct_avg[curr_key] = np.average(count_table[curr_key])\n",
    "    ct_std[curr_key] = np.std(count_table[curr_key])\n",
    "    \n",
    "count_average = pd.DataFrame(ct_avg, index = (1,))\n",
    "count_std = pd.DataFrame(ct_std, index = (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 8\n",
    "conditions = ['cA->cB', 'iA->cB', 'cA->iB', 'iA->iB', \n",
    "              'cC->cB', 'iC->cB', 'cC->iB', 'iC->iB']\n",
    "bar_colors = ['blue', 'blue', 'red', 'red', \n",
    "              'green', 'green', 'red', 'red']\n",
    "means_allsubjs = [df['corr_A_before_corr_B'].mean(), \n",
    "                  df['incorr_A_before_corr_B'].mean(),\n",
    "                  df['corr_A_before_incorr_B'].mean(), \n",
    "                  df['incorr_A_before_incorr_B'].mean(), \n",
    "                  df['corr_C_before_corr_B'].mean(), \n",
    "                  df['incorr_C_before_corr_B'].mean(),\n",
    "                  df['corr_C_before_incorr_B'].mean(), \n",
    "                  df['incorr_C_before_incorr_B'].mean()]\n",
    "\n",
    "sem_allsubjs = [df['corr_A_before_corr_B'].std()/(np.sqrt(len(subs))), \n",
    "                df['incorr_A_before_corr_B'].std()/(np.sqrt(len(subs))),\n",
    "                df['corr_A_before_incorr_B'].std()/(np.sqrt(len(subs))),\n",
    "                df['incorr_A_before_incorr_B'].std()/(np.sqrt(len(subs))),\n",
    "                df['corr_C_before_corr_B'].std()/(np.sqrt(len(subs))), \n",
    "                df['incorr_C_before_corr_B'].std()/(np.sqrt(len(subs))),\n",
    "                df['corr_C_before_incorr_B'].std()/(np.sqrt(len(subs))),\n",
    "                df['incorr_C_before_incorr_B'].std()/(np.sqrt(len(subs)))]\n",
    "\n",
    "ind = np.arange(N)\n",
    "width = 0.5\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "ax.bar(ind, means_allsubjs, width, color = bar_colors, ecolor = 'black', \n",
    "       yerr = sem_allsubjs, align = 'center', bottom = 0)\n",
    "\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(conditions)\n",
    "ax.set_xlabel(\"Trial Type\")\n",
    "ax.set_ylabel(\"Average # of Trials\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculations for Reaction Time (across subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 8\n",
    "conditions = ['cA->cB', 'iA->cB', 'cA->iB', 'iA->iB', \n",
    "              'cC->cB', 'iC->cB', 'cC->iB', 'iC->iB']\n",
    "bar_colors = ['blue', 'blue', 'red', 'red', \n",
    "              'green', 'green', 'red', 'red']\n",
    "means_allsubjs = [df2['corr_A_before_corr_B_RTs'].mean(), \n",
    "                  df2['incorr_A_before_corr_B_RTs'].mean(),\n",
    "                  df2['corr_A_before_incorr_B_RTs'].mean(), \n",
    "                  df2['incorr_A_before_incorr_B_RTs'].mean(), \n",
    "                  df2['corr_C_before_corr_B_RTs'].mean(), \n",
    "                  df2['incorr_C_before_corr_B_RTs'].mean(),\n",
    "                  df2['corr_C_before_incorr_B_RTs'].mean(), \n",
    "                  df2['incorr_C_before_incorr_B_RTs'].mean()]\n",
    "\n",
    "sem_allsubjs = [df2['corr_A_before_corr_B_RTs'].std()/(np.sqrt(len(subs))), \n",
    "                df2['incorr_A_before_corr_B_RTs'].std()/(np.sqrt(len(subs))),\n",
    "                df2['corr_A_before_incorr_B_RTs'].std()/(np.sqrt(len(subs))),\n",
    "                df2['incorr_A_before_incorr_B_RTs'].std()/(np.sqrt(len(subs))),\n",
    "                df2['corr_C_before_corr_B_RTs'].std()/(np.sqrt(len(subs))), \n",
    "                df2['incorr_C_before_corr_B_RTs'].std()/(np.sqrt(len(subs))),\n",
    "                df2['corr_C_before_incorr_B_RTs'].std()/(np.sqrt(len(subs))),\n",
    "                df2['incorr_C_before_incorr_B_RTs'].std()/(np.sqrt(len(subs)))]\n",
    "\n",
    "ind = np.arange(N)\n",
    "width = 0.5\n",
    "\n",
    "fig, ax2 = plt.subplots()\n",
    "\n",
    "ax2.spines['right'].set_color('none')\n",
    "ax2.spines['top'].set_color('none')\n",
    "ax2.xaxis.set_ticks_position('bottom')\n",
    "ax2.yaxis.set_ticks_position('left')\n",
    "\n",
    "ax2.bar(ind, means_allsubjs, width, color = bar_colors, ecolor = 'black', \n",
    "       yerr = sem_allsubjs, align = 'center', bottom = 0)\n",
    "\n",
    "ax2.set_xticks(ind)\n",
    "ax2.set_xticklabels(conditions)\n",
    "ax2.set_ylabel(\"Average RT\")\n",
    "ax2.set_xlabel(\"Trial Type\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print \"WMAZE Counts\"\n",
    "# Counts within participanct may not sum to 240 (number of B trials) --\n",
    "# Conditionals require a correct/incorrect response from both A & B trials --\n",
    "# Non-response trials on either will remove trials from that possible total\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rt_average ={}\n",
    "rt_std = {}\n",
    "\n",
    "for curr_key in rt_table:\n",
    "    rt_average[curr_key] = np.average(rt_table[curr_key])\n",
    "    rt_std[curr_key] = np.average(rt_table[curr_key])\n",
    "    \n",
    "RT_average = pd.DataFrame(rt_average, index = (1,))\n",
    "RT_std = pd.DataFrame(rt_std, index = (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RT_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RT_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print \"WMAZE Average RT\"\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
