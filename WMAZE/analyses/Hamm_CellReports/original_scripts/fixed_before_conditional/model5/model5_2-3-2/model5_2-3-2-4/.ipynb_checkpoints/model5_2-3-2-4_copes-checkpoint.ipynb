{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import shutil \n",
    "import os\n",
    "from os.path import join, split, basename\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5 Version 2.3.2.4\n",
    "## Isolating trials of learning -- 11 during learning, 11 after learning\n",
    "### Removing last 3 volumes using FSL ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cope01_FX_before_COND_incorr_run1_trl1_onset5.72.nii.gz\n",
    "def onset_sort(x):\n",
    "    x = x.split('_')[-1]\n",
    "    return(x[5:-8])\n",
    "\n",
    "#subs = ['WMAZE_001']\n",
    "\n",
    "subs = ['WMAZE_002', 'WMAZE_004', 'WMAZE_005', 'WMAZE_006',\n",
    "        'WMAZE_007', 'WMAZE_008', 'WMAZE_009', 'WMAZE_010', 'WMAZE_012',\n",
    "        'WMAZE_017', 'WMAZE_018', 'WMAZE_019', 'WMAZE_020', 'WMAZE_021',\n",
    "        'WMAZE_022', 'WMAZE_023', 'WMAZE_024', 'WMAZE_026', 'WMAZE_027']\n",
    "\n",
    "\n",
    "sets = ['set1', 'set2', 'set3']\n",
    "runs = ['run1', 'run2', 'run3', 'run4', 'run5', 'run6']\n",
    "\n",
    "\n",
    "for sub in subs:\n",
    "    sub_dir = '/home/data/madlab/data/mri/wmaze/'\n",
    "    \n",
    "    #grab the derivative files created from the set-based learning analysis\n",
    "    frst_deriv_files = glob(join(sub_dir, \n",
    "                                 'scanner_behav/{0}/Bprime_pmode_set*.txt'.format(sub))) \n",
    "    frst_deriv_files.sort() \n",
    "    \n",
    "    #grab the learning curve file for B trials\n",
    "    learning_files = glob(join(sub_dir, 'scanner_behav/{0}/B_pmode_set*.txt'.format(sub))) \n",
    "    learning_files.sort()\n",
    "    \n",
    "    #grab the 95% confidence file for B trials\n",
    "    upper_95_files = glob(join(sub_dir, \n",
    "                               'scanner_behav/{0}/B_p95_set*.txt'.format(sub)))\n",
    "    upper_95_files.sort()\n",
    "    \n",
    "    #grab all cope files created by LSS Model 5\n",
    "    cope_files = glob(join(sub_dir, \n",
    "                          'frstlvl/wmaze_MRthesis/fixed_before_condional/model5_2-3-2/{0}/'.format(sub),\n",
    "                          'modelfit/contrasts/_estimate_model*/cope*_FX_before_COND_*corr_run*_trl*.nii.gz'))     \n",
    "    cope_files.sort()\n",
    "    \n",
    "    #grab the behavioral files for all runs\n",
    "    behav_runs = glob(join(sub_dir, \n",
    "                           'scanner_behav/{0}/{0}_wmazebl_2015*.txt'.format(sub))) \n",
    "    behav_runs.sort()\n",
    "    \n",
    "    os.makedirs(join('/home/data/madlab/data/mri/wmaze/frstlvl/wmaze_MRthesis/',\n",
    "                     'fixed_before_condional/model5_2-3-2-4/{0}/learning_window/'.format(sub)))\n",
    "    \n",
    "    os.makedirs(join('/home/data/madlab/data/mri/wmaze/frstlvl/wmaze_MRthesis/',\n",
    "                     'fixed_before_condional/model5_2-3-2-4/{0}/after_window/'.format(sub)))\n",
    "    \n",
    "    \n",
    "    #### LOADING AND ORGANIZING THE COPE FILES ####\n",
    "    all_runs = []\n",
    "    for curr_run in runs:\n",
    "        #selects only the cope files containing the current run's number\n",
    "        curr_run_files = np.array([f for f in cope_files if curr_run in f])\n",
    "        #gets the onset time out of the file names using function\n",
    "        onset_nums = [float(onset_sort(f)) for f in curr_run_files]\n",
    "        sorted_nums = np.argsort(onset_nums)\n",
    "        #arranges the actual files according to onset time\n",
    "        curr_run_files = curr_run_files[sorted_nums]\n",
    "        all_runs.append(curr_run_files)\n",
    "        \n",
    "    \n",
    "    for i, curr_set in enumerate(sets):\n",
    "        #load derivative, learning, and p95 files\n",
    "        deriv_file = np.loadtxt(frst_deriv_files[i])\n",
    "        learning_curve = np.loadtxt(learning_files[i]) \n",
    "        upper_95 = np.loadtxt(upper_95_files[i])\n",
    "        \n",
    "        #### COPE FILES ####\n",
    "        #merge the two runs into one array for the current stim set\n",
    "        curr_set_copes = np.concatenate((all_runs[i*2], all_runs[i*2+1]))\n",
    "        #print len(curr_set_copes) \n",
    "        \n",
    "        \n",
    "        #### GETTING THE DERIV FILES TO MATCH NUMBER OF COPES ####\n",
    "        #load behavioral files\n",
    "        behav_run1 = pd.read_table(behav_runs[i*2])\n",
    "        behav_run2 = pd.read_table(behav_runs[i*2+1])\n",
    "        #info concerning onset time\n",
    "        behav_os = np.empty(320, dtype=object)\n",
    "        behav_os[:160] = behav_run1['StimOnset'].values\n",
    "        behav_os[160:] = behav_run2['StimOnset'].values\n",
    "        #info concerning subject response\n",
    "        behav_resp = np.empty(320, dtype=object)\n",
    "        behav_resp[:160] = behav_run1['Resp'].values\n",
    "        behav_resp[160:] = behav_run2['Resp'].values\n",
    "        #info concerning trial type\n",
    "        behav_type = np.empty(320, dtype=object)\n",
    "        behav_type[:160] = behav_run1['TrialType'].values\n",
    "        behav_type[160:] = behav_run2['TrialType'].values       \n",
    "        \n",
    "        #indices of all Bs in the original dataset\n",
    "        b_indices = np.where(behav_type == 'B')[0]       \n",
    "        bad_Bs = []\n",
    "                \n",
    "        for curr_B in b_indices:\n",
    "            #identify in B trials which are non-response\n",
    "            if behav_resp[curr_B] == 'NR': \n",
    "                bad_Bs.append(curr_B)\n",
    "            #indices for last 3 trials of each run or if B trial comes first (observed on 001 run 6)    \n",
    "            if curr_B in [0, 157, 158, 159, 160, 317, 318, 319]: \n",
    "                bad_Bs.append(curr_B)\n",
    "        bad_Bs.sort()       \n",
    "        #get the indices for the bad Bs within the entire group of Bs\n",
    "        bad_B_ind = [j for j, f in enumerate(b_indices) if f in bad_Bs] \n",
    "        bad_B_ind.sort()\n",
    "        #reverse order of Bs to be removed\n",
    "        bad_B_ind = bad_B_ind[::-1]\n",
    "        \n",
    "        #LEARNING CURVE FILES\n",
    "        #create a temp version of learning_curve\n",
    "        temp2 = list(learning_curve)\n",
    "        #pop out the bad Bs starting from the end\n",
    "        for curr_bad_B in bad_B_ind:\n",
    "            temp2.pop(curr_bad_B)\n",
    "        #save without the removed Bs    \n",
    "        new_learning = np.array(temp2)\n",
    "        alt_learning_curve = new_learning[10:-17]\n",
    "        \n",
    "        #P95 FILES\n",
    "        #create a temp version of upper_95\n",
    "        temp3 = list(upper_95)\n",
    "        #pop out the bad Bs starting from the end\n",
    "        for curr_bad_B in bad_B_ind:\n",
    "            temp3.pop(curr_bad_B)\n",
    "        #save without the removed Bs    \n",
    "        new_upper_95 = np.array(temp3)\n",
    "        alt_upper_95 = new_upper_95[10:-17]\n",
    "        #print len(new_upper_95)\n",
    "        \n",
    "        # Condition to select subjects and sets that exhibit learning\n",
    "        if np.mean(new_learning[-10:]) > np.mean(new_upper_95[:10]):\n",
    "            #DERIV FILES\n",
    "            #create a temp version of deriv_file\n",
    "            temp = list(deriv_file)\n",
    "            #pop out the bad Bs starting from the end\n",
    "            for curr_bad_B in bad_B_ind:\n",
    "                temp.pop(curr_bad_B)\n",
    "            #save the deriv_file without the removed Bs    \n",
    "            new_deriv = np.array(temp)\n",
    "            alt_deriv_file = new_deriv[10:-17]\n",
    "            #target_trial = np.argmax(new_deriv)\n",
    "            #grabs the index of the largest derivative\n",
    "            alt_target_trial = np.argmax(alt_deriv_file)+10\n",
    "            #print alt_target_trial\n",
    "            #remove the bad Bs from the B-list\n",
    "            temp4 = list(b_indices)\n",
    "            for curr_bad_B in bad_B_ind:\n",
    "                temp4.pop(curr_bad_B)\n",
    "            new_Bs = np.array(temp4)\n",
    "            #convert original behavioral file indices to new B-specific index\n",
    "            new_indices_B = []\n",
    "            for m, curr_new_B in enumerate(new_Bs):\n",
    "                new_indices_B.append(m)\n",
    "            new_indices_B = np.array(new_indices_B)                     \n",
    "            #grabs the 20 B trials surrounding the target trial\n",
    "            b_learning = new_indices_B[alt_target_trial-5:alt_target_trial+6]\n",
    "            #grabs the 21 B trials after learning block\n",
    "            b_after = new_indices_B[alt_target_trial+6:alt_target_trial+17]  \n",
    "            fixed_learning_files = curr_set_copes[b_learning]\n",
    "            fixed_after_files = curr_set_copes[b_after] \n",
    "            \n",
    "            #copy and save selected learning files to new folder for merge script\n",
    "            for curr_learning in fixed_learning_files:\n",
    "                learning_basename =  os.path.basename(curr_learning)  \n",
    "                shutil.copy2(curr_learning,\n",
    "                             join('/home/data/madlab/data/mri/wmaze/frstlvl/wmaze_MRthesis/',\n",
    "                                  'fixed_before_condional/model5_2-3-2-4/{0}/'.format(sub),\n",
    "                                  'learning_window/{0}'.format(learning_basename)))\n",
    "               \n",
    "            #copy and save selected after files to new folder for merge script   \n",
    "            for curr_after in fixed_after_files:\n",
    "                after_basename =  os.path.basename(curr_after)\n",
    "                shutil.copy2(curr_after,\n",
    "                             join('/home/data/madlab/data/mri/wmaze/frstlvl/wmaze_MRthesis/',\n",
    "                                  'fixed_before_condional/model5_2-3-2-4/{0}/'.format(sub),\n",
    "                                  'after_window/{0}'.format(after_basename)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
