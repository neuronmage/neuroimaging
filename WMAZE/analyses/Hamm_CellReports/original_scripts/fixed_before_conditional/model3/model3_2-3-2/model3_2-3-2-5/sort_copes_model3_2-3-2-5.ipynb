{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 Version 2.3.2.5\n",
    "## Isolating trials of learning -- positive derivative value, negative derivative value\n",
    "### Removing last 3 volumes using FSL ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB 63 [  6   8  10  15  20  23  30  35  39  45  48  50  58  71  74  76  79  93\n",
      "  96 101 103 109 112 115 119 124 128 130 136 145 147 153 156 168 176 185\n",
      " 188 192 197 205 207 211 213 218 222 229 231 235 237 252 256 258 260 263\n",
      " 268 274 278 282 300 307 309 312 316]\n",
      "GB 61 [  1   6   8  11  15  19  29  32  35  39  45  51  62  69  76  78  81  86\n",
      "  99 102 104 113 116 123 128 132 138 143 148 150 154 162 164 179 185 191\n",
      " 194 196 200 207 213 218 222 225 229 231 237 240 242 247 254 258 268 272\n",
      " 274 278 282 285 290 294 309]\n",
      "GB 58 [  1   5  17  30  34  37  40  43  51  58  60  70  73  75  78  88  90  95\n",
      "  98 101 105 113 117 120 124 137 140 147 151 154 156 162 165 168 171 175\n",
      " 178 181 205 209 216 219 225 229 231 243 246 264 270 274 283 286 288 292\n",
      " 296 298 309 312]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"        \\n        #copy and save selected learning files to new folder for merge script\\n        for curr_learning in fixed_learning_files:\\n            learning_basename =  os.path.basename(curr_learning)  \\n            shutil.copy2(curr_learning,\\n                         join('/home/data/madlab/data/mri/wmaze/frstlvl/wmaze_MRthesis/',\\n                              'fixed_before_conditional/model3_2-3-2-5/{0}/'.format(sub),\\n                              'learning/{0}'.format(learning_basename)))\\n\\n        #copy and save selected after files to new folder for merge script   \\n        for curr_nonlearning in fixed_nonlearning_files:\\n            nonlearning_basename =  os.path.basename(curr_nonlearning)\\n            shutil.copy2(curr_nonlearning,\\n                         join('/home/data/madlab/data/mri/wmaze/frstlvl/wmaze_MRthesis/',\\n                              'fixed_before_conditional/model3_2-3-2-5/{0}/'.format(sub),\\n                              'nonlearning/{0}'.format(nonlearning_basename)))\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import shutil \n",
    "import os\n",
    "from os.path import join, split, basename\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from pylab import *\n",
    "\n",
    "#cope01_FX_before_COND_incorr_run1_trl1_onset5.72.nii.gz\n",
    "def onset_sort(x):\n",
    "    x = x.split('_')[-1]\n",
    "    return(x[5:-8])\n",
    "\n",
    "subs = ['WMAZE_005']\n",
    "'''\n",
    "subs = ['WMAZE_002', 'WMAZE_004', 'WMAZE_005', 'WMAZE_006',\n",
    "        'WMAZE_007', 'WMAZE_008', 'WMAZE_009', 'WMAZE_010', 'WMAZE_012',\n",
    "        'WMAZE_017', 'WMAZE_018', 'WMAZE_019', 'WMAZE_020', 'WMAZE_021',\n",
    "        'WMAZE_022', 'WMAZE_023', 'WMAZE_024', 'WMAZE_026', 'WMAZE_027']\n",
    "'''\n",
    "\n",
    "sets = ['set1', 'set2', 'set3']\n",
    "runs = ['run1', 'run2', 'run3', 'run4', 'run5', 'run6']\n",
    "\n",
    "\n",
    "for sub in subs:\n",
    "    sub_dir = '/home/data/madlab/data/mri/wmaze/'\n",
    "    \n",
    "    #grab the derivative files created from the set-based learning analysis\n",
    "    frst_deriv_files = glob(join(sub_dir, \n",
    "                                 'scanner_behav/{0}/Bprime_pmode_set*.txt'.format(sub))) \n",
    "    frst_deriv_files.sort() \n",
    "    \n",
    "    #grab the learning curve file for B trials\n",
    "    learning_files = glob(join(sub_dir, 'scanner_behav/{0}/B_pmode_set*.txt'.format(sub))) \n",
    "    learning_files.sort()\n",
    "    \n",
    "    #grab the 95% confidence file for B trials\n",
    "    upper_95_files = glob(join(sub_dir, \n",
    "                               'scanner_behav/{0}/B_p95_set*.txt'.format(sub)))\n",
    "    upper_95_files.sort()\n",
    "    \n",
    "    #grab all cope files created by LSS Model 5\n",
    "    cope_files = glob(join(sub_dir, \n",
    "                          'frstlvl/wmaze_MRthesis/fixed_before_conditional/model3_2-3-2/{0}/'.format(sub),\n",
    "                          'modelfit/contrasts/_estimate_model*/cope*_FX_before_COND_*corr_run*_trl*.nii.gz'))     \n",
    "    cope_files.sort()\n",
    "    \n",
    "    #grab the behavioral files for all runs\n",
    "    behav_runs = glob(join(sub_dir, \n",
    "                           'scanner_behav/{0}/{0}_wmazebl_2015*.txt'.format(sub))) \n",
    "    behav_runs.sort()\n",
    "    \n",
    "    #os.makedirs(join('/home/data/madlab/data/mri/wmaze/frstlvl/wmaze_MRthesis/',\n",
    "                     #'fixed_before_conditional/model3_2-3-2-5_test/{0}/learning/'.format(sub)))\n",
    "    \n",
    "    #os.makedirs(join('/home/data/madlab/data/mri/wmaze/frstlvl/wmaze_MRthesis/',\n",
    "                    # 'fixed_before_conditional/model3_2-3-2-5/{0}_test/nonlearning/'.format(sub)))\n",
    "    \n",
    "    \n",
    "    #### LOADING AND ORGANIZING THE COPE FILES ####\n",
    "    all_runs = []\n",
    "    for curr_run in runs:\n",
    "        #selects only the cope files containing the current run's number\n",
    "        curr_run_files = np.array([f for f in cope_files if curr_run in f])\n",
    "        #gets the onset time out of the file names using function\n",
    "        onset_nums = [float(onset_sort(f)) for f in curr_run_files]\n",
    "        sorted_nums = np.argsort(onset_nums)\n",
    "        #arranges the actual files according to onset time\n",
    "        curr_run_files = curr_run_files[sorted_nums]\n",
    "        all_runs.append(curr_run_files)\n",
    "        \n",
    "    \n",
    "    for i, curr_set in enumerate(sets):\n",
    "        #load derivative, learning, and p95 files\n",
    "        deriv_file = np.loadtxt(frst_deriv_files[i])\n",
    "        learning_curve = np.loadtxt(learning_files[i]) \n",
    "        upper_95 = np.loadtxt(upper_95_files[i])\n",
    "        \n",
    "        #### COPE FILES ####\n",
    "        #merge the two runs into one array for the current stim set\n",
    "        curr_set_copes = np.concatenate((all_runs[i*2], all_runs[i*2+1])) \n",
    "        \n",
    "        \n",
    "        #### GETTING THE DERIV FILES TO MATCH NUMBER OF COPES ####\n",
    "        #load behavioral files\n",
    "        behav_run1 = pd.read_table(behav_runs[i*2])\n",
    "        behav_run2 = pd.read_table(behav_runs[i*2+1])\n",
    "        \n",
    "        #info concerning onset time\n",
    "        behav_os = np.empty(320, dtype=object)\n",
    "        behav_os[:160] = behav_run1['StimOnset'].values\n",
    "        behav_os[160:] = behav_run2['StimOnset'].values\n",
    "        \n",
    "        #info concerning subject response\n",
    "        behav_resp = np.empty(320, dtype=object)\n",
    "        behav_resp[:160] = behav_run1['Resp'].values\n",
    "        behav_resp[160:] = behav_run2['Resp'].values\n",
    "        \n",
    "        #info concerning trial type\n",
    "        behav_type = np.empty(320, dtype=object)\n",
    "        behav_type[:160] = behav_run1['TrialType'].values\n",
    "        behav_type[160:] = behav_run2['TrialType'].values\n",
    "        \n",
    "        trial_shift = behav_type[:-1] \n",
    "        trial_shift = np.insert(trial_shift, 0, -1)\n",
    "        \n",
    "        #indices of all Bs in the original dataset without preceeding BL trials\n",
    "        b_indices = np.where((behav_type == 'B'))[0]\n",
    "        #grabs B trials with preceeding BLs\n",
    "        b_BL_indices = np.where((behav_type == 'B') & (trial_shift == 'BL'))[0]       \n",
    "        \n",
    "        #isolate bad Bs for removal in learning curve/derivative/p95 files\n",
    "        bad_Bs = [] \n",
    "        bad_Bs.extend(b_BL_indices)\n",
    "        for curr_B in b_indices:\n",
    "            if not curr_B in bad_Bs:\n",
    "                #identify in B trials which are non-response\n",
    "                if behav_resp[curr_B] == 'NR': \n",
    "                    bad_Bs.append(curr_B)\n",
    "                #indices if B trial comes first (observed on 001 run 6)    \n",
    "                if curr_B in [0, 157, 158, 159, 160, 317, 318, 319]: \n",
    "                    bad_Bs.append(curr_B)\n",
    "        bad_Bs.sort() \n",
    "        #print bad_Bs       \n",
    "        \n",
    "        #get the indices for the bad Bs within the group of Bs\n",
    "        bad_B_ind = [j for j, f in enumerate(b_indices) if f in bad_Bs] \n",
    "        bad_B_ind.sort()\n",
    "        #reverse order of Bs to be removed\n",
    "        bad_B_ind = bad_B_ind[::-1]\n",
    "        #print len(bad_B_ind)\n",
    "                      \n",
    "        #LEARNING CURVE FILES\n",
    "        #create a temp version of learning_curve\n",
    "        temp2 = list(learning_curve)\n",
    "        #pop out the bad Bs starting from the end\n",
    "        for curr_bad_B in bad_B_ind:\n",
    "            temp2.pop(curr_bad_B)\n",
    "        #save without the removed Bs    \n",
    "        new_learning = np.array(temp2)\n",
    "        #print len(new_learning)\n",
    "        \n",
    "        #P95 FILES\n",
    "        temp3 = list(upper_95)\n",
    "        for curr_bad_B in bad_B_ind:\n",
    "            temp3.pop(curr_bad_B)  \n",
    "        # new upper 95% without bad Bs    \n",
    "        new_upper_95 = np.array(temp3)\n",
    "        #print len(new_upper_95)\n",
    "                \n",
    "        \n",
    "        #DERIV FILES\n",
    "        temp = list(deriv_file)\n",
    "        for curr_bad_B in bad_B_ind:\n",
    "            temp.pop(curr_bad_B)   \n",
    "        new_deriv = np.array(temp[:-1])\n",
    "        #print new_deriv\n",
    "        #print len(deriv_file)\n",
    "        learning = np.where(new_deriv > 0)[0]\n",
    "        nonlearning = np.where(new_deriv <= 0)[0]\n",
    "        #print \"learning\"\n",
    "        #print learning\n",
    "        #print \"nonlearning\"\n",
    "        #print nonlearning\n",
    "         \n",
    "        #remove the bad Bs from the B-list\n",
    "        temp4 = list(b_indices)\n",
    "        for curr_bad_B in bad_B_ind:\n",
    "            temp4.pop(curr_bad_B)\n",
    "        good_Bs = np.array(temp4)\n",
    "        print \"GB\", len(good_Bs), good_Bs\n",
    "        \n",
    "\n",
    "        #convert original behavioral file indices to new B-specific index\n",
    "        new_indices_B = []\n",
    "        for n, curr_new_B in enumerate(good_Bs):\n",
    "            new_indices_B.append(n)\n",
    "        new_indices_B = np.array(new_indices_B)\n",
    "        #print \"New Bs\"\n",
    "        #print new_indices_B        \n",
    "        #print new_indices_B\n",
    "        #grabs the B trials with a positive value derivative\n",
    "        b_learning = new_indices_B[learning]\n",
    "        #print b_learning\n",
    "        #print len(curr_set_copes)\n",
    "        #grabs the B trials with a zero or negative value derivative\n",
    "        b_nonlearning = new_indices_B[nonlearning]\n",
    "        #print b_nonlearning\n",
    "        fixed_learning_files = curr_set_copes[b_learning]\n",
    "        fixed_nonlearning_files = curr_set_copes[b_nonlearning] \n",
    "        \n",
    "        \n",
    "'''        \n",
    "        #copy and save selected learning files to new folder for merge script\n",
    "        for curr_learning in fixed_learning_files:\n",
    "            learning_basename =  os.path.basename(curr_learning)  \n",
    "            shutil.copy2(curr_learning,\n",
    "                         join('/home/data/madlab/data/mri/wmaze/frstlvl/wmaze_MRthesis/',\n",
    "                              'fixed_before_conditional/model3_2-3-2-5/{0}/'.format(sub),\n",
    "                              'learning/{0}'.format(learning_basename)))\n",
    "\n",
    "        #copy and save selected after files to new folder for merge script   \n",
    "        for curr_nonlearning in fixed_nonlearning_files:\n",
    "            nonlearning_basename =  os.path.basename(curr_nonlearning)\n",
    "            shutil.copy2(curr_nonlearning,\n",
    "                         join('/home/data/madlab/data/mri/wmaze/frstlvl/wmaze_MRthesis/',\n",
    "                              'fixed_before_conditional/model3_2-3-2-5/{0}/'.format(sub),\n",
    "                              'nonlearning/{0}'.format(nonlearning_basename)))\n",
    "'''        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
