{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 Version 2.3.2.4\n",
    "## Isolating trials of learning -- 7 during learning, 7 after learning\n",
    "### Removing last 3 volumes using FSL ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import shutil \n",
    "import os\n",
    "from os.path import join, split, basename\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Bs before BLs [  9  16  28  37  48  51  64  86  94 104 110 136 139 152 174 177 202 207\n",
      " 221 236 248 272 280 290 304 315]\n",
      "# Bs w/o BLs [  1  12  18  23  30  33  42  44  54  59  66  70  76  79  88 100 114 118\n",
      " 121 123 127 131 143 147 154 158 161 163 166 171 180 185 188 193 209 213\n",
      " 216 223 227 232 238 245 250 256 262 266 268 283 293 295 300 308 311 318]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-809ccfbdae05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mbad_Bs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_BL_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcurr_B\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mb_wo_BL_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcurr_B\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbad_Bs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m                 \u001b[0;31m#identify in B trials which are non-response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbehav_resp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurr_B\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'NR'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "#cope01_FX_before_COND_incorr_run1_trl1_onset5.72.nii.gz\n",
    "def onset_sort(x):\n",
    "    x = x.split('_')[-1]\n",
    "    return(x[5:-8])\n",
    "\n",
    "subs = ['WMAZE_010']\n",
    "'''\n",
    "subs = ['WMAZE_002', 'WMAZE_004', 'WMAZE_005', 'WMAZE_006',\n",
    "        'WMAZE_007', 'WMAZE_008', 'WMAZE_009', 'WMAZE_010', 'WMAZE_012',\n",
    "        'WMAZE_017', 'WMAZE_018', 'WMAZE_019', 'WMAZE_020', 'WMAZE_021',\n",
    "        'WMAZE_022', 'WMAZE_023', 'WMAZE_024', 'WMAZE_026', 'WMAZE_027']\n",
    "'''\n",
    "\n",
    "sets = ['set1', 'set2', 'set3']\n",
    "runs = ['run1', 'run2', 'run3', 'run4', 'run5', 'run6']\n",
    "\n",
    "\n",
    "for sub in subs:\n",
    "    sub_dir = '/home/data/madlab/data/mri/wmaze/'\n",
    "    \n",
    "    #grab the derivative files created from the set-based learning analysis\n",
    "    frst_deriv_files = glob(join(sub_dir, \n",
    "                                 'scanner_behav/{0}/Bprime_pmode_set*.txt'.format(sub))) \n",
    "    frst_deriv_files.sort() \n",
    "    \n",
    "    #grab the learning curve file for B trials\n",
    "    learning_files = glob(join(sub_dir, 'scanner_behav/{0}/B_pmode_set*.txt'.format(sub))) \n",
    "    learning_files.sort()\n",
    "    \n",
    "    #grab the 95% confidence file for B trials\n",
    "    upper_95_files = glob(join(sub_dir, \n",
    "                               'scanner_behav/{0}/B_p95_set*.txt'.format(sub)))\n",
    "    upper_95_files.sort()\n",
    "    \n",
    "    #grab all cope files created by LSS Model 5\n",
    "    cope_files = glob(join(sub_dir, \n",
    "                          'frstlvl/wmaze_MRthesis/fixed_before_conditional/model3_2-3-2/{0}/'.format(sub),\n",
    "                          'modelfit/contrasts/_estimate_model*/cope*_FX_before_COND_*corr_run*_trl*.nii.gz'))     \n",
    "    cope_files.sort()\n",
    "    #print cope_files\n",
    "    \n",
    "    #grab the behavioral files for all runs\n",
    "    behav_runs = glob(join(sub_dir, \n",
    "                           'scanner_behav/{0}/{0}_wmazebl_2015*.txt'.format(sub))) \n",
    "    behav_runs.sort()\n",
    "    '''\n",
    "    os.makedirs(join('/home/data/madlab/data/mri/wmaze/frstlvl/wmaze_MRthesis/',\n",
    "                     'fixed_before_conditional/model3_2-3-2-4/11-11window/{0}/learning_window/'.format(sub)))\n",
    "    \n",
    "    os.makedirs(join('/home/data/madlab/data/mri/wmaze/frstlvl/wmaze_MRthesis/',\n",
    "                     'fixed_before_conditional/model3_2-3-2-4/11-11window/{0}/after_window/'.format(sub)))\n",
    "    '''\n",
    "    \n",
    "    #### LOADING AND ORGANIZING THE COPE FILES ####\n",
    "    all_runs = []\n",
    "    for curr_run in runs:\n",
    "        #selects only the cope files containing the current run's number\n",
    "        curr_run_files = np.array([f for f in cope_files if curr_run in f])\n",
    "        #gets the onset time out of the file names using function\n",
    "        onset_nums = [float(onset_sort(f)) for f in curr_run_files]\n",
    "        sorted_nums = np.argsort(onset_nums)\n",
    "        #arranges the actual files according to onset time\n",
    "        curr_run_files = curr_run_files[sorted_nums]\n",
    "        all_runs.append(curr_run_files)\n",
    "        \n",
    "    \n",
    "    for i, curr_set in enumerate(sets):\n",
    "        #load derivative, learning, and p95 files\n",
    "        deriv_file = np.loadtxt(frst_deriv_files[i])\n",
    "        learning_curve = np.loadtxt(learning_files[i]) \n",
    "        upper_95 = np.loadtxt(upper_95_files[i])\n",
    "        \n",
    "        #### COPE FILES ####\n",
    "        #merge the two runs into one array for the current stim set\n",
    "        curr_set_copes = np.concatenate((all_runs[i*2], all_runs[i*2+1]))\n",
    "        #print len(curr_set_copes) \n",
    "        \n",
    "        \n",
    "        #### GETTING THE DERIV FILES TO MATCH NUMBER OF COPES ####\n",
    "        #load behavioral files\n",
    "        behav_run1 = pd.read_table(behav_runs[i*2])\n",
    "        behav_run2 = pd.read_table(behav_runs[i*2+1])\n",
    "        \n",
    "        \n",
    "        #info concerning onset time\n",
    "        behav_os = np.empty(320, dtype=object)\n",
    "        behav_os[:160] = behav_run1['StimOnset'].values\n",
    "        behav_os[160:] = behav_run2['StimOnset'].values\n",
    "        \n",
    "        #info concerning subject response\n",
    "        behav_resp = np.empty(320, dtype=object)\n",
    "        behav_resp[:160] = behav_run1['Resp'].values\n",
    "        behav_resp[160:] = behav_run2['Resp'].values\n",
    "        \n",
    "        #info concerning trial type\n",
    "        behav_type = np.empty(320, dtype=object)\n",
    "        behav_type[:160] = behav_run1['TrialType'].values\n",
    "        behav_type[160:] = behav_run2['TrialType'].values\n",
    "        \n",
    "        trial_shift = behav_type[:-1] \n",
    "        trial_shift = np.insert(trial_shift, 0, -1)\n",
    "        \n",
    "        #indices of all Bs in the original dataset without preceeding BL trials\n",
    "        b_BL_indices = np.where((behav_type == 'B') & (trial_shift == 'BL'))[0]\n",
    "        #grabs only B without preceeding BL trials\n",
    "        b_wo_BL_indices = np.where((behav_type == 'B') & (trial_shift != 'BL'))[0]\n",
    "        print \"# Bs before BLs\", b_BL_indices\n",
    "        print \"# Bs w/o BLs\", b_wo_BL_indices       \n",
    "        \n",
    "        #isolate bad Bs for removal in learning curve/derivative/p95 files\n",
    "        bad_Bs = [] \n",
    "        bad_Bs.append(b_BL_indices)\n",
    "        for curr_B in b_wo_BL_indices:\n",
    "            if not curr_B in bad_Bs:\n",
    "                #identify in B trials which are non-response\n",
    "                if behav_resp[curr_B] == 'NR': \n",
    "                    bad_Bs.append(curr_B)\n",
    "                #indices if B trial comes first (observed on 001 run 6)    \n",
    "                if curr_B in [0, 157, 158, 159, 160, 317, 318, 319]: \n",
    "                    bad_Bs.append(curr_B)\n",
    "        bad_Bs.sort() \n",
    "        print bad_Bs\n",
    "        \n",
    "        #get the indices for the bad Bs within the group of Bs\n",
    "        bad_B_ind = [j for j, f in enumerate(b_wo_BL_indices) if f in bad_Bs] \n",
    "        bad_B_ind.sort()\n",
    "        #print bad_Bs\n",
    "        #reverse order of Bs to be removed\n",
    "        bad_B_ind = bad_B_ind[::-1]\n",
    "        \n",
    "        \n",
    "        #remove the bad Bs from the B-list\n",
    "        tempB = list(b_wo_BL_indices)\n",
    "        for curr_bad_B in bad_B_ind:\n",
    "            tempB.pop(curr_bad_B)\n",
    "        good_Bs = np.array(tempB)\n",
    "        #print good_Bs\n",
    "        #print b_wo_BL_indices\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #LEARNING CURVE FILES\n",
    "        #create a temp version of learning_curve\n",
    "        temp2 = list(learning_curve)\n",
    "        #pop out the bad Bs starting from the end\n",
    "        for curr_bad_B in bad_B_ind:\n",
    "            temp2.pop(curr_bad_B)\n",
    "        #save without the removed Bs    \n",
    "        new_learning = np.array(temp2)\n",
    "        alt_learning_curve = new_learning[10:-17]\n",
    "        \n",
    "        #P95 FILES\n",
    "        #create a temp version of upper_95\n",
    "        temp3 = list(upper_95)\n",
    "        #pop out the bad Bs starting from the end\n",
    "        for curr_bad_B in bad_B_ind:\n",
    "            temp3.pop(curr_bad_B)\n",
    "        #save without the removed Bs    \n",
    "        new_upper_95 = np.array(temp3)\n",
    "        alt_upper_95 = new_upper_95[10:-17]\n",
    "        #print len(new_upper_95)\n",
    "        \n",
    "        # Condition to select subjects and sets that exhibit learning\n",
    "        if np.mean(new_learning[-10:]) > np.mean(new_upper_95[:10]):\n",
    "            #DERIV FILES\n",
    "            #create a temp version of deriv_file\n",
    "            temp = list(deriv_file)\n",
    "            #pop out the bad Bs starting from the end\n",
    "            for curr_bad_B in bad_B_ind:\n",
    "                temp.pop(curr_bad_B)\n",
    "            #save the deriv_file without the removed Bs    \n",
    "            new_deriv = np.array(temp)\n",
    "            alt_deriv_file = new_deriv[10:-17]\n",
    "            \n",
    "            #target_trial = np.argmax(new_deriv)\n",
    "            #grabs the index of the largest derivative\n",
    "            alt_target_trial = np.argmax(alt_deriv_file)+10\n",
    "            \n",
    "            \n",
    "            #print len(good_Bs)\n",
    "            #print good_Bs\n",
    "        \n",
    "            #print behav_os[good_Bs-1]\n",
    "            #print \"# copes\", len(curr_set_copes)\n",
    "            #print curr_set_copes\n",
    "            #convert original behavioral file indices to new B-specific index\n",
    "            new_indices_B = []\n",
    "            for n, curr_new_B in enumerate(good_Bs):\n",
    "                new_indices_B.append(n)\n",
    "            new_indices_B = np.array(new_indices_B) \n",
    "            #print alt_target_trial        \n",
    "            #print new_indices_B\n",
    "            #grabs the 7 B trials surrounding the target trial\n",
    "            b_learning = new_indices_B[alt_target_trial-5:alt_target_trial+6]\n",
    "            #print b_learning\n",
    "            #grabs the 7 B trials after learning block\n",
    "            b_after = new_indices_B[alt_target_trial+6:alt_target_trial+17]\n",
    "            #print b_after\n",
    "            fixed_learning_files = curr_set_copes[b_learning]\n",
    "            fixed_after_files = curr_set_copes[b_after] \n",
    "            '''\n",
    "            #copy and save selected learning files to new folder for merge script\n",
    "            for curr_learning in fixed_learning_files:\n",
    "                learning_basename =  os.path.basename(curr_learning)  \n",
    "                shutil.copy2(curr_learning,\n",
    "                             join('/home/data/madlab/data/mri/wmaze/frstlvl/wmaze_MRthesis/',\n",
    "                                  'fixed_before_conditional/model3_2-3-2-4/11-11window/{0}/'.format(sub),\n",
    "                                  'learning_window/{0}'.format(learning_basename)))\n",
    "               \n",
    "            #copy and save selected after files to new folder for merge script   \n",
    "            for curr_after in fixed_after_files:\n",
    "                after_basename =  os.path.basename(curr_after)\n",
    "                shutil.copy2(curr_after,\n",
    "                             join('/home/data/madlab/data/mri/wmaze/frstlvl/wmaze_MRthesis/',\n",
    "                                  'fixed_before_conditional/model3_2-3-2-4/11-11window/{0}/'.format(sub),\n",
    "                                  'after_window/{0}'.format(after_basename)))\n",
    "            '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
