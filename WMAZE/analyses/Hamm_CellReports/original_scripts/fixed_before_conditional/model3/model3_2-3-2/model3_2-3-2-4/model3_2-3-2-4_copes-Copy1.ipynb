{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 Version 2.3.2.4\n",
    "## Isolating trials of learning -- 7 during learning, 7 after learning\n",
    "### Removing last 3 volumes using FSL ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import shutil \n",
    "import os\n",
    "from os.path import join, split, basename\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 16, 28, 37, 48, 51, 64, 86, 94, 104, 110, 121, 136, 139, 152, 158, 174, 177, 202, 207, 221, 236, 248, 272, 280, 290, 304, 315, 318]\n",
      "[318, 315, 304, 290, 280, 272, 248, 236, 221, 207, 202, 177, 174, 158, 152, 139, 136, 121, 110, 104, 94, 86, 64, 51, 48, 37, 28, 16, 9]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "pop index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-ccf5a0de60c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m#pop out the bad Bs starting from the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcurr_bad_B\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbad_B_ind\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mtemp2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_bad_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;31m#save without the removed Bs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mnew_learning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop index out of range"
     ]
    }
   ],
   "source": [
    "#cope01_FX_before_COND_incorr_run1_trl1_onset5.72.nii.gz\n",
    "def onset_sort(x):\n",
    "    x = x.split('_')[-1]\n",
    "    return(x[5:-8])\n",
    "\n",
    "subs = ['WMAZE_010']\n",
    "'''\n",
    "subs = ['WMAZE_002', 'WMAZE_004', 'WMAZE_005', 'WMAZE_006',\n",
    "        'WMAZE_007', 'WMAZE_008', 'WMAZE_009', 'WMAZE_010', 'WMAZE_012',\n",
    "        'WMAZE_017', 'WMAZE_018', 'WMAZE_019', 'WMAZE_020', 'WMAZE_021',\n",
    "        'WMAZE_022', 'WMAZE_023', 'WMAZE_024', 'WMAZE_026', 'WMAZE_027']\n",
    "'''\n",
    "\n",
    "sets = ['set1', 'set2', 'set3']\n",
    "runs = ['run1', 'run2', 'run3', 'run4', 'run5', 'run6']\n",
    "\n",
    "\n",
    "for sub in subs:\n",
    "    sub_dir = '/home/data/madlab/data/mri/wmaze/'\n",
    "    \n",
    "    #grab the derivative files created from the set-based learning analysis\n",
    "    frst_deriv_files = glob(join(sub_dir, \n",
    "                                 'scanner_behav/{0}/Bprime_pmode_set*.txt'.format(sub))) \n",
    "    frst_deriv_files.sort() \n",
    "    \n",
    "    #grab the learning curve file for B trials\n",
    "    learning_files = glob(join(sub_dir, 'scanner_behav/{0}/B_pmode_set*.txt'.format(sub))) \n",
    "    learning_files.sort()\n",
    "    \n",
    "    #grab the 95% confidence file for B trials\n",
    "    upper_95_files = glob(join(sub_dir, \n",
    "                               'scanner_behav/{0}/B_p95_set*.txt'.format(sub)))\n",
    "    upper_95_files.sort()\n",
    "    \n",
    "    #grab all cope files created by LSS Model 5\n",
    "    cope_files = glob(join(sub_dir, \n",
    "                          'frstlvl/wmaze_MRthesis/fixed_before_conditional/model3_2-3-2/{0}/'.format(sub),\n",
    "                          'modelfit/contrasts/_estimate_model*/cope*_FX_before_COND_*corr_run*_trl*.nii.gz'))     \n",
    "    cope_files.sort()\n",
    "    #print cope_files\n",
    "    \n",
    "    #grab the behavioral files for all runs\n",
    "    behav_runs = glob(join(sub_dir, \n",
    "                           'scanner_behav/{0}/{0}_wmazebl_2015*.txt'.format(sub))) \n",
    "    behav_runs.sort()\n",
    "    '''\n",
    "    os.makedirs(join('/home/data/madlab/data/mri/wmaze/frstlvl/wmaze_MRthesis/',\n",
    "                     'fixed_before_conditional/model3_2-3-2-4/11-11window/{0}/learning_window/'.format(sub)))\n",
    "    \n",
    "    os.makedirs(join('/home/data/madlab/data/mri/wmaze/frstlvl/wmaze_MRthesis/',\n",
    "                     'fixed_before_conditional/model3_2-3-2-4/11-11window/{0}/after_window/'.format(sub)))\n",
    "    '''\n",
    "    \n",
    "    #### LOADING AND ORGANIZING THE COPE FILES ####\n",
    "    all_runs = []\n",
    "    for curr_run in runs:\n",
    "        #selects only the cope files containing the current run's number\n",
    "        curr_run_files = np.array([f for f in cope_files if curr_run in f])\n",
    "        #gets the onset time out of the file names using function\n",
    "        onset_nums = [float(onset_sort(f)) for f in curr_run_files]\n",
    "        sorted_nums = np.argsort(onset_nums)\n",
    "        #arranges the actual files according to onset time\n",
    "        curr_run_files = curr_run_files[sorted_nums]\n",
    "        all_runs.append(curr_run_files)\n",
    "        \n",
    "    \n",
    "    for i, curr_set in enumerate(sets):\n",
    "        #load derivative, learning, and p95 files\n",
    "        deriv_file = np.loadtxt(frst_deriv_files[i])\n",
    "        learning_curve = np.loadtxt(learning_files[i]) \n",
    "        upper_95 = np.loadtxt(upper_95_files[i])\n",
    "        \n",
    "        #### COPE FILES ####\n",
    "        #merge the two runs into one array for the current stim set\n",
    "        curr_set_copes = np.concatenate((all_runs[i*2], all_runs[i*2+1]))\n",
    "        #print len(curr_set_copes) \n",
    "        \n",
    "        \n",
    "        #### GETTING THE DERIV FILES TO MATCH NUMBER OF COPES ####\n",
    "        #load behavioral files\n",
    "        behav_run1 = pd.read_table(behav_runs[i*2])\n",
    "        behav_run2 = pd.read_table(behav_runs[i*2+1])\n",
    "        \n",
    "        \n",
    "        #info concerning onset time\n",
    "        behav_os = np.empty(320, dtype=object)\n",
    "        behav_os[:160] = behav_run1['StimOnset'].values\n",
    "        behav_os[160:] = behav_run2['StimOnset'].values\n",
    "        \n",
    "        #info concerning subject response\n",
    "        behav_resp = np.empty(320, dtype=object)\n",
    "        behav_resp[:160] = behav_run1['Resp'].values\n",
    "        behav_resp[160:] = behav_run2['Resp'].values\n",
    "        \n",
    "        #info concerning trial type\n",
    "        behav_type = np.empty(320, dtype=object)\n",
    "        behav_type[:160] = behav_run1['TrialType'].values\n",
    "        behav_type[160:] = behav_run2['TrialType'].values\n",
    "        \n",
    "        trial_shift = behav_type[:-1] \n",
    "        trial_shift = np.insert(trial_shift, 0, -1)\n",
    "        \n",
    "        all_b_indices = np.where((behav_type == 'B'))[0]\n",
    "        #indices of all Bs in the original dataset without preceeding BL trials\n",
    "        b_BL_indices = np.where((behav_type == 'B') & (trial_shift == 'BL'))[0]\n",
    "        #grabs only B without preceeding BL trials\n",
    "        #b_wo_BL_indices = np.where((behav_type == 'B') & (trial_shift != 'BL'))[0]\n",
    "        #print \"# Bs before BLs\", len(b_BL_indices)\n",
    "        #print \"# Bs w/o BLs\", b_wo_BL_indices       \n",
    "        \n",
    "        #isolate bad Bs for removal in learning curve/derivative/p95 files\n",
    "        bad_Bs = [] \n",
    "        bad_Bs.extend(b_BL_indices)\n",
    "        for curr_B in all_b_indices:\n",
    "            if not curr_B in bad_Bs:\n",
    "                #identify in B trials which are non-response\n",
    "                if behav_resp[curr_B] == 'NR': \n",
    "                    bad_Bs.append(curr_B)\n",
    "                #indices if B trial comes first (observed on 001 run 6)    \n",
    "                if curr_B in [0, 157, 158, 159, 160, 317, 318, 319]: \n",
    "                    bad_Bs.append(curr_B)\n",
    "        bad_Bs.sort() \n",
    "        #print bad_Bs\n",
    "        \n",
    "        #get the indices for the bad Bs within the group of Bs\n",
    "        bad_B_ind = [j for j, f in enumerate(all_b_indices) if f in bad_Bs] \n",
    "        bad_B_ind.sort()\n",
    "        #print bad_B_ind\n",
    "        #reverse order of Bs to be removed\n",
    "        bad_B_ind = bad_Bs[::-1]\n",
    "        print bad_B_ind\n",
    "      \n",
    "        #LEARNING CURVE FILES\n",
    "        #create a temp version of learning_curve\n",
    "        temp2 = list(learning_curve)\n",
    "        #pop out the bad Bs starting from the end\n",
    "        for curr_bad_B in bad_B_ind:\n",
    "            temp2.pop(curr_bad_B)\n",
    "        #save without the removed Bs    \n",
    "        new_learning = np.array(temp2)\n",
    "        #print len(new_learning)\n",
    "        alt_learning_curve = new_learning[10:-17]\n",
    "        \n",
    "        #P95 FILES\n",
    "        #create a temp version of upper_95\n",
    "        temp3 = list(upper_95)\n",
    "        #pop out the bad Bs starting from the end\n",
    "        for curr_bad_B in bad_B_ind:\n",
    "            temp3.pop(curr_bad_B)\n",
    "        #save without the removed Bs    \n",
    "        new_upper_95 = np.array(temp3)\n",
    "        alt_upper_95 = new_upper_95[10:-17]\n",
    "        #print len(new_upper_95)\n",
    "        \n",
    "        # Condition to select subjects and sets that exhibit learning\n",
    "        if np.mean(new_learning[-10:]) > np.mean(new_upper_95[:10]):\n",
    "            #DERIV FILES\n",
    "            #create a temp version of deriv_file\n",
    "            temp = list(deriv_file)\n",
    "            #pop out the bad Bs starting from the end\n",
    "            for curr_bad_B in bad_B_ind:\n",
    "                temp.pop(curr_bad_B)\n",
    "            #save the deriv_file without the removed Bs    \n",
    "            new_deriv = np.array(temp)\n",
    "            alt_deriv_file = new_deriv[10:-17]\n",
    "            \n",
    "            #target_trial = np.argmax(new_deriv)\n",
    "            #grabs the index of the largest derivative\n",
    "            alt_target_trial = np.argmax(alt_deriv_file)+10\n",
    "            \n",
    "            \n",
    "            #print len(good_Bs)\n",
    "            #print good_Bs\n",
    "        \n",
    "            #print behav_os[good_Bs-1]\n",
    "            #print \"# copes\", len(curr_set_copes)\n",
    "            #print curr_set_copes\n",
    "            #convert original behavioral file indices to new B-specific index\n",
    "            new_indices_B = []\n",
    "            for n, curr_new_B in enumerate(good_Bs):\n",
    "                new_indices_B.append(n)\n",
    "            new_indices_B = np.array(new_indices_B) \n",
    "            #print alt_target_trial        \n",
    "            #print new_indices_B\n",
    "            #grabs the 7 B trials surrounding the target trial\n",
    "            b_learning = new_indices_B[alt_target_trial-5:alt_target_trial+6]\n",
    "            #print b_learning\n",
    "            #grabs the 7 B trials after learning block\n",
    "            b_after = new_indices_B[alt_target_trial+6:alt_target_trial+17]\n",
    "            #print b_after\n",
    "            #fixed_learning_files = curr_set_copes[b_learning]\n",
    "            #fixed_after_files = curr_set_copes[b_after] \n",
    "            '''\n",
    "            #copy and save selected learning files to new folder for merge script\n",
    "            for curr_learning in fixed_learning_files:\n",
    "                learning_basename =  os.path.basename(curr_learning)  \n",
    "                shutil.copy2(curr_learning,\n",
    "                             join('/home/data/madlab/data/mri/wmaze/frstlvl/wmaze_MRthesis/',\n",
    "                                  'fixed_before_conditional/model3_2-3-2-4/11-11window/{0}/'.format(sub),\n",
    "                                  'learning_window/{0}'.format(learning_basename)))\n",
    "               \n",
    "            #copy and save selected after files to new folder for merge script   \n",
    "            for curr_after in fixed_after_files:\n",
    "                after_basename =  os.path.basename(curr_after)\n",
    "                shutil.copy2(curr_after,\n",
    "                             join('/home/data/madlab/data/mri/wmaze/frstlvl/wmaze_MRthesis/',\n",
    "                                  'fixed_before_conditional/model3_2-3-2-4/11-11window/{0}/'.format(sub),\n",
    "                                  'after_window/{0}'.format(after_basename)))\n",
    "            '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
