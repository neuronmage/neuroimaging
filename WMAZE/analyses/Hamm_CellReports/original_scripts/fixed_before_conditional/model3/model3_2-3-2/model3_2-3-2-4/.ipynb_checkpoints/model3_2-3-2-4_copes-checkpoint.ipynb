{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 Version 2.3.2.4\n",
    "## Isolating trials of learning -- 11 during learning, 11 after learning\n",
    "### Removing last 3 volumes using FSL ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import shutil \n",
    "import os\n",
    "from os.path import join, split, basename\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "54\n",
      "[13 14 15 16 17 18 19 20 21 22 23]\n",
      "[24 25 26 27 28 29 30 31 32 33 34]\n",
      "53\n",
      "52\n",
      "[ 8  9 10 11 12 13 14 15 16 17 18]\n",
      "[19 20 21 22 23 24 25 26 27 28 29]\n"
     ]
    }
   ],
   "source": [
    "#cope01_FX_before_COND_incorr_run1_trl1_onset5.72.nii.gz\n",
    "def onset_sort(x):\n",
    "    x = x.split('_')[-1]\n",
    "    return(x[5:-8])\n",
    "\n",
    "subs = ['WMAZE_001']\n",
    "'''\n",
    "subs = ['WMAZE_002', 'WMAZE_004', 'WMAZE_005', 'WMAZE_006',\n",
    "        'WMAZE_007', 'WMAZE_008', 'WMAZE_009', 'WMAZE_010', 'WMAZE_012',\n",
    "        'WMAZE_017', 'WMAZE_018', 'WMAZE_019', 'WMAZE_020', 'WMAZE_021',\n",
    "        'WMAZE_022', 'WMAZE_023', 'WMAZE_024', 'WMAZE_026', 'WMAZE_027']\n",
    "'''\n",
    "\n",
    "sets = ['set1', 'set2', 'set3']\n",
    "runs = ['run1', 'run2', 'run3', 'run4', 'run5', 'run6']\n",
    "\n",
    "\n",
    "for sub in subs:\n",
    "    sub_dir = '/home/data/madlab/data/mri/wmaze/'\n",
    "    \n",
    "    #grab the derivative files created from the set-based learning analysis\n",
    "    frst_deriv_files = glob(join(sub_dir,  'scanner_behav/{0}/Bprime_pmode_set*.txt'.format(sub))) \n",
    "    frst_deriv_files.sort()     \n",
    "    #grab the learning curve file for B trials\n",
    "    learning_files = glob(join(sub_dir, 'scanner_behav/{0}/B_pmode_set*.txt'.format(sub))) \n",
    "    learning_files.sort()    \n",
    "    #grab the 95% confidence file for B trials\n",
    "    upper_95_files = glob(join(sub_dir, 'scanner_behav/{0}/B_p95_set*.txt'.format(sub)))\n",
    "    upper_95_files.sort() \n",
    "    #grab all cope files created by LSS Model 5\n",
    "    cope_files = glob(join(sub_dir, \n",
    "                          'frstlvl/wmaze_MRthesis/fixed_before_conditional/model3_2-3-2/{0}/'.format(sub),\n",
    "                          'modelfit/contrasts/_estimate_model*/cope*_FX_before_COND_*corr_run*_trl*.nii.gz'))     \n",
    "    cope_files.sort()\n",
    "    \n",
    "    #grab the behavioral files for all runs\n",
    "    behav_runs = glob(join(sub_dir, 'scanner_behav/{0}/{0}_wmazebl_2015*.txt'.format(sub))) \n",
    "    behav_runs.sort()\n",
    "    '''\n",
    "    os.makedirs(join('/home/data/madlab/data/mri/wmaze/frstlvl/wmaze_MRthesis/',\n",
    "                     'fixed_before_conditional/model3_2-3-2-4/11-11window/{0}/learning_window/'.format(sub)))\n",
    "    \n",
    "    os.makedirs(join('/home/data/madlab/data/mri/wmaze/frstlvl/wmaze_MRthesis/',\n",
    "                     'fixed_before_conditional/model3_2-3-2-4/11-11window/{0}/after_window/'.format(sub)))\n",
    "    '''\n",
    "    \n",
    "    #### LOADING AND ORGANIZING THE COPE FILES ####\n",
    "    all_runs = []\n",
    "    for curr_run in runs:\n",
    "        #selects only the cope files containing the current run's number\n",
    "        curr_run_files = np.array([f for f in cope_files if curr_run in f])    \n",
    "        onset_nums = [float(onset_sort(f)) for f in curr_run_files] #gets onset time from filename using function\n",
    "        sorted_nums = np.argsort(onset_nums)\n",
    "        curr_run_files = curr_run_files[sorted_nums] #arranges the actual files according to onset time\n",
    "        all_runs.append(curr_run_files)\n",
    "           \n",
    "    for i, curr_set in enumerate(sets): #load derivative, learning, and p95 files\n",
    "        deriv_file = np.loadtxt(frst_deriv_files[i])\n",
    "        learning_curve = np.loadtxt(learning_files[i]) \n",
    "        upper_95 = np.loadtxt(upper_95_files[i])\n",
    "        \n",
    "        #### COPE FILES ####\n",
    "        #merge the two runs into one array for the current stim set\n",
    "        curr_set_copes = np.concatenate((all_runs[i*2], all_runs[i*2+1]))\n",
    "               \n",
    "        #### GETTING THE DERIV FILES TO MATCH NUMBER OF COPES ####\n",
    "        behav_run1 = pd.read_table(behav_runs[i*2]) #load both run behavioral files\n",
    "        behav_run2 = pd.read_table(behav_runs[i*2+1])       \n",
    "        \n",
    "        behav_os = np.empty(320, dtype = object) #info concerning onset time\n",
    "        behav_os[:160] = behav_run1['StimOnset'].values\n",
    "        behav_os[160:] = behav_run2['StimOnset'].values               \n",
    "        behav_resp = np.empty(320, dtype = object)  #info concerning subject response\n",
    "        behav_resp[:160] = behav_run1['Resp'].values\n",
    "        behav_resp[160:] = behav_run2['Resp'].values        \n",
    "        behav_type = np.empty(320, dtype = object) #info concerning trial type\n",
    "        behav_type[:160] = behav_run1['TrialType'].values\n",
    "        behav_type[160:] = behav_run2['TrialType'].values\n",
    "        \n",
    "        trial_shift = behav_type[:-1] \n",
    "        trial_shift = np.insert(trial_shift, 0, -1)\n",
    "        \n",
    "        #indices of all Bs in the original dataset without preceeding BL trials\n",
    "        b_indices = np.where((behav_type == 'B'))[0]        \n",
    "        b_BL_indices = np.where((behav_type == 'B') & (trial_shift == 'BL'))[0] #grabs B trials with preceeding BLs\n",
    "               \n",
    "        #isolate bad Bs for removal in learning curve/derivative/p95 files\n",
    "        bad_Bs = [] \n",
    "        bad_Bs.extend(b_BL_indices)\n",
    "        for curr_B in b_indices:\n",
    "            if not curr_B in bad_Bs: #identify in B trials which are non-response\n",
    "                if behav_resp[curr_B] == 'NR': \n",
    "                    bad_Bs.append(curr_B)    \n",
    "                if curr_B in [0, 157, 158, 159, 160, 317, 318, 319]: #indices if B first trial (observed on 001 run 6)\n",
    "                    bad_Bs.append(curr_B)\n",
    "        bad_Bs.sort()   \n",
    "        \n",
    "        #get the indices for the bad Bs within the group of Bs\n",
    "        bad_B_ind = [j for j, f in enumerate(b_indices) if f in bad_Bs] \n",
    "        bad_B_ind.sort()\n",
    "        bad_B_ind = bad_B_ind[::-1] #reverse order of Bs to be removed\n",
    "        \n",
    "        #LEARNING CURVE FILES\n",
    "        temp2 = list(learning_curve) #create a temp version of learning_curve\n",
    "        for curr_bad_B in bad_B_ind: #pop out the bad Bs starting from the end\n",
    "            temp2.pop(curr_bad_B)   \n",
    "        new_learning = np.array(temp2) #save without the removed Bs \n",
    "        alt_learning_curve = new_learning[10:-17]\n",
    "        \n",
    "        #P95 FILES\n",
    "        temp3 = list(upper_95)\n",
    "        for curr_bad_B in bad_B_ind:\n",
    "            temp3.pop(curr_bad_B)   \n",
    "        new_upper_95 = np.array(temp3)\n",
    "        alt_upper_95 = new_upper_95[10:-17]\n",
    "        \n",
    "        # Condition to select subjects and sets that exhibit learning\n",
    "        if np.mean(new_learning[-10:]) > np.mean(new_upper_95[:10]):\n",
    "            #DERIV FILES\n",
    "            temp = list(deriv_file)\n",
    "            for curr_bad_B in bad_B_ind:\n",
    "                temp.pop(curr_bad_B)   \n",
    "            new_deriv = np.array(temp)\n",
    "            alt_deriv_file = new_deriv[10:-17]           \n",
    "            #target_trial = np.argmax(new_deriv)\n",
    "            alt_target_trial = np.argmax(alt_deriv_file)+10 #grabs the index of the largest derivative\n",
    "                       \n",
    "            #remove the bad Bs from the B-list\n",
    "            temp4 = list(b_indices)\n",
    "            for curr_bad_B in bad_B_ind:\n",
    "                temp4.pop(curr_bad_B)\n",
    "            good_Bs = np.array(temp4)\n",
    "\n",
    "            #convert original behavioral file indices to new B-specific index\n",
    "            new_indices_B = []\n",
    "            for n, curr_new_B in enumerate(good_Bs):\n",
    "                new_indices_B.append(n)\n",
    "            new_indices_B = np.array(new_indices_B)         \n",
    "            #grabs the 11 B trials surrounding the target trial\n",
    "            b_learning = new_indices_B[alt_target_trial-5:alt_target_trial+6]\n",
    "            #grabs the 11 B trials after learning block\n",
    "            b_after = new_indices_B[alt_target_trial+6:alt_target_trial+17]\n",
    "            fixed_learning_files = curr_set_copes[b_learning]\n",
    "            fixed_after_files = curr_set_copes[b_after] \n",
    "            '''\n",
    "            #copy and save selected learning files to new folder for merge script\n",
    "            for curr_learning in fixed_learning_files:\n",
    "                learning_basename =  os.path.basename(curr_learning)  \n",
    "                shutil.copy2(curr_learning,\n",
    "                             join('/home/data/madlab/data/mri/wmaze/frstlvl/wmaze_MRthesis/',\n",
    "                                  'fixed_before_conditional/model3_2-3-2-4/11-11window/{0}/'.format(sub),\n",
    "                                  'learning_window/{0}'.format(learning_basename)))\n",
    "               \n",
    "            #copy and save selected after files to new folder for merge script   \n",
    "            for curr_after in fixed_after_files:\n",
    "                after_basename =  os.path.basename(curr_after)\n",
    "                shutil.copy2(curr_after,\n",
    "                             join('/home/data/madlab/data/mri/wmaze/frstlvl/wmaze_MRthesis/',\n",
    "                                  'fixed_before_conditional/model3_2-3-2-4/11-11window/{0}/'.format(sub),\n",
    "                                  'after_window/{0}'.format(after_basename)))\n",
    "            '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
