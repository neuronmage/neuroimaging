{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIDSifer & Dicom Conversion\n",
    "\n",
    "\n",
    "## Numbering convention preceding scan label _IS NOT CONSISTENT_ across subjects\n",
    "## Script calls \"heuristics.csv\" \n",
    "### heuristics.csv contains two columns:\n",
    "##### - init_name -- designated data file type (e.g. T1w, T2w, pd, etc)\n",
    "##### - dest_name -- naming convention for data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL ['/scratch/madlab/bidsify_sea/SEA-1035/Pruden_SEA_1035-S1/scans/9-T1w_MPR_vNav']\n",
      "\n",
      "/scratch/madlab/bidsify_sea/SEA-1035/Pruden_SEA_1035-S1/scans/9-T1w_MPR_vNav /home/data/madlab/Pruden_SEA/dset/sub-1035/anat/sub-1035_T1w\n",
      "Chris Rorden's dcm2niiX version v1.0.20190902  GCC4.8.5 (64-bit Linux)\n",
      "Found 176 DICOM file(s)\n",
      "Convert 176 DICOM as /home/data/madlab/Pruden_SEA/dset/sub-1035/anat/sub-1035_T1w/files_T1w_MPR_vNav_20220501154331_9 (256x256x176x1)\n",
      "Conversion required 2.715244 seconds (2.500000 for core code).\n",
      "1035 /scratch/madlab/bidsify_sea/SEA-1035/Pruden_SEA_1035-S1/scans/9-T1w_MPR_vNav\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import json\n",
    "import shutil\n",
    "import tarfile\n",
    "import subprocess as sp\n",
    "from glob import glob\n",
    "import pydicom as dcm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil \n",
    "\n",
    "#### FUNCTIONS ####\n",
    "\n",
    "def convert_nifti(target_folder, destination): #conversion function, removes superfluous directory tree\n",
    "    os.makedirs(destination, exist_ok=True) #make new directory in permanent storage\n",
    "    src_dcms = '{0}/resources/DICOM/files/'.format(target_folder) \n",
    "    cmd = \"dcm2niix -o {0} {1}\".format(destination, src_dcms) #convert and save to respective scan type folder\n",
    "    sp.Popen(cmd, shell=True).wait() #subprocess executes conversion command, waits if necessary\n",
    "    for i in glob(destination + \"/*\"): #grabs all files\n",
    "        idx = i.index(\".\") #returns index of \".\" in current path/filename to identify beginning of extension\n",
    "        shutil.move(i, destination + i[idx:]) #move converted NIFTI from scratch to data location with extension\n",
    "    shutil.rmtree(destination) #remove old tree\n",
    "    \n",
    "###################\n",
    "       \n",
    "df = pd.read_csv('heuristics.csv') #open heuristics file as pandas dataframe  \n",
    "\n",
    "for tar_file in glob('/home/data/madlab/Pruden_SEA/sourcedata/Pruden_SEA_*-S1.tar.gz'): #iterate through Ss tars\n",
    "    sub = os.path.basename(tar_file).split('_')[-1].split('-')[0][:4] #gets only Ss ID \n",
    "    pain_name = os.path.basename(tar_file).split('_')[-1].split('-')[0][:] #gets only Ss ID\n",
    "  \n",
    "    if os.path.exists('/home/data/madlab/Pruden_SEA/dset/sub-{0}/'.format(sub)): #check to see if Ss is new\n",
    "        continue        \n",
    "    os.makedirs('/scratch/madlab/bidsify_sea/SEA-{0}/'.format(sub), exist_ok=True) #creates subdirectories\n",
    "    \n",
    "    #unzipping file into new directories without deletion \n",
    "    sp.Popen('tar -xf {0} -C /scratch/madlab/bidsify_sea/SEA-{1}'.format(tar_file, sub), shell=True).wait()\n",
    "    #defines current working directory for subject data\n",
    "    curr_dir = '/scratch/madlab/bidsify_sea/SEA-{0}/Pruden_SEA_{1}-S1/scans/'.format(sub, pain_name)\n",
    "       \n",
    "    #grabs relevant directories (excluding setter, 32ch, and MPRG) \n",
    "    all_dirs = sorted([x for x in glob(curr_dir + \"*\") if not \"setter\" in x and not \"32ch\" in x and not \"MPRG\" in x])\n",
    "    final_dirs = []\n",
    "    for x in ['T1', 'T2w', 't2', 'pd_tse', 'dMRI_PA', 'dMRI_DistortionMap_AP', 'dMRI_DistortionMap_PA']: \n",
    "        type_nums = []\n",
    "        temp = []\n",
    "        for idx, scan_type in enumerate(all_dirs): #iterate through the filtered scans    \n",
    "            #print(x, idx, scan_type)\n",
    "            if x in scan_type: #iterate through targeted scan types\n",
    "                temp.append(all_dirs[idx])\n",
    "                type_nums.append(int(all_dirs[idx].split('/')[-1].split('-')[0])) #grab the scan CIS assigned scan #       \n",
    "        if len(temp) > 1: #when more than one scan of target type is found\n",
    "            #print(temp, type_nums.index(min(type_nums)))\n",
    "            final_dirs.append(temp[type_nums.index(max(type_nums))]) #remove the first of that type from all_dirs  \n",
    "        elif len(temp) == 1:\n",
    "            final_dirs.append(temp[0])\n",
    "    #stupid dMRI is in three different scan types... needs its own crap loop\n",
    "    dMRIs = glob('/scratch/madlab/bidsify_sea/SEA-{0}/Pruden_SEA_{1}-S1/scans/*-dMRI'.format(sub, pain_name))\n",
    "    dMRI_nums = []\n",
    "    for idx, dMRI in enumerate(dMRIs):\n",
    "        dMRI_nums.append(int(dMRIs[idx].split('/')[-1].split('-')[0]))\n",
    "    if len(dMRIs) > 1:\n",
    "        final_dirs.append(dMRIs[dMRI_nums.index(max(dMRI_nums))])\n",
    "    elif len(dMRIs) == 1:\n",
    "        final_dirs.append(dMRIs[0])           \n",
    "    final_dirs = sorted(final_dirs)\n",
    "    print(\"FINAL\", final_dirs)   \n",
    "    print(\"\")\n",
    "  \n",
    "    for i in ['anat', 'dwi', 'fmap']: #iterate through folder types      \n",
    "        os.makedirs('/home/data/madlab/Pruden_SEA/dset/sub-{0}/{1}/'.format(sub, i), exist_ok=True) #create dir for each\n",
    "    completed = []    \n",
    "    for curr_scan in final_dirs: #iterate through filtered scans\n",
    "        for row, scan_type in enumerate(df['init_name']): #iterate through scan types defined in heuristics file\n",
    "            if scan_type in curr_scan: #if init name matches current scan type \n",
    "                if not scan_type in completed: #and it hasn't hit before\n",
    "                    break #use row where break stops\n",
    "        print(curr_scan, '/home/data/madlab/Pruden_SEA/dset/sub-{0}/'.format(sub)+df['dest_name'][row].format(sub))\n",
    "        #use custom function to run dcm2niix on current dicoms\n",
    "        convert_nifti(curr_scan,'/home/data/madlab/Pruden_SEA/dset/sub-{0}/'.format(sub)+df['dest_name'][row].format(sub)) \n",
    "        completed.append(scan_type)\n",
    "        print(sub, curr_scan) #prints current Ss identity failure          "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import json\n",
    "import shutil\n",
    "import tarfile\n",
    "import subprocess as sp\n",
    "from glob import glob\n",
    "import pydicom as dcm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil \n",
    "\n",
    "#### FUNCTIONS ####\n",
    "\n",
    "def convert_nifti(target_folder, destination): #conversion function, removes superfluous directory tree\n",
    "    os.makedirs(destination, exist_ok=True) #make new directory in permanent storage\n",
    "    src_dcms = '{0}/resources/DICOM/files/'.format(target_folder) \n",
    "    cmd = \"dcm2niix -o {0} {1}\".format(destination, src_dcms) #convert and save to respective scan type folder\n",
    "    sp.Popen(cmd, shell=True).wait() #subprocess executes conversion command, waits if necessary\n",
    "    for i in glob(destination + \"/*\"): #grabs all files\n",
    "        idx = i.index(\".\") #returns index of \".\" in current path/filename to identify beginning of extension\n",
    "        shutil.move(i, destination + i[idx:]) #move converted NIFTI from scratch to data location with extension\n",
    "    shutil.rmtree(destination) #remove old tree\n",
    "    \n",
    "###################\n",
    "       \n",
    "df = pd.read_csv('heuristics.csv') #open heuristics file as pandas dataframe  \n",
    "\n",
    "for tar_file in glob('/home/data/madlab/Pruden_SEA/sourcedata/Pruden_SEA_*-S1.tar.gz'): #iterate through Ss tars\n",
    "#for tar_file in glob('/home/data/madlab/Pruden_SEA/sourcedata/Pruden_SEA_1008EH-S1.tar.gz'): #used for debugging\n",
    "    print(tar_file)\n",
    "    sub = os.path.basename(tar_file).split('_')[-1].split('-')[0][:4] #gets only Ss ID \n",
    "    pain_name = os.path.basename(tar_file).split('_')[-1].split('-')[0][:] #gets only Ss ID\n",
    "       \n",
    "    if os.path.exists('/home/data/madlab/Pruden_SEA/dset/sub-{0}/'.format(sub)): #check to see if Ss is new\n",
    "        continue        \n",
    "    os.makedirs('/scratch/madlab/bidsify_sea/SEA-{0}/'.format(sub), exist_ok=True) #creates subdirectories\n",
    "    \n",
    "    #unzipping file into new directories without deletion \n",
    "    sp.Popen('tar -xf {0} -C /scratch/madlab/bidsify_sea/SEA-{1}'.format(tar_file, sub), shell=True).wait()\n",
    "    #defines current working directory for subject data\n",
    "    curr_dir = '/scratch/madlab/bidsify_sea/SEA-{0}/Pruden_SEA_{1}-S1/scans/'.format(sub, pain_name)\n",
    "       \n",
    "    #grabs relevant directories (excluding setter, 32ch, and MPRG) \n",
    "    all_dirs = sorted([x for x in glob(curr_dir + \"*\") if not \"setter\" in x and not \"32ch\" in x and not \"MPRG\" in x])\n",
    "    for x in ['T1', 'T2w', 't2', 'pd_tse']: #deals with multiple scans of the same type (uses last scan acquired)\n",
    "        type_nums = []\n",
    "        type_idxs = []\n",
    "        for idx, scan_type in enumerate(all_dirs): #iterate through the filtered scans     \n",
    "            if x in scan_type: #iterate through targeted scan types\n",
    "                type_nums.append(int(all_dirs[idx].split('/')[-1].split('-')[0])) #grab the scan CIS assigned scan #\n",
    "                type_idxs.append(idx) #grab the all_dir index of targeted scans\n",
    "                if len(type_nums) == 2: #when a second scan of the target type is found                  \n",
    "                    all_dirs.pop(type_idxs[type_nums.index(min(type_nums))]) #remove the first of that type from all_dirs   \n",
    "       \n",
    "    for i in ['anat', 'dwi', 'fmap']: #iterate through folder types      \n",
    "        os.makedirs('/home/data/madlab/Pruden_SEA/dset/sub-{0}/{1}/'.format(sub, i), exist_ok=True) #create dir for each\n",
    "    completed = []    \n",
    "    for curr_scan in all_dirs: #iterate through filtered scans\n",
    "        for row, scan_type in enumerate(df['init_name']): #iterate through scan types defined in heuristics file\n",
    "            if scan_type in curr_scan: #if init name matches current scan type \n",
    "                if not scan_type in completed:\n",
    "                    break #use row where break stops\n",
    "        #print(curr_scan, '/home/data/madlab/Pruden_SEA/dset/sub-{0}/'.format(sub)+df['dest_name'][row].format(sub))\n",
    "        #use custom function to run dcm2niix on current dicoms\n",
    "        convert_nifti(curr_scan,'/home/data/madlab/Pruden_SEA/dset/sub-{0}/'.format(sub)+df['dest_name'][row].format(sub)) \n",
    "        completed.append(scan_type)\n",
    "        print(sub, curr_scan) #prints current Ss identity failure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---Brute Force Method (_used when naming convention was compromised_)---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import json\n",
    "import shutil\n",
    "import tarfile\n",
    "import subprocess as sp\n",
    "from glob import glob\n",
    "import pydicom as dcm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T1 Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "dcm2niix -o /home/data/madlab/Pruden_SEA/dset/sub-1008/anat/ /scratch/madlab/bidsify_sea/SEA-1008/Pruden_SEA_1008EH-S1/scans/4-T1w_MPR_vNav/resources/DICOM/files/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T2 Scan"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%bash \n",
    "\n",
    "dcm2niix -o /home/data/madlab/Pruden_SEA/dset/sub-1005/anat/ /scratch/madlab/bidsify_sea/SEA-1005/Pruden_SEA_1005-S1/scans/10-T2w_SPC_vNav/resources/DICOM/files/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PD Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "dcm2niix -o /home/data/madlab/Pruden_SEA/dset/sub-1008/anat/ /scratch/madlab/bidsify_sea/SEA-1008/Pruden_SEA_1008EH-S1/scans/6-pd_tse_Cor_T2_PDHR_FCS/resources/DICOM/files/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DWI Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "dcm2niix -o /home/data/madlab/Pruden_SEA/dset/sub-1005/dwi/ /scratch/madlab/bidsify_sea/SEA-1005/Pruden_SEA_1005T6-S1/scans/13-dMRI/resources/DICOM/files/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DWI Scan - PA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "dcm2niix -o /home/data/madlab/Pruden_SEA/dset/sub-1005/dwi/ /scratch/madlab/bidsify_sea/SEA-1005/Pruden_SEA_1005T6-S1/scans/14-dMRI_PA/resources/DICOM/files/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distortion Map - PA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "dcm2niix -o /home/data/madlab/Pruden_SEA/dset/sub-1008/fmap/ /scratch/madlab/bidsify_sea/SEA-1008/Pruden_SEA_1008EH-S1/scans/8-dMRI_DistortionMap_PA/resources/DICOM/files/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distortion Map - AP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "dcm2niix -o /home/data/madlab/Pruden_SEA/dset/sub-1008/fmap/ /scratch/madlab/bidsify_sea/SEA-1008/Pruden_SEA_1008EH-S1/scans/9-dMRI_DistortionMap_AP/resources/DICOM/files/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---Random Code/Notes---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #an issue was discovered in how the file tree saved for some tars -- *special considerations*\n",
    "    #old Ss directories --> long format\n",
    "    #long_dir = '/scratch/madlab/bidsify_sea/SEA-{0}/home/data/madlab/Pruden_SEA/sourcedata/Pruden_SEA_{0}-S1/scans/'.format(sub)\n",
    "    #new Ss directories --> short format\n",
    "    #short_dir = '/scratch/madlab/bidsify_sea/SEA-{0}/Pruden_SEA_{0}-S1/scans/'.format(sub)\n",
    "    #if os.path.exists(long_dir):\n",
    "        #curr_dir = long_dir #previously acquired Ss\n",
    "    #else:\n",
    "        #curr_dir = short_dir #future Ss\n",
    "        \n",
    "#previous method of dealing with protocol inconsistencies        \n",
    "    corr_scan = {} #only correct scans \n",
    "    corr_idx = {} #indices of correct scans within all_dirs\n",
    "    #scan sequence (numbers before scan type) are not consistent across Ss -- *special considerations*\n",
    "    for idx, curr_scan in enumerate(all_dirs): #dealing with the inconsistent sequence of scans\n",
    "        i = int(curr_scan.split(\"/\")[-1].split(\"-\")[0]) #get scan number and convert from string to int\n",
    "        for row, scan_type in enumerate(df['init_name']): #iterate through scan types in heuristics.csv\n",
    "            #print(i, idx, scan_type)\n",
    "            if scan_type in curr_scan: #current scan contains init_name listed in heuristics file\n",
    "                if not scan_type in corr_scan: #current scan type is not in correct list\n",
    "                    corr_idx[scan_type] = idx #new sublist for indices of scan type\n",
    "                    corr_scan[scan_type] = i #new sublist for correct scan paths\n",
    "\n",
    "    temp = [] \n",
    "    for key in corr_scan: #iterate through scan types in correct list\n",
    "        temp.append(all_dirs[corr_idx[key]]) #isolate and append targeted scan path to temp\n",
    "    all_dirs = temp #reassign all_dirs to contain only the scans we targeted\n",
    "    #print(all_dirs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
